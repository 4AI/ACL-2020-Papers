{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.2"
    },
    "colab": {
      "name": "generate_paper_list_with_arxiv_link.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hunkim/ACL-2020-Papers/blob/master/generate_paper_list_with_arxiv_link.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1m2RpTeiCNQq",
        "colab_type": "text"
      },
      "source": [
        "# Load Paper List"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6G-XWU8JCNQr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def read_papers(path):\n",
        "    papers = [[]]\n",
        "    with open(path, \"r\", encoding=\"utf-8\") as f:\n",
        "        for line in f:\n",
        "            line = line.strip()\n",
        "            if line:\n",
        "                papers[-1].append(line)\n",
        "            else:\n",
        "                papers.append([])\n",
        "    for p in papers:\n",
        "        assert len(p) == 2\n",
        "    return papers"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m_5mqAPzCNQu",
        "colab_type": "code",
        "outputId": "1af6fe5f-b149-452c-f2fd-d57bf41f400d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "longp = read_papers(\"./data/long.txt\")\n",
        "longp[:3]"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['2kenize: Tying Subword Sequences for Chinese Script Conversion',\n",
              "  'Pranav A and Isabelle Augenstein'],\n",
              " ['A Batch Normalized Inference Network Keeps the KL Vanishing Away',\n",
              "  'Qile Zhu, Wei Bi, Xiaojiang Liu, Xiyao Ma, Xiaolin Li and Dapeng Wu'],\n",
              " ['A Call for More Rigor in Unsupervised Cross-lingual Learning',\n",
              "  'Mikel Artetxe, Sebastian Ruder, Dani Yogatama, Gorka Labaka and Eneko Agirre']]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AxPZti17CNQx",
        "colab_type": "code",
        "outputId": "9b6ff125-9a55-4ce1-be39-aecaef1da8f9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "len(longp)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "571"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SqL_0bNPCNQ0",
        "colab_type": "code",
        "outputId": "5ea50937-8954-4de5-e22b-54f15bb61023",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        }
      },
      "source": [
        "short = read_papers(\"./data/short.txt\")\n",
        "short[:3]"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['A Complete Shift-Reduce Chinese Discourse Parser with Robust Dynamic Oracle',\n",
              "  'Shyh-Shiun Hung, Hen-Hsen Huang and Hsin-Hsi Chen'],\n",
              " ['A Diverse Corpus for Evaluating and Developing English Math Word Problem Solvers',\n",
              "  'Shen-yun Miao, Chao-Chun Liang and Keh-Yih Su'],\n",
              " ['A Frame-based Sentence Representation for Machine Reading Comprehension',\n",
              "  'Shaoru Guo, Ru Li, Hongye Tan, Xiaoli Li, Yong Guan, Hongyan Zhao and Yueping Zhang']]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rLNXH4MJCNQ2",
        "colab_type": "code",
        "outputId": "0453196c-9c99-4b13-fdf1-21eb63abd839",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "len(short)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "208"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TrBRORv3CNQ5",
        "colab_type": "code",
        "outputId": "e3932d0d-a826-4117-8ae4-6259c9805f8f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        }
      },
      "source": [
        "demop = read_papers(\"./data/demo.txt\")\n",
        "demop[:3]"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['ADVISER: A Toolkit for Developing Multi-modal, Multi-domain and Socially-engaged Conversational Agents',\n",
              "  'Chia-Yu Li, Daniel Ortega, Dirk Väth, Florian Lux, Lindsey Vanderlyn, Maximilian Schmidt, Michael Neumann, Moritz Völkel, Pavel Denisov, Sabrina Jenne, Zorica Kacarevic and Ngoc Thang Vu'],\n",
              " ['BENTO: A Visual Platform for Building Clinical NLP Pipelines Based on CodaLab',\n",
              "  'Yonghao Jin, Fei Li and Hong Yu'],\n",
              " ['Clinical-Coder: Assigning Interpretable ICD-10 Codes to Chinese Clinical Notes',\n",
              "  'Pengfei Cao, Chenwei Yan, xiangling fu, Yubo Chen, Kang Liu, Jun Zhao, Shengping Liu and Weifeng Chong']]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GySLkygHCNQ7",
        "colab_type": "code",
        "outputId": "96ef1894-8ea7-44ba-f922-059a87cef4a7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "len(demop)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "43"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0cNcBqCsCNQ-",
        "colab_type": "code",
        "outputId": "cb69362a-7bc3-4567-be1a-b21186930ca8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        }
      },
      "source": [
        "student = read_papers(\"./data/student.txt\")\n",
        "student[:3]"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['#NotAWhore! A Computational Linguistic Perspective of Rape Culture and Victimization on Social Media',\n",
              "  'Ashima Suvarna and Grusha Bhalla'],\n",
              " ['A Geometry-Inspired Attack for Generating Natural Language Adversarial Examples',\n",
              "  'Zhao Meng and Roger Wattenhofer'],\n",
              " ['A Simple and Effective Dependency parser for Telugu',\n",
              "  'Sneha Nallani, Manish Shrivastava and Dipti Sharma']]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o9Zc2x0qCNRA",
        "colab_type": "code",
        "outputId": "120a6c6f-7bf7-42cb-91d2-64eff8df937f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "len(student)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "49"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aw4p7l8eCYX2",
        "colab_type": "text"
      },
      "source": [
        "# Sorting by Topic\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c36Fa3LPCovq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "334213e3-e0f7-4cb8-f751-768d887f73eb"
      },
      "source": [
        "import gensim\n",
        "from gensim.utils import simple_preprocess\n",
        "from gensim.parsing.preprocessing import STOPWORDS\n",
        "from nltk.stem import WordNetLemmatizer, SnowballStemmer\n",
        "from nltk.stem.porter import *\n",
        "import numpy as np\n",
        "import nltk\n",
        "\n",
        "nltk.download('wordnet')\n",
        "stemmer = SnowballStemmer(\"english\")\n",
        "\n",
        "def lemmatize_stemming(text):\n",
        "  return stemmer.stem(WordNetLemmatizer().lemmatize(text, pos='v'))\n",
        "\n",
        "# Tokenize and lemmatize\n",
        "def preprocess(text):\n",
        "  result=[]\n",
        "  for token in gensim.utils.simple_preprocess(text) :\n",
        "    if token not in gensim.parsing.preprocessing.STOPWORDS and len(token) > 3:\n",
        "      result.append(lemmatize_stemming(token))\n",
        "                \n",
        "  return result\n",
        "\n",
        "\n"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zqDjrwyoHEPu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#FIXME: Better way to get human readable topic names from LDA topics?\n",
        "def list2topiclist(list, num_topics = 8):\n",
        "  processed_docs = []\n",
        "  for line in list:\n",
        "    processed_line = preprocess(line[0])\n",
        "    processed_docs.append(processed_line)\n",
        "\n",
        "    dictionary = gensim.corpora.Dictionary(processed_docs)\n",
        "    bow_corpus = [dictionary.doc2bow(doc) for doc in processed_docs]\n",
        "\n",
        "  \n",
        "  lda = gensim.models.LdaModel(bow_corpus, num_topics, \n",
        "                               id2word = dictionary, passes = 10)\n",
        "\n",
        "\n",
        "  def get_topic_title(idx, topn=3):\n",
        "    topn_terms = [dictionary[x[0]] for x in lda.get_topic_terms(idx, topn)]\n",
        "    return \" \".join(topn_terms)\n",
        "\n",
        "  # Create topic title\n",
        "  list_topic_titles = []\n",
        "  for i in range(num_topics):\n",
        "    list_topic_titles.append(get_topic_title(i))\n",
        "\n",
        "  # Assign list to topic\n",
        "  topic_dict = {}\n",
        "  for line in list:\n",
        "    processed_line = preprocess(line[0])\n",
        "    bow_vector = dictionary.doc2bow(processed_line)\n",
        "    line_topic = sorted(lda.get_document_topics(bow_vector), \n",
        "                        key=lambda tup: tup[1], reverse=True)\n",
        "    topic_title = list_topic_titles[line_topic[0][0]]\n",
        "\n",
        "    if topic_title not in topic_dict:\n",
        "      topic_dict[topic_title] = []\n",
        "\n",
        "    topic_dict[topic_title].append(line)\n",
        "  \n",
        "  return topic_dict\n",
        "      \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zw8jDBlNNGYH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 190
        },
        "outputId": "8bdee55b-ee6d-46b9-d98f-a2384065dd38"
      },
      "source": [
        "print(demop)\n",
        "topics = list2topiclist(demop)\n",
        "for topic in topics:\n",
        "  print(topic)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[['ADVISER: A Toolkit for Developing Multi-modal, Multi-domain and Socially-engaged Conversational Agents', 'Chia-Yu Li, Daniel Ortega, Dirk Väth, Florian Lux, Lindsey Vanderlyn, Maximilian Schmidt, Michael Neumann, Moritz Völkel, Pavel Denisov, Sabrina Jenne, Zorica Kacarevic and Ngoc Thang Vu'], ['BENTO: A Visual Platform for Building Clinical NLP Pipelines Based on CodaLab', 'Yonghao Jin, Fei Li and Hong Yu'], ['Clinical-Coder: Assigning Interpretable ICD-10 Codes to Chinese Clinical Notes', 'Pengfei Cao, Chenwei Yan, xiangling fu, Yubo Chen, Kang Liu, Jun Zhao, Shengping Liu and Weifeng Chong'], ['CLIReval: Evaluating Machine Translation as a Cross-Lingual Information Retrieval Task', 'Shuo Sun, Suzanna Sia and Kevin Duh'], ['Conversation Learner - A Machine Teaching Tool for Building Dialog Managers for Task-Oriented Dialog Systems', 'Swadheen Shukla, Lars Liden, Shahin Shayandeh, Eslam Kamal, Jinchao Li, Matt Mazzola, Thomas Park, Baolin Peng and Jianfeng Gao'], ['ConvLab-2: An Open-Source Toolkit for Building, Evaluating, and Diagnosing Dialogue Systems', 'Qi Zhu, Zheng Zhang, Yan Fang, Xiang Li, Ryuichi Takanobu, Jinchao Li, Baolin Peng, Jianfeng Gao, xiaoyan zhu and Minlie Huang'], ['DIALOGPT : Large-Scale Generative Pre-training for Conversational Response Generation', 'Yizhe Zhang, Siqi Sun, Michel Galley, Yen-Chun Chen, Chris Brockett, Xiang Gao, Jianfeng Gao, Jingjing Liu and Bill Dolan'], ['Embedding-based Scientific Literature Discovery in a Text Editor Application', 'Onur Gökçe, Jonathan Prada, Nikola Nikolov, Nianlong Gu and Richard Hahnloser'], ['ESPnet-ST: All-in-One Speech Translation Toolkit', 'Hirofumi Inaguma, Shun Kiyono, Kevin Duh, Shigeki Karita, Nelson Yalta, Tomoki Hayashi and Shinji Watanabe'], ['EVIDENCEMINER: Textual Evidence Discovery for Life Sciences', 'Xuan Wang, Yingjun Guan, Weili Liu, Aabhas Chauhan, Enyi Jiang, Qi Li, David Liem, Dibakar Sigdel, John Caufield, Peipei Ping and Jiawei Han'], ['exBERT: A Visual Analysis Tool to Explore Learned Representations in Transformer Models', 'Benjamin Hoover, Hendrik Strobelt and Sebastian Gehrmann'], ['GAIA: A Fine-grained Multimedia Knowledge Extraction System', 'Manling Li, Alireza Zareian, Ying Lin, Xiaoman Pan, Spencer Whitehead, BRIAN CHEN, Bo Wu, Heng Ji, Shih-Fu Chang, Clare Voss, Daniel Napierski and Marjorie Freedman'], ['Interactive Task Learning from GUI-Grounded Natural Language Instructions and Demonstrations', 'Toby Jia-Jun Li, Tom Mitchell and Brad Myers'], ['jiant: A Software Toolkit for Research on General-Purpose Text Understanding Models', 'Yada Pruksachatkun, Phil Yeres, Haokun Liu, Jason Phang, Phu Mon Htut, Alex Wang, Ian Tenney and Samuel R. Bowman'], ['Label Noise in Context', 'Michael Desmond, Catherine Finegan-Dollak, Jeff Boston and Matt Arnold'], ['LEAN-LIFE: A Label-Efficient Annotation Framework Towards Learning from Explanation', 'Dong-Ho Lee, Rahul Khanna, Bill Yuchen Lin, Seyeon Lee, Qinyuan Ye, Elizabeth Boschee, Leonardo Neves and Xiang Ren'], ['LinggleWrite: a Coaching System for Essay Writing', 'Chung-Ting Tsai, Jhih-Jie Chen, Chingyu Yang and Jason Chang'], ['MixingBoard: a Knowledgeable Stylized Integrated Text Generation Platform', 'Xiang Gao, Michel Galley and Bill Dolan'], ['MMPE: A Multi-Modal Interface using Handwriting, Touch Reordering, and Speech Commands for Post-Editing Machine Translation', 'Nico Herbig, Santanu Pal, Tim Düwel, Kalliopi Maria Meladaki, Mahsa Monshizadeh, Vladislav Hnatovskiy, Antonio Krüger and Josef van Genabith'], ['Multilingual Universal Sentence Encoder for Semantic Retrieval', 'Yinfei Yang, Daniel Cer, Amin Ahmad, Mandy Guo, Jax Law, Noah Constant, Gustavo Hernandez Abrego, Steve Yuan, Chris Tar, Yun-hsuan Sung, Brian Strope and Ray Kurzweil'], ['Nakdan: Professional Hebrew Diacritizer', 'Avi Shmidman, Shaltiel Shmidman, Moshe Koppel and Yoav Goldberg'], ['NLP Scholar: An Interactive Visual Explorer for Natural Language Processing Literature', 'Saif Mohammad'], ['NSTM: Real-Time Query-Driven News Overview Composition at Bloomberg', 'Joshua Bambrick, Minjie Xu, Andy Almonte, Igor Malioutov, Guim Perarnau, Vittorio Selo and Iat Chong Chan'], ['OpusFilter: A Configurable Parallel Corpus Filtering Toolbox', 'Mikko Aulamo, Sami Virpioja and Jörg Tiedemann'], ['Penman: An Open-Source Library and Tool for AMR Graphs', 'Michael Wayne Goodman'], ['Personalized PageRank with Syntagmatic Information for Multilingual Word Sense Disambiguation', 'Federico Scozzafava, Marco Maru, Fabrizio Brignone, Giovanni Torrisi and Roberto Navigli'], ['Photon: A Robust Cross-Domain Text-to-SQL System', 'Jichuan Zeng, Xi Victoria Lin, Steven C.H. Hoi, Richard Socher, Caiming Xiong, Michael Lyu and Irwin King'], ['Prta: A System to Support the Analysis of Propaganda Techniques in the News', 'Giovanni Da San Martino, Shaden Shaar, Yifan Zhang, Seunghak Yu, Alberto Barrón-Cedeño and Preslav Nakov'], ['pyBART: Evidence-based Syntactic Transformations for IE', 'Aryeh Tiktinsky, Yoav Goldberg and Reut Tsarfaty'], ['Stanza: A Python Natural Language Processing Toolkit for Many Human Languages', 'Peng Qi, Yuhao Zhang, Yuhui Zhang, Jason Bolton and Christopher D. Manning'], ['Stimulating Creativity with FunLines: A Case Study of Humor Generation in Headlines', 'Nabil Hossain, John Krumm, Tanvir Sajed and Henry Kautz'], ['SUPP.AI: finding evidence for supplement-drug interactions', 'Lucy Wang, Oyvind Tafjord, Arman Cohan, Sarthak Jain, Sam Skjonsberg, Carissa Schoenick, Nick Botner and Waleed Ammar'], ['Syntactic Search by Example', 'Micah Shlain, Hillel Taub-Tabib, Shoval Sadde and Yoav Goldberg'], ['SyntaxGym: An Online Platform for Targeted Evaluation of Language Models', 'Jon Gauthier, Jennifer Hu, Ethan Wilcox, Peng Qian and Roger Levy'], ['Tabouid: a Wikipedia-based word guessing game', 'Timothée Bernard'], ['Talk to Papers: Bringing Neural Question Answering to Academic Search', 'Tiancheng Zhao and Kyusong Lee'], ['TextBrewer: An Open-Source Knowledge Distillation Toolkit for Natural Language Processing', 'Ziqing Yang, Yiming Cui, Zhipeng Chen, Wanxiang Che, Ting Liu, Shijin Wang and Guoping Hu'], ['The Microsoft Toolkit of Multi-Task Deep Neural Networks for Natural Language Understanding', 'Xiaodong Liu, Yu Wang, Jianshu Ji, Hao Cheng, Xueyun Zhu, Emmanuel Awa, Pengcheng He, Weizhu Chen, Hoifung Poon, Guihong Cao and Jianfeng Gao'], ['Torch-Struct: Deep Structured Prediction Library', 'Alexander Rush'], ['Trialstreamer: Mapping and Browsing Medical Evidence in Real-Time', 'Benjamin Nye, Ani Nenkova, Iain Marshall and Byron C. Wallace'], ['Usnea: An Authorship Tool for Interactive Fiction using Retrieval Based Semantic Parsing', 'Ben Swanson and Boris Smus'], ['What’s The Latest? A Question-driven News Chatbot', 'Philippe Laban, John Canny and Marti A. Hearst'], ['Xiaomingbot: A Multilingual Robot News Reporter', 'Runxin Xu, Jun Cao, Mingxuan Wang, Jiaze Chen, Hao Zhou, Ying Zeng, Yuping Wang, Li Chen, Xiang Yin, Xijin Zhang, Songcheng Jiang, Yuxuan Wang and Lei Li']]\n",
            "multi search domain\n",
            "visual platform model\n",
            "clinic dialog chines\n",
            "news evalu open\n",
            "generat text translat\n",
            "base toolkit task\n",
            "interact languag natur\n",
            "languag toolkit natur\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TUjlRSPtCNRD",
        "colab_type": "text"
      },
      "source": [
        "# Search arXiv Link"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ws04-fbRCNRD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from googlesearch import search\n",
        "import urllib\n",
        "from bs4 import BeautifulSoup\n",
        "from difflib import SequenceMatcher\n",
        "from tqdm import tqdm\n",
        "import time\n",
        "\n",
        "def similarity(a, b):\n",
        "    return SequenceMatcher(None, a, b).ratio()\n",
        "\n",
        "\n",
        "def search_arxiv_link(title):\n",
        "    link = None\n",
        "    for j in search(title, tld=\"co.in\", num=10, stop=1, pause=1.0, user_agent=\"acl2020\"):\n",
        "        if 'arxiv.org/abs' in j:\n",
        "            thepage = urllib.request.urlopen(j)\n",
        "            soup = BeautifulSoup(thepage, \"html.parser\")\n",
        "            searched_title = ' '.join(soup.title.text.lower().split()[1:])\n",
        "            if similarity(title, searched_title) > 0.8:\n",
        "                link = j\n",
        "                break\n",
        "            else:\n",
        "                print(\"NOT MATCHED\")\n",
        "                print(title)\n",
        "                print(searched_title)\n",
        "    return link"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SAJu9189CNRF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def generate_paper_list_with_arxiv_link(f, papers):\n",
        "    for p in tqdm(papers):\n",
        "        title, authors = p\n",
        "        link = search_arxiv_link(title.lower())\n",
        "        if link:\n",
        "            f.write(f\"- {title} [[arXiv]]({link})\\n\")\n",
        "        else:\n",
        "            f.write(f\"- {title}\\n\")\n",
        "    f.write(\"\\n\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "796iR6xmLnMd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def generate_paper_list_with_arxiv_link_topic(f, papers):\n",
        "  topic_papers = list2topiclist(papers)\n",
        "  for topic in topic_papers:\n",
        "    f.write(\"### \" + topic + \"\\n\")\n",
        "    generate_paper_list_with_arxiv_link(f, topic_papers[topic])\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "11VvQQBRMZjY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "a2c99d6e-5237-46e8-a6dd-72f012af6553"
      },
      "source": [
        "with open(\"papers_with_arxiv_link_topic.md\", \"w\") as f:\n",
        "  f.write(\"## Long Papers\\n\\n\")\n",
        "  generate_paper_list_with_arxiv_link_topic(f, longp)\n",
        "  f.write(\"## Short Papers\\n\\n\")\n",
        "  generate_paper_list_with_arxiv_link_topic(f, short)\n",
        "  f.write(\"## System Demonstrations\\n\\n\")\n",
        "  generate_paper_list_with_arxiv_link_topic(f, demop)\n",
        "  f.write(\"## Student Research Workshop\\n\\n\")\n",
        "  generate_paper_list_with_arxiv_link_topic(f, student)\n"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "  0%|          | 0/69 [00:00<?, ?it/s]\u001b[A\n",
            "  1%|▏         | 1/69 [00:02<02:36,  2.30s/it]\u001b[A\n",
            "  3%|▎         | 2/69 [00:04<02:30,  2.24s/it]\u001b[A\n",
            "  4%|▍         | 3/69 [00:06<02:23,  2.17s/it]\u001b[A\n",
            "  6%|▌         | 4/69 [00:08<02:21,  2.18s/it]\u001b[A\n",
            "  7%|▋         | 5/69 [00:10<02:17,  2.15s/it]\u001b[A\n",
            "  9%|▊         | 6/69 [00:12<02:12,  2.10s/it]\u001b[A\n",
            " 10%|█         | 7/69 [00:15<02:18,  2.24s/it]\u001b[A\n",
            " 12%|█▏        | 8/69 [00:17<02:19,  2.28s/it]\u001b[A\n",
            " 13%|█▎        | 9/69 [00:19<02:15,  2.25s/it]\u001b[A\n",
            " 14%|█▍        | 10/69 [00:21<02:10,  2.21s/it]\u001b[A\n",
            " 16%|█▌        | 11/69 [00:24<02:06,  2.18s/it]\u001b[A\n",
            " 17%|█▋        | 12/69 [00:25<01:59,  2.10s/it]\u001b[A\n",
            " 19%|█▉        | 13/69 [00:27<01:55,  2.06s/it]\u001b[A\n",
            " 20%|██        | 14/69 [00:30<01:54,  2.09s/it]\u001b[A\n",
            " 22%|██▏       | 15/69 [00:32<01:53,  2.10s/it]\u001b[A\n",
            " 23%|██▎       | 16/69 [00:34<01:49,  2.07s/it]\u001b[A\n",
            " 25%|██▍       | 17/69 [00:36<01:46,  2.05s/it]\u001b[A\n",
            " 26%|██▌       | 18/69 [00:38<01:45,  2.07s/it]\u001b[A\n",
            " 28%|██▊       | 19/69 [00:40<01:48,  2.17s/it]\u001b[A\n",
            " 29%|██▉       | 20/69 [00:42<01:45,  2.16s/it]\u001b[A\n",
            " 30%|███       | 21/69 [00:44<01:41,  2.11s/it]\u001b[A\n",
            " 32%|███▏      | 22/69 [00:46<01:37,  2.07s/it]\u001b[A\n",
            " 33%|███▎      | 23/69 [00:48<01:34,  2.06s/it]\u001b[A\n",
            " 35%|███▍      | 24/69 [00:51<01:35,  2.12s/it]\u001b[A\n",
            " 36%|███▌      | 25/69 [00:53<01:30,  2.07s/it]\u001b[A\n",
            " 38%|███▊      | 26/69 [00:55<01:31,  2.12s/it]\u001b[A\n",
            " 39%|███▉      | 27/69 [00:57<01:29,  2.14s/it]\u001b[A\n",
            " 41%|████      | 28/69 [00:59<01:24,  2.06s/it]\u001b[A\n",
            " 42%|████▏     | 29/69 [01:01<01:21,  2.03s/it]\u001b[A\n",
            " 43%|████▎     | 30/69 [01:03<01:19,  2.04s/it]\u001b[A\n",
            " 45%|████▍     | 31/69 [01:05<01:18,  2.06s/it]\u001b[A\n",
            " 46%|████▋     | 32/69 [01:08<01:21,  2.20s/it]\u001b[A\n",
            " 48%|████▊     | 33/69 [01:10<01:18,  2.19s/it]\u001b[A\n",
            " 49%|████▉     | 34/69 [01:12<01:16,  2.18s/it]\u001b[A\n",
            " 51%|█████     | 35/69 [01:14<01:16,  2.26s/it]\u001b[A\n",
            " 52%|█████▏    | 36/69 [01:17<01:15,  2.30s/it]\u001b[A\n",
            " 54%|█████▎    | 37/69 [01:19<01:11,  2.24s/it]\u001b[A\n",
            " 55%|█████▌    | 38/69 [01:21<01:11,  2.30s/it]\u001b[A\n",
            " 57%|█████▋    | 39/69 [01:23<01:07,  2.24s/it]\u001b[A\n",
            " 58%|█████▊    | 40/69 [01:25<01:04,  2.21s/it]\u001b[A\n",
            " 59%|█████▉    | 41/69 [01:28<01:01,  2.19s/it]\u001b[A\n",
            " 61%|██████    | 42/69 [01:30<00:58,  2.15s/it]\u001b[A\n",
            " 62%|██████▏   | 43/69 [01:32<00:55,  2.13s/it]\u001b[A\n",
            " 64%|██████▍   | 44/69 [01:34<00:56,  2.25s/it]\u001b[A\n",
            " 65%|██████▌   | 45/69 [01:37<00:53,  2.25s/it]\u001b[A\n",
            " 67%|██████▋   | 46/69 [01:39<00:53,  2.34s/it]\u001b[A\n",
            " 68%|██████▊   | 47/69 [01:41<00:51,  2.34s/it]\u001b[A\n",
            " 70%|██████▉   | 48/69 [01:44<00:47,  2.27s/it]\u001b[A\n",
            " 71%|███████   | 49/69 [01:46<00:45,  2.26s/it]\u001b[A\n",
            " 72%|███████▏  | 50/69 [01:48<00:43,  2.32s/it]\u001b[A\n",
            " 74%|███████▍  | 51/69 [01:50<00:41,  2.28s/it]\u001b[A\n",
            " 75%|███████▌  | 52/69 [01:52<00:37,  2.18s/it]\u001b[A\n",
            " 77%|███████▋  | 53/69 [01:55<00:35,  2.22s/it]\u001b[A\n",
            " 78%|███████▊  | 54/69 [01:57<00:32,  2.16s/it]\u001b[A\n",
            " 80%|███████▉  | 55/69 [01:59<00:29,  2.08s/it]\u001b[A\n",
            " 81%|████████  | 56/69 [02:01<00:27,  2.11s/it]\u001b[A\n",
            " 83%|████████▎ | 57/69 [02:03<00:25,  2.14s/it]\u001b[A\n",
            " 84%|████████▍ | 58/69 [02:05<00:24,  2.21s/it]\u001b[A\n",
            " 86%|████████▌ | 59/69 [02:07<00:21,  2.13s/it]\u001b[A\n",
            " 87%|████████▋ | 60/69 [02:10<00:19,  2.21s/it]\u001b[A\n",
            " 88%|████████▊ | 61/69 [02:12<00:17,  2.15s/it]\u001b[A\n",
            " 90%|████████▉ | 62/69 [02:14<00:14,  2.07s/it]\u001b[A\n",
            " 91%|█████████▏| 63/69 [02:15<00:12,  2.01s/it]\u001b[A\n",
            " 93%|█████████▎| 64/69 [02:18<00:10,  2.12s/it]\u001b[A\n",
            " 94%|█████████▍| 65/69 [02:20<00:08,  2.16s/it]\u001b[A\n",
            " 96%|█████████▌| 66/69 [02:23<00:07,  2.47s/it]\u001b[A\n",
            " 97%|█████████▋| 67/69 [02:26<00:04,  2.47s/it]\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "NOT MATCHED\n",
            "zero-shot text classification via reinforced self-training\n",
            "integrating semantic knowledge to tackle zero-shot text classification\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            " 99%|█████████▊| 68/69 [02:28<00:02,  2.31s/it]\u001b[A\n",
            "100%|██████████| 69/69 [02:30<00:00,  2.18s/it]\n",
            "\n",
            "  0%|          | 0/73 [00:00<?, ?it/s]\u001b[A\n",
            "  1%|▏         | 1/73 [00:02<02:56,  2.45s/it]\u001b[A\n",
            "  3%|▎         | 2/73 [00:04<02:48,  2.38s/it]\u001b[A\n",
            "  4%|▍         | 3/73 [00:06<02:38,  2.26s/it]\u001b[A\n",
            "  5%|▌         | 4/73 [00:08<02:29,  2.16s/it]\u001b[A\n",
            "  7%|▋         | 5/73 [00:10<02:24,  2.13s/it]\u001b[A\n",
            "  8%|▊         | 6/73 [00:12<02:22,  2.12s/it]\u001b[A\n",
            " 10%|▉         | 7/73 [00:14<02:17,  2.08s/it]\u001b[A\n",
            " 11%|█         | 8/73 [00:17<02:22,  2.19s/it]\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "NOT MATCHED\n",
            "attentive pooling with learnable norms for text representation\n",
            "attentive pooling networks\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            " 12%|█▏        | 9/73 [00:19<02:21,  2.20s/it]\u001b[A\n",
            " 14%|█▎        | 10/73 [00:21<02:19,  2.21s/it]\u001b[A\n",
            " 15%|█▌        | 11/73 [00:23<02:16,  2.20s/it]\u001b[A\n",
            " 16%|█▋        | 12/73 [00:25<02:11,  2.16s/it]\u001b[A\n",
            " 18%|█▊        | 13/73 [00:28<02:10,  2.17s/it]\u001b[A\n",
            " 19%|█▉        | 14/73 [00:30<02:06,  2.15s/it]\u001b[A\n",
            " 21%|██        | 15/73 [00:32<02:11,  2.27s/it]\u001b[A\n",
            " 22%|██▏       | 16/73 [00:34<02:08,  2.25s/it]\u001b[A\n",
            " 23%|██▎       | 17/73 [00:37<02:04,  2.23s/it]\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "NOT MATCHED\n",
            "contextualized weak supervision for text classification\n",
            "weakly-supervised neural text classification\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            " 25%|██▍       | 18/73 [00:39<02:03,  2.25s/it]\u001b[A\n",
            " 26%|██▌       | 19/73 [00:41<01:59,  2.22s/it]\u001b[A\n",
            " 27%|██▋       | 20/73 [00:43<02:00,  2.27s/it]\u001b[A\n",
            " 29%|██▉       | 21/73 [00:46<01:55,  2.21s/it]\u001b[A\n",
            " 30%|███       | 22/73 [00:47<01:46,  2.09s/it]\u001b[A\n",
            " 32%|███▏      | 23/73 [00:50<01:47,  2.15s/it]\u001b[A\n",
            " 33%|███▎      | 24/73 [00:52<01:43,  2.10s/it]\u001b[A\n",
            " 34%|███▍      | 25/73 [00:54<01:45,  2.20s/it]\u001b[A\n",
            " 36%|███▌      | 26/73 [00:56<01:42,  2.17s/it]\u001b[A\n",
            " 37%|███▋      | 27/73 [00:58<01:39,  2.15s/it]\u001b[A\n",
            " 38%|███▊      | 28/73 [01:00<01:36,  2.15s/it]\u001b[A\n",
            " 40%|███▉      | 29/73 [01:03<01:40,  2.28s/it]\u001b[A\n",
            " 41%|████      | 30/73 [01:05<01:35,  2.23s/it]\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "NOT MATCHED\n",
            "explicit semantic decomposition for definition generation\n",
            "semantic composition and decomposition: from recognition to generation\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            " 42%|████▏     | 31/73 [01:07<01:34,  2.26s/it]\u001b[A\n",
            " 44%|████▍     | 32/73 [01:10<01:35,  2.34s/it]\u001b[A\n",
            " 45%|████▌     | 33/73 [01:12<01:32,  2.31s/it]\u001b[A\n",
            " 47%|████▋     | 34/73 [01:14<01:26,  2.23s/it]\u001b[A\n",
            " 48%|████▊     | 35/73 [01:16<01:23,  2.20s/it]\u001b[A\n",
            " 49%|████▉     | 36/73 [01:18<01:20,  2.16s/it]\u001b[A\n",
            " 51%|█████     | 37/73 [01:21<01:23,  2.33s/it]\u001b[A\n",
            " 52%|█████▏    | 38/73 [01:23<01:17,  2.20s/it]\u001b[A\n",
            " 53%|█████▎    | 39/73 [01:25<01:16,  2.24s/it]\u001b[A\n",
            " 55%|█████▍    | 40/73 [01:27<01:12,  2.20s/it]\u001b[A\n",
            " 56%|█████▌    | 41/73 [01:30<01:09,  2.17s/it]\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "NOT MATCHED\n",
            "learning constraints for structured prediction using rectifier networks\n",
            "adversarial constraint learning for structured prediction\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            " 58%|█████▊    | 42/73 [01:32<01:06,  2.16s/it]\u001b[A\n",
            " 59%|█████▉    | 43/73 [01:34<01:06,  2.23s/it]\u001b[A\n",
            " 60%|██████    | 44/73 [01:36<01:03,  2.19s/it]\u001b[A\n",
            " 62%|██████▏   | 45/73 [01:38<00:59,  2.11s/it]\u001b[A\n",
            " 63%|██████▎   | 46/73 [01:40<00:54,  2.03s/it]\u001b[A\n",
            " 64%|██████▍   | 47/73 [01:42<00:51,  1.98s/it]\u001b[A\n",
            " 66%|██████▌   | 48/73 [01:44<00:50,  2.02s/it]\u001b[A\n",
            " 67%|██████▋   | 49/73 [01:46<00:51,  2.13s/it]\u001b[A\n",
            " 68%|██████▊   | 50/73 [01:48<00:47,  2.07s/it]\u001b[A\n",
            " 70%|██████▉   | 51/73 [01:51<00:47,  2.14s/it]\u001b[A\n",
            " 71%|███████   | 52/73 [01:53<00:47,  2.26s/it]\u001b[A\n",
            " 73%|███████▎  | 53/73 [01:55<00:45,  2.26s/it]\u001b[A\n",
            " 74%|███████▍  | 54/73 [01:58<00:42,  2.24s/it]\u001b[A\n",
            " 75%|███████▌  | 55/73 [02:00<00:41,  2.29s/it]\u001b[A\n",
            " 77%|███████▋  | 56/73 [02:02<00:37,  2.21s/it]\u001b[A\n",
            " 78%|███████▊  | 57/73 [02:04<00:35,  2.21s/it]\u001b[A\n",
            " 79%|███████▉  | 58/73 [02:06<00:33,  2.22s/it]\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "NOT MATCHED\n",
            "relation-aware collaborative learning for unified aspect-based sentiment analysis\n",
            "an interactive multi-task learning network for end-to-end aspect-based sentiment analysis\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            " 81%|████████  | 59/73 [02:09<00:30,  2.21s/it]\u001b[A\n",
            " 82%|████████▏ | 60/73 [02:11<00:28,  2.18s/it]\u001b[A\n",
            " 84%|████████▎ | 61/73 [02:13<00:25,  2.13s/it]\u001b[A\n",
            " 85%|████████▍ | 62/73 [02:15<00:23,  2.13s/it]\u001b[A\n",
            " 86%|████████▋ | 63/73 [02:17<00:21,  2.12s/it]\u001b[A\n",
            " 88%|████████▊ | 64/73 [02:19<00:19,  2.16s/it]\u001b[A\n",
            " 89%|████████▉ | 65/73 [02:22<00:18,  2.34s/it]\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "NOT MATCHED\n",
            "spanmlt: a span-based multi-task learning framework for pair-wise aspect and opinion terms extraction\n",
            "an interactive multi-task learning network for end-to-end aspect-based sentiment analysis\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            " 90%|█████████ | 66/73 [02:24<00:16,  2.30s/it]\u001b[A\n",
            " 92%|█████████▏| 67/73 [02:26<00:13,  2.22s/it]\u001b[A\n",
            " 93%|█████████▎| 68/73 [02:28<00:11,  2.20s/it]\u001b[A\n",
            " 95%|█████████▍| 69/73 [02:30<00:08,  2.15s/it]\u001b[A\n",
            " 96%|█████████▌| 70/73 [02:33<00:06,  2.17s/it]\u001b[A\n",
            " 97%|█████████▋| 71/73 [02:35<00:04,  2.21s/it]\u001b[A\n",
            " 99%|█████████▊| 72/73 [02:37<00:02,  2.16s/it]\u001b[A\n",
            "100%|██████████| 73/73 [02:39<00:00,  2.19s/it]\n",
            "\n",
            "  0%|          | 0/71 [00:00<?, ?it/s]\u001b[A\n",
            "  1%|▏         | 1/71 [00:02<02:50,  2.43s/it]\u001b[A\n",
            "  3%|▎         | 2/71 [00:04<02:42,  2.35s/it]\u001b[A\n",
            "  4%|▍         | 3/71 [00:06<02:34,  2.28s/it]\u001b[A\n",
            "  6%|▌         | 4/71 [00:09<02:34,  2.31s/it]\u001b[A\n",
            "  7%|▋         | 5/71 [00:11<02:29,  2.26s/it]\u001b[A\n",
            "  8%|▊         | 6/71 [00:13<02:24,  2.22s/it]\u001b[A\n",
            " 10%|▉         | 7/71 [00:15<02:23,  2.24s/it]\u001b[A\n",
            " 11%|█▏        | 8/71 [00:18<02:23,  2.28s/it]\u001b[A\n",
            " 13%|█▎        | 9/71 [00:20<02:17,  2.22s/it]\u001b[A\n",
            " 14%|█▍        | 10/71 [00:21<02:09,  2.12s/it]\u001b[A\n",
            " 15%|█▌        | 11/71 [00:23<02:05,  2.09s/it]\u001b[A\n",
            " 17%|█▋        | 12/71 [00:26<02:04,  2.11s/it]\u001b[A\n",
            " 18%|█▊        | 13/71 [00:28<02:08,  2.22s/it]\u001b[A\n",
            " 20%|█▉        | 14/71 [00:30<02:05,  2.20s/it]\u001b[A\n",
            " 21%|██        | 15/71 [00:33<02:05,  2.24s/it]\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "NOT MATCHED\n",
            "curriculum learning for natural language understanding\n",
            "visualizing and understanding curriculum learning for long short-term memory networks\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            " 23%|██▎       | 16/71 [00:35<02:04,  2.27s/it]\u001b[A\n",
            " 24%|██▍       | 17/71 [00:37<02:00,  2.22s/it]\u001b[A\n",
            " 25%|██▌       | 18/71 [00:39<01:54,  2.16s/it]\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "NOT MATCHED\n",
            "distilling annotations via active imitation learning\n",
            "random expert distillation: imitation learning via expert policy support estimation\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            " 27%|██▋       | 19/71 [00:41<01:48,  2.08s/it]\u001b[A\n",
            " 28%|██▊       | 20/71 [00:43<01:46,  2.09s/it]\u001b[A\n",
            " 30%|██▉       | 21/71 [00:45<01:45,  2.11s/it]\u001b[A\n",
            " 31%|███       | 22/71 [00:48<01:48,  2.21s/it]\u001b[A\n",
            " 32%|███▏      | 23/71 [00:50<01:46,  2.22s/it]\u001b[A\n",
            " 34%|███▍      | 24/71 [00:52<01:43,  2.19s/it]\u001b[A\n",
            " 35%|███▌      | 25/71 [00:54<01:37,  2.13s/it]\u001b[A\n",
            " 37%|███▋      | 26/71 [00:56<01:35,  2.12s/it]\u001b[A\n",
            " 38%|███▊      | 27/71 [00:59<01:39,  2.27s/it]\u001b[A\n",
            " 39%|███▉      | 28/71 [01:01<01:36,  2.24s/it]\u001b[A\n",
            " 41%|████      | 29/71 [01:03<01:35,  2.27s/it]\u001b[A\n",
            " 42%|████▏     | 30/71 [01:05<01:31,  2.23s/it]\u001b[A\n",
            " 44%|████▎     | 31/71 [01:07<01:26,  2.16s/it]\u001b[A\n",
            " 45%|████▌     | 32/71 [01:10<01:28,  2.27s/it]\u001b[A\n",
            " 46%|████▋     | 33/71 [01:12<01:25,  2.25s/it]\u001b[A\n",
            " 48%|████▊     | 34/71 [01:14<01:20,  2.17s/it]\u001b[A\n",
            " 49%|████▉     | 35/71 [01:16<01:17,  2.16s/it]\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "NOT MATCHED\n",
            "improving disentangled text representation learning with information-theoretic guidance\n",
            "improving disentangled representation learning with the beta bernoulli process\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            " 51%|█████     | 36/71 [01:19<01:17,  2.20s/it]\u001b[A\n",
            " 52%|█████▏    | 37/71 [01:21<01:13,  2.18s/it]\u001b[A\n",
            " 54%|█████▎    | 38/71 [01:23<01:10,  2.15s/it]\u001b[A\n",
            " 55%|█████▍    | 39/71 [01:25<01:07,  2.09s/it]\u001b[A\n",
            " 56%|█████▋    | 40/71 [01:27<01:02,  2.02s/it]\u001b[A\n",
            " 58%|█████▊    | 41/71 [01:29<01:01,  2.05s/it]\u001b[A\n",
            " 59%|█████▉    | 42/71 [01:31<01:00,  2.08s/it]\u001b[A\n",
            " 61%|██████    | 43/71 [01:33<00:58,  2.09s/it]\u001b[A\n",
            " 62%|██████▏   | 44/71 [01:35<00:55,  2.07s/it]\u001b[A\n",
            " 63%|██████▎   | 45/71 [01:37<00:52,  2.02s/it]\u001b[A\n",
            " 65%|██████▍   | 46/71 [01:39<00:52,  2.11s/it]\u001b[A\n",
            " 66%|██████▌   | 47/71 [01:41<00:50,  2.12s/it]\u001b[A\n",
            " 68%|██████▊   | 48/71 [01:44<00:49,  2.13s/it]\u001b[A\n",
            " 69%|██████▉   | 49/71 [01:46<00:47,  2.14s/it]\u001b[A\n",
            " 70%|███████   | 50/71 [01:48<00:44,  2.13s/it]\u001b[A\n",
            " 72%|███████▏  | 51/71 [01:50<00:41,  2.09s/it]\u001b[A\n",
            " 73%|███████▎  | 52/71 [01:52<00:41,  2.16s/it]\u001b[A\n",
            " 75%|███████▍  | 53/71 [01:54<00:38,  2.14s/it]\u001b[A\n",
            " 76%|███████▌  | 54/71 [01:56<00:36,  2.14s/it]\u001b[A\n",
            " 77%|███████▋  | 55/71 [01:58<00:34,  2.14s/it]\u001b[A\n",
            " 79%|███████▉  | 56/71 [02:01<00:32,  2.17s/it]\u001b[A\n",
            " 80%|████████  | 57/71 [02:03<00:30,  2.16s/it]\u001b[A\n",
            " 82%|████████▏ | 58/71 [02:05<00:27,  2.11s/it]\u001b[A\n",
            " 83%|████████▎ | 59/71 [02:07<00:26,  2.21s/it]\u001b[A\n",
            " 85%|████████▍ | 60/71 [02:10<00:24,  2.26s/it]\u001b[A\n",
            " 86%|████████▌ | 61/71 [02:12<00:22,  2.21s/it]\u001b[A\n",
            " 87%|████████▋ | 62/71 [02:14<00:20,  2.28s/it]\u001b[A\n",
            " 89%|████████▊ | 63/71 [02:16<00:18,  2.26s/it]\u001b[A\n",
            " 90%|█████████ | 64/71 [02:19<00:15,  2.26s/it]\u001b[A\n",
            " 92%|█████████▏| 65/71 [02:21<00:13,  2.22s/it]\u001b[A\n",
            " 93%|█████████▎| 66/71 [02:23<00:11,  2.23s/it]\u001b[A\n",
            " 94%|█████████▍| 67/71 [02:25<00:08,  2.23s/it]\u001b[A\n",
            " 96%|█████████▌| 68/71 [02:28<00:06,  2.22s/it]\u001b[A\n",
            " 97%|█████████▋| 69/71 [02:30<00:04,  2.18s/it]\u001b[A\n",
            " 99%|█████████▊| 70/71 [02:32<00:02,  2.15s/it]\u001b[A\n",
            "100%|██████████| 71/71 [02:34<00:00,  2.17s/it]\n",
            "\n",
            "  0%|          | 0/66 [00:00<?, ?it/s]\u001b[A\n",
            "  2%|▏         | 1/66 [00:01<02:05,  1.93s/it]\u001b[A\n",
            "  3%|▎         | 2/66 [00:03<02:02,  1.91s/it]\u001b[A\n",
            "  5%|▍         | 3/66 [00:05<02:02,  1.94s/it]\u001b[A\n",
            "  6%|▌         | 4/66 [00:07<02:03,  1.99s/it]\u001b[A\n",
            "  8%|▊         | 5/66 [00:10<02:09,  2.12s/it]\u001b[A\n",
            "  9%|▉         | 6/66 [00:13<02:24,  2.41s/it]\u001b[A\n",
            " 11%|█         | 7/66 [00:15<02:12,  2.25s/it]\u001b[A\n",
            " 12%|█▏        | 8/66 [00:17<02:08,  2.22s/it]\u001b[A\n",
            " 14%|█▎        | 9/66 [00:19<02:04,  2.19s/it]\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "NOT MATCHED\n",
            "bilingual dictionary based neural machine translation without using parallel sentences\n",
            "bridging neural machine translation and bilingual dictionaries\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            " 15%|█▌        | 10/66 [00:21<01:57,  2.10s/it]\u001b[A\n",
            " 17%|█▋        | 11/66 [00:23<01:52,  2.05s/it]\u001b[A\n",
            " 18%|█▊        | 12/66 [00:25<01:48,  2.01s/it]\u001b[A\n",
            " 20%|█▉        | 13/66 [00:27<01:47,  2.03s/it]\u001b[A\n",
            " 21%|██        | 14/66 [00:29<01:47,  2.07s/it]\u001b[A\n",
            " 23%|██▎       | 15/66 [00:31<01:49,  2.14s/it]\u001b[A\n",
            " 24%|██▍       | 16/66 [00:34<01:50,  2.20s/it]\u001b[A\n",
            " 26%|██▌       | 17/66 [00:36<01:46,  2.17s/it]\u001b[A\n",
            " 27%|██▋       | 18/66 [00:38<01:41,  2.11s/it]\u001b[A\n",
            " 29%|██▉       | 19/66 [00:40<01:35,  2.04s/it]\u001b[A\n",
            " 30%|███       | 20/66 [00:42<01:35,  2.07s/it]\u001b[A\n",
            " 32%|███▏      | 21/66 [00:44<01:37,  2.17s/it]\u001b[A\n",
            " 33%|███▎      | 22/66 [00:46<01:35,  2.17s/it]\u001b[A\n",
            " 35%|███▍      | 23/66 [00:48<01:32,  2.14s/it]\u001b[A\n",
            " 36%|███▋      | 24/66 [00:51<01:30,  2.16s/it]\u001b[A\n",
            " 38%|███▊      | 25/66 [00:53<01:26,  2.11s/it]\u001b[A\n",
            " 39%|███▉      | 26/66 [00:55<01:26,  2.15s/it]\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "NOT MATCHED\n",
            "graph neural news recommendation with unsupervised preference disentanglement\n",
            "graph neural news recommendation with long-term and short-term interest modeling\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            " 41%|████      | 27/66 [00:57<01:22,  2.13s/it]\u001b[A\n",
            " 42%|████▏     | 28/66 [00:59<01:19,  2.10s/it]\u001b[A\n",
            " 44%|████▍     | 29/66 [01:01<01:17,  2.11s/it]\u001b[A\n",
            " 45%|████▌     | 30/66 [01:03<01:14,  2.07s/it]\u001b[A\n",
            " 47%|████▋     | 31/66 [01:05<01:14,  2.14s/it]\u001b[A\n",
            " 48%|████▊     | 32/66 [01:07<01:11,  2.10s/it]\u001b[A\n",
            " 50%|█████     | 33/66 [01:10<01:18,  2.37s/it]\u001b[A\n",
            " 52%|█████▏    | 34/66 [01:12<01:10,  2.21s/it]\u001b[A\n",
            " 53%|█████▎    | 35/66 [01:14<01:06,  2.15s/it]\u001b[A\n",
            " 55%|█████▍    | 36/66 [01:16<01:02,  2.07s/it]\u001b[A\n",
            " 56%|█████▌    | 37/66 [01:18<01:00,  2.07s/it]\u001b[A\n",
            " 58%|█████▊    | 38/66 [01:20<00:58,  2.09s/it]\u001b[A\n",
            " 59%|█████▉    | 39/66 [01:22<00:55,  2.06s/it]\u001b[A\n",
            " 61%|██████    | 40/66 [01:24<00:54,  2.10s/it]\u001b[A\n",
            " 62%|██████▏   | 41/66 [01:27<00:53,  2.13s/it]\u001b[A\n",
            " 64%|██████▎   | 42/66 [01:29<00:50,  2.10s/it]\u001b[A\n",
            " 65%|██████▌   | 43/66 [01:31<00:48,  2.11s/it]\u001b[A\n",
            " 67%|██████▋   | 44/66 [01:33<00:45,  2.07s/it]\u001b[A\n",
            " 68%|██████▊   | 45/66 [01:35<00:46,  2.21s/it]\u001b[A\n",
            " 70%|██████▉   | 46/66 [01:37<00:43,  2.17s/it]\u001b[A\n",
            " 71%|███████   | 47/66 [01:39<00:40,  2.11s/it]\u001b[A\n",
            " 73%|███████▎  | 48/66 [01:42<00:38,  2.15s/it]\u001b[A\n",
            " 74%|███████▍  | 49/66 [01:44<00:36,  2.15s/it]\u001b[A\n",
            " 76%|███████▌  | 50/66 [01:46<00:33,  2.07s/it]\u001b[A\n",
            " 77%|███████▋  | 51/66 [01:48<00:32,  2.15s/it]\u001b[A\n",
            " 79%|███████▉  | 52/66 [01:50<00:31,  2.23s/it]\u001b[A\n",
            " 80%|████████  | 53/66 [01:53<00:28,  2.20s/it]\u001b[A\n",
            " 82%|████████▏ | 54/66 [01:55<00:26,  2.18s/it]\u001b[A\n",
            " 83%|████████▎ | 55/66 [01:57<00:24,  2.20s/it]\u001b[A\n",
            " 85%|████████▍ | 56/66 [01:59<00:21,  2.17s/it]\u001b[A\n",
            " 86%|████████▋ | 57/66 [02:02<00:20,  2.28s/it]\u001b[A\n",
            " 88%|████████▊ | 58/66 [02:04<00:18,  2.27s/it]\u001b[A\n",
            " 89%|████████▉ | 59/66 [02:06<00:15,  2.20s/it]\u001b[A\n",
            " 91%|█████████ | 60/66 [02:09<00:14,  2.35s/it]\u001b[A\n",
            " 92%|█████████▏| 61/66 [02:11<00:11,  2.36s/it]\u001b[A\n",
            " 94%|█████████▍| 62/66 [02:13<00:09,  2.31s/it]\u001b[A\n",
            " 95%|█████████▌| 63/66 [02:15<00:06,  2.29s/it]\u001b[A\n",
            " 97%|█████████▋| 64/66 [02:18<00:04,  2.37s/it]\u001b[A\n",
            " 98%|█████████▊| 65/66 [02:20<00:02,  2.31s/it]\u001b[A\n",
            "100%|██████████| 66/66 [02:22<00:00,  2.16s/it]\n",
            "\n",
            "  0%|          | 0/45 [00:00<?, ?it/s]\u001b[A\n",
            "  2%|▏         | 1/45 [00:02<01:28,  2.01s/it]\u001b[A\n",
            "  4%|▍         | 2/45 [00:04<01:30,  2.09s/it]\u001b[A\n",
            "  7%|▋         | 3/45 [00:06<01:28,  2.10s/it]\u001b[A\n",
            "  9%|▉         | 4/45 [00:08<01:27,  2.13s/it]\u001b[A\n",
            " 11%|█         | 5/45 [00:10<01:24,  2.11s/it]\u001b[A\n",
            " 13%|█▎        | 6/45 [00:12<01:20,  2.06s/it]\u001b[A\n",
            " 16%|█▌        | 7/45 [00:14<01:20,  2.11s/it]\u001b[A\n",
            " 18%|█▊        | 8/45 [00:16<01:17,  2.11s/it]\u001b[A\n",
            " 20%|██        | 9/45 [00:19<01:17,  2.15s/it]\u001b[A\n",
            " 22%|██▏       | 10/45 [00:21<01:14,  2.11s/it]\u001b[A\n",
            " 24%|██▍       | 11/45 [00:23<01:12,  2.15s/it]\u001b[A\n",
            " 27%|██▋       | 12/45 [00:25<01:11,  2.17s/it]\u001b[A\n",
            " 29%|██▉       | 13/45 [00:27<01:10,  2.19s/it]\u001b[A\n",
            " 31%|███       | 14/45 [00:30<01:07,  2.19s/it]\u001b[A\n",
            " 33%|███▎      | 15/45 [00:32<01:04,  2.16s/it]\u001b[A\n",
            " 36%|███▌      | 16/45 [00:34<01:06,  2.29s/it]\u001b[A\n",
            " 38%|███▊      | 17/45 [00:36<01:01,  2.19s/it]\u001b[A\n",
            " 40%|████      | 18/45 [00:38<00:58,  2.18s/it]\u001b[A\n",
            " 42%|████▏     | 19/45 [00:40<00:54,  2.10s/it]\u001b[A\n",
            " 44%|████▍     | 20/45 [00:43<00:53,  2.15s/it]\u001b[A\n",
            " 47%|████▋     | 21/45 [00:44<00:49,  2.07s/it]\u001b[A\n",
            " 49%|████▉     | 22/45 [00:47<00:47,  2.07s/it]\u001b[A\n",
            " 51%|█████     | 23/45 [00:48<00:44,  2.00s/it]\u001b[A\n",
            " 53%|█████▎    | 24/45 [00:50<00:41,  1.97s/it]\u001b[A\n",
            " 56%|█████▌    | 25/45 [00:53<00:41,  2.08s/it]\u001b[A\n",
            " 58%|█████▊    | 26/45 [00:55<00:39,  2.07s/it]\u001b[A\n",
            " 60%|██████    | 27/45 [00:56<00:35,  2.00s/it]\u001b[A\n",
            " 62%|██████▏   | 28/45 [00:58<00:33,  1.98s/it]\u001b[A\n",
            " 64%|██████▍   | 29/45 [01:01<00:33,  2.11s/it]\u001b[A\n",
            " 67%|██████▋   | 30/45 [01:03<00:32,  2.19s/it]\u001b[A\n",
            " 69%|██████▉   | 31/45 [01:05<00:29,  2.14s/it]\u001b[A\n",
            " 71%|███████   | 32/45 [01:07<00:27,  2.13s/it]\u001b[A\n",
            " 73%|███████▎  | 33/45 [01:10<00:27,  2.26s/it]\u001b[A\n",
            " 76%|███████▌  | 34/45 [01:12<00:25,  2.28s/it]\u001b[A\n",
            " 78%|███████▊  | 35/45 [01:14<00:22,  2.23s/it]\u001b[A\n",
            " 80%|████████  | 36/45 [01:16<00:19,  2.20s/it]\u001b[A\n",
            " 82%|████████▏ | 37/45 [01:19<00:18,  2.34s/it]\u001b[A\n",
            " 84%|████████▍ | 38/45 [01:21<00:15,  2.28s/it]\u001b[A\n",
            " 87%|████████▋ | 39/45 [01:23<00:12,  2.15s/it]\u001b[A\n",
            " 89%|████████▉ | 40/45 [01:25<00:10,  2.14s/it]\u001b[A\n",
            " 91%|█████████ | 41/45 [01:28<00:08,  2.24s/it]\u001b[A\n",
            " 93%|█████████▎| 42/45 [01:30<00:06,  2.24s/it]\u001b[A\n",
            " 96%|█████████▌| 43/45 [01:32<00:04,  2.27s/it]\u001b[A\n",
            " 98%|█████████▊| 44/45 [01:35<00:02,  2.26s/it]\u001b[A\n",
            "100%|██████████| 45/45 [01:37<00:00,  2.17s/it]\n",
            "\n",
            "  0%|          | 0/74 [00:00<?, ?it/s]\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "NOT MATCHED\n",
            "unknown intent detection using gaussian mixture model with an application to zero-shot intent classification\n",
            "zero-shot user intent detection via capsule neural networks\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "  1%|▏         | 1/74 [00:02<02:31,  2.08s/it]\u001b[A\n",
            "  3%|▎         | 2/74 [00:04<02:33,  2.14s/it]\u001b[A\n",
            "  4%|▍         | 3/74 [00:06<02:24,  2.03s/it]\u001b[A\n",
            "  5%|▌         | 4/74 [00:08<02:26,  2.09s/it]\u001b[A\n",
            "  7%|▋         | 5/74 [00:10<02:23,  2.09s/it]\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "NOT MATCHED\n",
            "adaptive compression of word embeddings\n",
            "online embedding compression for text classification using low rank matrix factorization\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "  8%|▊         | 6/74 [00:12<02:20,  2.07s/it]\u001b[A\n",
            "  9%|▉         | 7/74 [00:14<02:18,  2.07s/it]\u001b[A\n",
            " 11%|█         | 8/74 [00:18<02:49,  2.56s/it]\u001b[A\n",
            " 12%|█▏        | 9/74 [00:20<02:42,  2.50s/it]\u001b[A\n",
            " 14%|█▎        | 10/74 [00:22<02:33,  2.40s/it]\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "NOT MATCHED\n",
            "cross-lingual unsupervised sentiment classification with multi-view transfer learning\n",
            "multi-source cross-lingual model transfer: learning what to share\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            " 15%|█▍        | 11/74 [00:24<02:26,  2.33s/it]\u001b[A\n",
            " 16%|█▌        | 12/74 [00:27<02:24,  2.33s/it]\u001b[A\n",
            " 18%|█▊        | 13/74 [00:29<02:16,  2.24s/it]\u001b[A\n",
            " 19%|█▉        | 14/74 [00:31<02:09,  2.15s/it]\u001b[A\n",
            " 20%|██        | 15/74 [00:33<02:10,  2.21s/it]\u001b[A\n",
            " 22%|██▏       | 16/74 [00:36<02:19,  2.40s/it]\u001b[A\n",
            " 23%|██▎       | 17/74 [00:38<02:09,  2.28s/it]\u001b[A\n",
            " 24%|██▍       | 18/74 [00:41<02:16,  2.43s/it]\u001b[A\n",
            " 26%|██▌       | 19/74 [00:43<02:06,  2.30s/it]\u001b[A\n",
            " 27%|██▋       | 20/74 [00:45<02:03,  2.29s/it]\u001b[A\n",
            " 28%|██▊       | 21/74 [00:47<01:58,  2.24s/it]\u001b[A\n",
            " 30%|██▉       | 22/74 [00:50<01:59,  2.30s/it]\u001b[A\n",
            " 31%|███       | 23/74 [00:52<01:56,  2.29s/it]\u001b[A\n",
            " 32%|███▏      | 24/74 [00:54<01:47,  2.15s/it]\u001b[A\n",
            " 34%|███▍      | 25/74 [00:56<01:53,  2.31s/it]\u001b[A\n",
            " 35%|███▌      | 26/74 [00:58<01:48,  2.26s/it]\u001b[A\n",
            " 36%|███▋      | 27/74 [01:00<01:42,  2.19s/it]\u001b[A\n",
            " 38%|███▊      | 28/74 [01:03<01:40,  2.19s/it]\u001b[A\n",
            " 39%|███▉      | 29/74 [01:05<01:40,  2.23s/it]\u001b[A\n",
            " 41%|████      | 30/74 [01:07<01:34,  2.15s/it]\u001b[A\n",
            " 42%|████▏     | 31/74 [01:09<01:33,  2.17s/it]\u001b[A\n",
            " 43%|████▎     | 32/74 [01:11<01:32,  2.20s/it]\u001b[A\n",
            " 45%|████▍     | 33/74 [01:14<01:33,  2.28s/it]\u001b[A\n",
            " 46%|████▌     | 34/74 [01:16<01:33,  2.34s/it]\u001b[A\n",
            " 47%|████▋     | 35/74 [01:18<01:28,  2.26s/it]\u001b[A\n",
            " 49%|████▊     | 36/74 [01:21<01:24,  2.21s/it]\u001b[A\n",
            " 50%|█████     | 37/74 [01:23<01:19,  2.16s/it]\u001b[A\n",
            " 51%|█████▏    | 38/74 [01:25<01:15,  2.09s/it]\u001b[A\n",
            " 53%|█████▎    | 39/74 [01:27<01:14,  2.14s/it]\u001b[A\n",
            " 54%|█████▍    | 40/74 [01:29<01:11,  2.11s/it]\u001b[A\n",
            " 55%|█████▌    | 41/74 [01:31<01:13,  2.23s/it]\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "NOT MATCHED\n",
            "meta-reinforced multi-domain state generator for dialogue systems\n",
            "transferable multi-domain state generator for task-oriented dialogue systems\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            " 57%|█████▋    | 42/74 [01:33<01:07,  2.11s/it]\u001b[A\n",
            " 58%|█████▊    | 43/74 [01:35<01:05,  2.11s/it]\u001b[A\n",
            " 59%|█████▉    | 44/74 [01:37<01:04,  2.13s/it]\u001b[A\n",
            " 61%|██████    | 45/74 [01:40<01:04,  2.22s/it]\u001b[A\n",
            " 62%|██████▏   | 46/74 [01:42<00:58,  2.09s/it]\u001b[A\n",
            " 64%|██████▎   | 47/74 [01:44<01:00,  2.24s/it]\u001b[A\n",
            " 65%|██████▍   | 48/74 [01:47<00:59,  2.30s/it]\u001b[A\n",
            " 66%|██████▌   | 49/74 [01:49<00:56,  2.28s/it]\u001b[A\n",
            " 68%|██████▊   | 50/74 [01:51<00:52,  2.19s/it]\u001b[A\n",
            " 69%|██████▉   | 51/74 [01:53<00:50,  2.18s/it]\u001b[A\n",
            " 70%|███████   | 52/74 [01:57<00:56,  2.56s/it]\u001b[A\n",
            " 72%|███████▏  | 53/74 [01:59<00:50,  2.40s/it]\u001b[A\n",
            " 73%|███████▎  | 54/74 [02:01<00:46,  2.34s/it]\u001b[A\n",
            " 74%|███████▍  | 55/74 [02:03<00:42,  2.22s/it]\u001b[A\n",
            " 76%|███████▌  | 56/74 [02:05<00:39,  2.20s/it]\u001b[A\n",
            " 77%|███████▋  | 57/74 [02:07<00:37,  2.19s/it]\u001b[A\n",
            " 78%|███████▊  | 58/74 [02:09<00:35,  2.20s/it]\u001b[A\n",
            " 80%|███████▉  | 59/74 [02:11<00:32,  2.16s/it]\u001b[A\n",
            " 81%|████████  | 60/74 [02:13<00:29,  2.14s/it]\u001b[A\n",
            " 82%|████████▏ | 61/74 [02:16<00:27,  2.14s/it]\u001b[A\n",
            " 84%|████████▍ | 62/74 [02:18<00:25,  2.12s/it]\u001b[A\n",
            " 85%|████████▌ | 63/74 [02:20<00:23,  2.10s/it]\u001b[A\n",
            " 86%|████████▋ | 64/74 [02:22<00:22,  2.22s/it]\u001b[A\n",
            " 88%|████████▊ | 65/74 [02:24<00:19,  2.14s/it]\u001b[A\n",
            " 89%|████████▉ | 66/74 [02:26<00:17,  2.15s/it]\u001b[A\n",
            " 91%|█████████ | 67/74 [02:28<00:14,  2.13s/it]\u001b[A\n",
            " 92%|█████████▏| 68/74 [02:30<00:12,  2.10s/it]\u001b[A\n",
            " 93%|█████████▎| 69/74 [02:32<00:10,  2.07s/it]\u001b[A\n",
            " 95%|█████████▍| 70/74 [02:35<00:08,  2.08s/it]\u001b[A\n",
            " 96%|█████████▌| 71/74 [02:37<00:06,  2.11s/it]\u001b[A\n",
            " 97%|█████████▋| 72/74 [02:39<00:04,  2.08s/it]\u001b[A\n",
            " 99%|█████████▊| 73/74 [02:41<00:02,  2.14s/it]\u001b[A\n",
            "100%|██████████| 74/74 [02:43<00:00,  2.21s/it]\n",
            "\n",
            "  0%|          | 0/89 [00:00<?, ?it/s]\u001b[A\n",
            "  1%|          | 1/89 [00:01<02:50,  1.94s/it]\u001b[A\n",
            "  2%|▏         | 2/89 [00:04<02:52,  1.98s/it]\u001b[A\n",
            "  3%|▎         | 3/89 [00:06<02:54,  2.03s/it]\u001b[A\n",
            "  4%|▍         | 4/89 [00:08<02:52,  2.02s/it]\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "NOT MATCHED\n",
            "addressing posterior collapse with mutual information for improved variational neural machine translation\n",
            "improved variational neural machine translation by promoting mutual information\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "  6%|▌         | 5/89 [00:10<02:51,  2.04s/it]\u001b[A\n",
            "  7%|▋         | 6/89 [00:12<02:50,  2.05s/it]\u001b[A\n",
            "  8%|▊         | 7/89 [00:14<02:50,  2.08s/it]\u001b[A\n",
            "  9%|▉         | 8/89 [00:17<02:59,  2.22s/it]\u001b[A\n",
            " 10%|█         | 9/89 [00:19<03:00,  2.26s/it]\u001b[A\n",
            " 11%|█         | 10/89 [00:21<02:53,  2.19s/it]\u001b[A\n",
            " 12%|█▏        | 11/89 [00:24<03:01,  2.33s/it]\u001b[A\n",
            " 13%|█▎        | 12/89 [00:26<03:03,  2.38s/it]\u001b[A\n",
            " 15%|█▍        | 13/89 [00:28<02:54,  2.30s/it]\u001b[A\n",
            " 16%|█▌        | 14/89 [00:30<02:45,  2.21s/it]\u001b[A\n",
            " 17%|█▋        | 15/89 [00:33<02:49,  2.29s/it]\u001b[A\n",
            " 18%|█▊        | 16/89 [00:35<02:46,  2.28s/it]\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "NOT MATCHED\n",
            "ecpe-2d: emotion-cause pair extraction based on joint two-dimensional representation, interaction and prediction\n",
            "emotion-cause pair extraction: a new task to emotion analysis in texts\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            " 19%|█▉        | 17/89 [00:37<02:42,  2.26s/it]\u001b[A\n",
            " 20%|██        | 18/89 [00:39<02:39,  2.25s/it]\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "NOT MATCHED\n",
            "effective inter-clause modeling for end-to-end emotion-cause pair extraction\n",
            "end-to-end emotion-cause pair extraction via learning to link\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            " 21%|██▏       | 19/89 [00:41<02:28,  2.12s/it]\u001b[A\n",
            " 22%|██▏       | 20/89 [00:43<02:23,  2.08s/it]\u001b[A\n",
            " 24%|██▎       | 21/89 [00:45<02:19,  2.05s/it]\u001b[A\n",
            " 25%|██▍       | 22/89 [00:48<02:31,  2.27s/it]\u001b[A\n",
            " 26%|██▌       | 23/89 [00:50<02:23,  2.18s/it]\u001b[A\n",
            " 27%|██▋       | 24/89 [00:52<02:22,  2.19s/it]\u001b[A\n",
            " 28%|██▊       | 25/89 [00:54<02:22,  2.22s/it]\u001b[A\n",
            " 29%|██▉       | 26/89 [00:57<02:20,  2.23s/it]\u001b[A\n",
            " 30%|███       | 27/89 [00:59<02:22,  2.30s/it]\u001b[A\n",
            " 31%|███▏      | 28/89 [01:01<02:17,  2.25s/it]\u001b[A\n",
            " 33%|███▎      | 29/89 [01:04<02:19,  2.33s/it]\u001b[A\n",
            " 34%|███▎      | 30/89 [01:07<02:25,  2.47s/it]\u001b[A\n",
            " 35%|███▍      | 31/89 [01:08<02:12,  2.29s/it]\u001b[A\n",
            " 36%|███▌      | 32/89 [01:10<02:04,  2.18s/it]\u001b[A\n",
            " 37%|███▋      | 33/89 [01:13<02:03,  2.21s/it]\u001b[A\n",
            " 38%|███▊      | 34/89 [01:15<02:01,  2.21s/it]\u001b[A\n",
            " 39%|███▉      | 35/89 [01:18<02:11,  2.43s/it]\u001b[A\n",
            " 40%|████      | 36/89 [01:20<02:04,  2.35s/it]\u001b[A\n",
            " 42%|████▏     | 37/89 [01:22<01:55,  2.23s/it]\u001b[A\n",
            " 43%|████▎     | 38/89 [01:24<01:48,  2.13s/it]\u001b[A\n",
            " 44%|████▍     | 39/89 [01:26<01:45,  2.11s/it]\u001b[A\n",
            " 45%|████▍     | 40/89 [01:28<01:44,  2.12s/it]\u001b[A\n",
            " 46%|████▌     | 41/89 [01:30<01:42,  2.13s/it]\u001b[A\n",
            " 47%|████▋     | 42/89 [01:32<01:38,  2.11s/it]\u001b[A\n",
            " 48%|████▊     | 43/89 [01:34<01:34,  2.04s/it]\u001b[A\n",
            " 49%|████▉     | 44/89 [01:36<01:31,  2.04s/it]\u001b[A\n",
            " 51%|█████     | 45/89 [01:38<01:31,  2.08s/it]\u001b[A\n",
            " 52%|█████▏    | 46/89 [01:41<01:31,  2.12s/it]\u001b[A\n",
            " 53%|█████▎    | 47/89 [01:43<01:36,  2.30s/it]\u001b[A\n",
            " 54%|█████▍    | 48/89 [01:46<01:36,  2.36s/it]\u001b[A\n",
            " 55%|█████▌    | 49/89 [01:48<01:30,  2.27s/it]\u001b[A\n",
            " 56%|█████▌    | 50/89 [01:50<01:27,  2.25s/it]\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "NOT MATCHED\n",
            "predicting the topical stance and political leaning of media using tweets\n",
            "predicting the topical stance of media and popular twitter users\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            " 57%|█████▋    | 51/89 [01:52<01:24,  2.21s/it]\u001b[A\n",
            " 58%|█████▊    | 52/89 [01:54<01:18,  2.13s/it]\u001b[A\n",
            " 60%|█████▉    | 53/89 [01:56<01:18,  2.17s/it]\u001b[A\n",
            " 61%|██████    | 54/89 [01:58<01:16,  2.17s/it]\u001b[A\n",
            " 62%|██████▏   | 55/89 [02:01<01:15,  2.21s/it]\u001b[A\n",
            " 63%|██████▎   | 56/89 [02:03<01:11,  2.17s/it]\u001b[A\n",
            " 64%|██████▍   | 57/89 [02:05<01:09,  2.16s/it]\u001b[A\n",
            " 65%|██████▌   | 58/89 [02:07<01:05,  2.11s/it]\u001b[A\n",
            " 66%|██████▋   | 59/89 [02:09<01:03,  2.11s/it]\u001b[A\n",
            " 67%|██████▋   | 60/89 [02:11<01:01,  2.12s/it]\u001b[A\n",
            " 69%|██████▊   | 61/89 [02:13<00:59,  2.11s/it]\u001b[A\n",
            " 70%|██████▉   | 62/89 [02:16<01:00,  2.22s/it]\u001b[A\n",
            " 71%|███████   | 63/89 [02:18<00:59,  2.30s/it]\u001b[A\n",
            " 72%|███████▏  | 64/89 [02:21<00:56,  2.26s/it]\u001b[A\n",
            " 73%|███████▎  | 65/89 [02:23<00:53,  2.22s/it]\u001b[A\n",
            " 74%|███████▍  | 66/89 [02:25<00:52,  2.30s/it]\u001b[A\n",
            " 75%|███████▌  | 67/89 [02:27<00:50,  2.30s/it]\u001b[A\n",
            " 76%|███████▋  | 68/89 [02:30<00:48,  2.29s/it]\u001b[A\n",
            " 78%|███████▊  | 69/89 [02:32<00:47,  2.35s/it]\u001b[A\n",
            " 79%|███████▊  | 70/89 [02:35<00:46,  2.46s/it]\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "NOT MATCHED\n",
            "structural information preserving for graph-to-text generation\n",
            "structural neural encoders for amr-to-text generation\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            " 80%|███████▉  | 71/89 [02:37<00:41,  2.33s/it]\u001b[A\n",
            " 81%|████████  | 72/89 [02:39<00:39,  2.34s/it]\u001b[A\n",
            " 82%|████████▏ | 73/89 [02:42<00:38,  2.40s/it]\u001b[A\n",
            " 83%|████████▎ | 74/89 [02:44<00:34,  2.32s/it]\u001b[A\n",
            " 84%|████████▍ | 75/89 [02:46<00:30,  2.18s/it]\u001b[A\n",
            " 85%|████████▌ | 76/89 [02:48<00:28,  2.18s/it]\u001b[A\n",
            " 87%|████████▋ | 77/89 [02:50<00:25,  2.10s/it]\u001b[A\n",
            " 88%|████████▊ | 78/89 [02:52<00:23,  2.13s/it]\u001b[A\n",
            " 89%|████████▉ | 79/89 [02:54<00:21,  2.16s/it]\u001b[A\n",
            " 90%|████████▉ | 80/89 [02:57<00:19,  2.21s/it]\u001b[A\n",
            " 91%|█████████ | 81/89 [02:59<00:17,  2.16s/it]\u001b[A\n",
            " 92%|█████████▏| 82/89 [03:01<00:14,  2.10s/it]\u001b[A\n",
            " 93%|█████████▎| 83/89 [03:03<00:12,  2.15s/it]\u001b[A\n",
            " 94%|█████████▍| 84/89 [03:05<00:10,  2.15s/it]\u001b[A\n",
            " 96%|█████████▌| 85/89 [03:07<00:08,  2.11s/it]\u001b[A\n",
            " 97%|█████████▋| 86/89 [03:09<00:06,  2.10s/it]\u001b[A\n",
            " 98%|█████████▊| 87/89 [03:11<00:04,  2.08s/it]\u001b[A\n",
            " 99%|█████████▉| 88/89 [03:13<00:02,  2.08s/it]\u001b[A\n",
            "100%|██████████| 89/89 [03:16<00:00,  2.20s/it]\n",
            "\n",
            "  0%|          | 0/84 [00:00<?, ?it/s]\u001b[A\n",
            "  1%|          | 1/84 [00:02<03:11,  2.31s/it]\u001b[A\n",
            "  2%|▏         | 2/84 [00:04<03:04,  2.25s/it]\u001b[A\n",
            "  4%|▎         | 3/84 [00:06<02:59,  2.21s/it]\u001b[A\n",
            "  5%|▍         | 4/84 [00:08<02:52,  2.16s/it]\u001b[A\n",
            "  6%|▌         | 5/84 [00:10<02:49,  2.15s/it]\u001b[A\n",
            "  7%|▋         | 6/84 [00:12<02:42,  2.08s/it]\u001b[A\n",
            "  8%|▊         | 7/84 [00:14<02:42,  2.10s/it]\u001b[A\n",
            " 10%|▉         | 8/84 [00:16<02:35,  2.05s/it]\u001b[A\n",
            " 11%|█         | 9/84 [00:18<02:35,  2.07s/it]\u001b[A\n",
            " 12%|█▏        | 10/84 [00:20<02:35,  2.10s/it]\u001b[A\n",
            " 13%|█▎        | 11/84 [00:23<02:34,  2.11s/it]\u001b[A\n",
            " 14%|█▍        | 12/84 [00:25<02:31,  2.11s/it]\u001b[A\n",
            " 15%|█▌        | 13/84 [00:27<02:41,  2.27s/it]\u001b[A\n",
            " 17%|█▋        | 14/84 [00:30<02:38,  2.27s/it]\u001b[A\n",
            " 18%|█▊        | 15/84 [00:32<02:36,  2.27s/it]\u001b[A\n",
            " 19%|█▉        | 16/84 [00:34<02:33,  2.25s/it]\u001b[A\n",
            " 20%|██        | 17/84 [00:36<02:27,  2.21s/it]\u001b[A\n",
            " 21%|██▏       | 18/84 [00:39<02:33,  2.32s/it]\u001b[A\n",
            " 23%|██▎       | 19/84 [00:41<02:30,  2.32s/it]\u001b[A\n",
            " 24%|██▍       | 20/84 [00:44<02:38,  2.48s/it]\u001b[A\n",
            " 25%|██▌       | 21/84 [00:46<02:29,  2.38s/it]\u001b[A\n",
            " 26%|██▌       | 22/84 [00:48<02:19,  2.25s/it]\u001b[A\n",
            " 27%|██▋       | 23/84 [00:50<02:14,  2.20s/it]\u001b[A\n",
            " 29%|██▊       | 24/84 [00:52<02:12,  2.21s/it]\u001b[A\n",
            " 30%|██▉       | 25/84 [00:54<02:06,  2.15s/it]\u001b[A\n",
            " 31%|███       | 26/84 [00:56<02:02,  2.12s/it]\u001b[A\n",
            " 32%|███▏      | 27/84 [00:58<01:58,  2.08s/it]\u001b[A\n",
            " 33%|███▎      | 28/84 [01:01<01:59,  2.13s/it]\u001b[A\n",
            " 35%|███▍      | 29/84 [01:03<01:55,  2.11s/it]\u001b[A\n",
            " 36%|███▌      | 30/84 [01:05<01:49,  2.03s/it]\u001b[A\n",
            " 37%|███▋      | 31/84 [01:07<01:49,  2.06s/it]\u001b[A\n",
            " 38%|███▊      | 32/84 [01:09<01:48,  2.09s/it]\u001b[A\n",
            " 39%|███▉      | 33/84 [01:11<01:54,  2.24s/it]\u001b[A\n",
            " 40%|████      | 34/84 [01:13<01:48,  2.16s/it]\u001b[A\n",
            " 42%|████▏     | 35/84 [01:17<02:10,  2.65s/it]\u001b[A\n",
            " 43%|████▎     | 36/84 [01:20<02:01,  2.54s/it]\u001b[A\n",
            " 44%|████▍     | 37/84 [01:22<01:54,  2.43s/it]\u001b[A\n",
            " 45%|████▌     | 38/84 [01:24<01:48,  2.35s/it]\u001b[A\n",
            " 46%|████▋     | 39/84 [01:26<01:41,  2.26s/it]\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "NOT MATCHED\n",
            "improving image captioning with better use of caption\n",
            "hidden state guidance: improving image captioning using an image conditioned autoencoder\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            " 48%|████▊     | 40/84 [01:28<01:37,  2.21s/it]\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "NOT MATCHED\n",
            "improving multimodal named entity recognition via entity span detection with unified multimodal transformer\n",
            "a multimodal deep learning approach for named entity recognition from social media\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            " 49%|████▉     | 41/84 [01:30<01:37,  2.28s/it]\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "NOT MATCHED\n",
            "inset: sentence infilling with inter-sentential transformer\n",
            "inset: sentence infilling with inter-sentential generative pre-training\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            " 50%|█████     | 42/84 [01:33<01:37,  2.32s/it]\u001b[A\n",
            " 51%|█████     | 43/84 [01:35<01:33,  2.29s/it]\u001b[A\n",
            " 52%|█████▏    | 44/84 [01:37<01:32,  2.30s/it]\u001b[A\n",
            " 54%|█████▎    | 45/84 [01:39<01:27,  2.24s/it]\u001b[A\n",
            " 55%|█████▍    | 46/84 [01:42<01:23,  2.19s/it]\u001b[A\n",
            " 56%|█████▌    | 47/84 [01:44<01:23,  2.25s/it]\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "NOT MATCHED\n",
            "learning to ask more: semi-autoregressive sequential question generation under dual-graph interaction\n",
            "semi-autoregressive neural machine translation\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            " 57%|█████▋    | 48/84 [01:46<01:19,  2.22s/it]\u001b[A\n",
            " 58%|█████▊    | 49/84 [01:49<01:20,  2.30s/it]\u001b[A\n",
            " 60%|█████▉    | 50/84 [01:51<01:16,  2.24s/it]\u001b[A\n",
            " 61%|██████    | 51/84 [01:53<01:12,  2.18s/it]\u001b[A\n",
            " 62%|██████▏   | 52/84 [01:55<01:10,  2.22s/it]\u001b[A\n",
            " 63%|██████▎   | 53/84 [01:57<01:08,  2.21s/it]\u001b[A\n",
            " 64%|██████▍   | 54/84 [01:59<01:04,  2.14s/it]\u001b[A\n",
            " 65%|██████▌   | 55/84 [02:01<01:01,  2.12s/it]\u001b[A\n",
            " 67%|██████▋   | 56/84 [02:03<00:59,  2.14s/it]\u001b[A\n",
            " 68%|██████▊   | 57/84 [02:06<00:58,  2.15s/it]\u001b[A\n",
            " 69%|██████▉   | 58/84 [02:08<00:54,  2.10s/it]\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "NOT MATCHED\n",
            "premise selection in natural language mathematical texts\n",
            "natural language premise selection: finding supporting statements for mathematical text\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            " 70%|███████   | 59/84 [02:10<00:54,  2.16s/it]\u001b[A\n",
            " 71%|███████▏  | 60/84 [02:12<00:53,  2.24s/it]\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "NOT MATCHED\n",
            "reinceptione: relation-aware inception network with joint local-global structural information for knowledge graph embedding\n",
            "relation-aware entity alignment for heterogeneous knowledge graphs\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            " 73%|███████▎  | 61/84 [02:15<00:51,  2.26s/it]\u001b[A\n",
            " 74%|███████▍  | 62/84 [02:17<00:47,  2.18s/it]\u001b[A\n",
            " 75%|███████▌  | 63/84 [02:19<00:44,  2.13s/it]\u001b[A\n",
            " 76%|███████▌  | 64/84 [02:21<00:44,  2.20s/it]\u001b[A\n",
            " 77%|███████▋  | 65/84 [02:23<00:40,  2.13s/it]\u001b[A\n",
            " 79%|███████▊  | 66/84 [02:25<00:39,  2.20s/it]\u001b[A\n",
            " 80%|███████▉  | 67/84 [02:27<00:36,  2.12s/it]\u001b[A\n",
            " 81%|████████  | 68/84 [02:29<00:33,  2.12s/it]\u001b[A\n",
            " 82%|████████▏ | 69/84 [02:32<00:31,  2.13s/it]\u001b[A\n",
            " 83%|████████▎ | 70/84 [02:34<00:31,  2.26s/it]\u001b[A\n",
            " 85%|████████▍ | 71/84 [02:36<00:29,  2.27s/it]\u001b[A\n",
            " 86%|████████▌ | 72/84 [02:38<00:26,  2.21s/it]\u001b[A\n",
            " 87%|████████▋ | 73/84 [02:41<00:24,  2.20s/it]\u001b[A\n",
            " 88%|████████▊ | 74/84 [02:43<00:21,  2.18s/it]\u001b[A\n",
            " 89%|████████▉ | 75/84 [02:45<00:19,  2.17s/it]\u001b[A\n",
            " 90%|█████████ | 76/84 [02:48<00:18,  2.31s/it]\u001b[A\n",
            " 92%|█████████▏| 77/84 [02:50<00:15,  2.27s/it]\u001b[A\n",
            " 93%|█████████▎| 78/84 [02:52<00:13,  2.29s/it]\u001b[A\n",
            " 94%|█████████▍| 79/84 [02:54<00:11,  2.24s/it]\u001b[A\n",
            " 95%|█████████▌| 80/84 [02:56<00:08,  2.17s/it]\u001b[A\n",
            " 96%|█████████▋| 81/84 [02:58<00:06,  2.06s/it]\u001b[A\n",
            " 98%|█████████▊| 82/84 [03:00<00:04,  2.13s/it]\u001b[A\n",
            " 99%|█████████▉| 83/84 [03:02<00:02,  2.15s/it]\u001b[A\n",
            "100%|██████████| 84/84 [03:04<00:00,  2.20s/it]\n",
            "\n",
            "  0%|          | 0/25 [00:00<?, ?it/s]\u001b[A\n",
            "  4%|▍         | 1/25 [00:02<00:51,  2.14s/it]\u001b[A\n",
            "  8%|▊         | 2/25 [00:04<00:48,  2.09s/it]\u001b[A\n",
            " 12%|█▏        | 3/25 [00:06<00:46,  2.12s/it]\u001b[A\n",
            " 16%|█▌        | 4/25 [00:08<00:43,  2.05s/it]\u001b[A\n",
            " 20%|██        | 5/25 [00:10<00:42,  2.14s/it]\u001b[A\n",
            " 24%|██▍       | 6/25 [00:12<00:40,  2.14s/it]\u001b[A\n",
            " 28%|██▊       | 7/25 [00:14<00:37,  2.10s/it]\u001b[A\n",
            " 32%|███▏      | 8/25 [00:16<00:36,  2.14s/it]\u001b[A\n",
            " 36%|███▌      | 9/25 [00:19<00:34,  2.16s/it]\u001b[A\n",
            " 40%|████      | 10/25 [00:21<00:34,  2.30s/it]\u001b[A\n",
            " 44%|████▍     | 11/25 [00:23<00:31,  2.25s/it]\u001b[A\n",
            " 48%|████▊     | 12/25 [00:26<00:31,  2.40s/it]\u001b[A\n",
            " 52%|█████▏    | 13/25 [00:28<00:27,  2.32s/it]\u001b[A\n",
            " 56%|█████▌    | 14/25 [00:30<00:24,  2.20s/it]\u001b[A\n",
            " 60%|██████    | 15/25 [00:32<00:21,  2.16s/it]\u001b[A\n",
            " 64%|██████▍   | 16/25 [00:35<00:20,  2.23s/it]\u001b[A\n",
            " 68%|██████▊   | 17/25 [00:37<00:17,  2.22s/it]\u001b[A\n",
            " 72%|███████▏  | 18/25 [00:39<00:15,  2.22s/it]\u001b[A\n",
            " 76%|███████▌  | 19/25 [00:42<00:13,  2.32s/it]\u001b[A\n",
            " 80%|████████  | 20/25 [00:44<00:11,  2.24s/it]\u001b[A\n",
            " 84%|████████▍ | 21/25 [00:46<00:08,  2.22s/it]\u001b[A\n",
            " 88%|████████▊ | 22/25 [00:48<00:06,  2.19s/it]\u001b[A\n",
            " 92%|█████████▏| 23/25 [00:50<00:04,  2.14s/it]\u001b[A\n",
            " 96%|█████████▌| 24/25 [00:52<00:02,  2.18s/it]\u001b[A\n",
            "100%|██████████| 25/25 [00:54<00:00,  2.20s/it]\n",
            "\n",
            "  0%|          | 0/27 [00:00<?, ?it/s]\u001b[A\n",
            "  4%|▎         | 1/27 [00:02<01:03,  2.46s/it]\u001b[A\n",
            "  7%|▋         | 2/27 [00:04<00:58,  2.34s/it]\u001b[A\n",
            " 11%|█         | 3/27 [00:06<00:54,  2.26s/it]\u001b[A\n",
            " 15%|█▍        | 4/27 [00:09<00:53,  2.32s/it]\u001b[A\n",
            " 19%|█▊        | 5/27 [00:11<00:50,  2.30s/it]\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "NOT MATCHED\n",
            "camouflaged chinese spam content detection with semi-supervised generative active learning\n",
            "detect camouflaged spam content via stoneskipping: graph and text joint embedding for chinese character variation representation\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            " 22%|██▏       | 6/27 [00:13<00:48,  2.32s/it]\u001b[A\n",
            " 26%|██▌       | 7/27 [00:15<00:44,  2.21s/it]\u001b[A\n",
            " 30%|██▉       | 8/27 [00:17<00:41,  2.17s/it]\u001b[A\n",
            " 33%|███▎      | 9/27 [00:19<00:38,  2.12s/it]\u001b[A\n",
            " 37%|███▋      | 10/27 [00:21<00:34,  2.06s/it]\u001b[A\n",
            " 41%|████      | 11/27 [00:23<00:33,  2.11s/it]\u001b[A\n",
            " 44%|████▍     | 12/27 [00:27<00:39,  2.60s/it]\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "NOT MATCHED\n",
            "interpretable operational risk classification with semi-supervised variational autoencoder\n",
            "disentangled variational auto-encoder for semi-supervised learning\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            " 48%|████▊     | 13/27 [00:29<00:34,  2.45s/it]\u001b[A\n",
            " 52%|█████▏    | 14/27 [00:32<00:31,  2.43s/it]\u001b[A\n",
            " 56%|█████▌    | 15/27 [00:34<00:28,  2.35s/it]\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "NOT MATCHED\n",
            "learning low-resource end-to-end goal-oriented dialog for fast and reliable system deployment\n",
            "learning end-to-end goal-oriented dialog\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            " 59%|█████▉    | 16/27 [00:36<00:25,  2.34s/it]\u001b[A\n",
            " 63%|██████▎   | 17/27 [00:38<00:22,  2.22s/it]\u001b[A\n",
            " 67%|██████▋   | 18/27 [00:40<00:19,  2.12s/it]\u001b[A\n",
            " 70%|███████   | 19/27 [00:42<00:16,  2.12s/it]\u001b[A\n",
            " 74%|███████▍  | 20/27 [00:44<00:14,  2.07s/it]\u001b[A\n",
            " 78%|███████▊  | 21/27 [00:46<00:12,  2.09s/it]\u001b[A\n",
            " 81%|████████▏ | 22/27 [00:48<00:10,  2.00s/it]\u001b[A\n",
            " 85%|████████▌ | 23/27 [00:50<00:08,  2.06s/it]\u001b[A\n",
            " 89%|████████▉ | 24/27 [00:52<00:06,  2.00s/it]\u001b[A\n",
            " 93%|█████████▎| 25/27 [00:54<00:04,  2.04s/it]\u001b[A\n",
            " 96%|█████████▋| 26/27 [00:56<00:02,  2.12s/it]\u001b[A\n",
            "100%|██████████| 27/27 [00:59<00:00,  2.19s/it]\n",
            "\n",
            "  0%|          | 0/17 [00:00<?, ?it/s]\u001b[A\n",
            "  6%|▌         | 1/17 [00:02<00:36,  2.30s/it]\u001b[A\n",
            " 12%|█▏        | 2/17 [00:04<00:33,  2.24s/it]\u001b[A\n",
            " 18%|█▊        | 3/17 [00:06<00:30,  2.20s/it]\u001b[A\n",
            " 24%|██▎       | 4/17 [00:08<00:27,  2.15s/it]\u001b[A\n",
            " 29%|██▉       | 5/17 [00:10<00:26,  2.18s/it]\u001b[A\n",
            " 35%|███▌      | 6/17 [00:13<00:24,  2.21s/it]\u001b[A\n",
            " 41%|████      | 7/17 [00:15<00:22,  2.27s/it]\u001b[A\n",
            " 47%|████▋     | 8/17 [00:17<00:19,  2.15s/it]\u001b[A\n",
            " 53%|█████▎    | 9/17 [00:19<00:17,  2.13s/it]\u001b[A\n",
            " 59%|█████▉    | 10/17 [00:21<00:14,  2.13s/it]\u001b[A\n",
            " 65%|██████▍   | 11/17 [00:23<00:12,  2.08s/it]\u001b[A\n",
            " 71%|███████   | 12/17 [00:25<00:10,  2.14s/it]\u001b[A\n",
            " 76%|███████▋  | 13/17 [00:27<00:08,  2.09s/it]\u001b[A\n",
            " 82%|████████▏ | 14/17 [00:30<00:06,  2.31s/it]\u001b[A\n",
            " 88%|████████▊ | 15/17 [00:32<00:04,  2.29s/it]\u001b[A\n",
            " 94%|█████████▍| 16/17 [00:35<00:02,  2.32s/it]\u001b[A\n",
            "100%|██████████| 17/17 [00:37<00:00,  2.21s/it]\n",
            "\n",
            "  0%|          | 0/30 [00:00<?, ?it/s]\u001b[A\n",
            "  3%|▎         | 1/30 [00:02<01:01,  2.10s/it]\u001b[A\n",
            "  7%|▋         | 2/30 [00:04<00:58,  2.10s/it]\u001b[A\n",
            " 10%|█         | 3/30 [00:06<01:00,  2.24s/it]\u001b[A\n",
            " 13%|█▎        | 4/30 [00:08<00:57,  2.20s/it]\u001b[A\n",
            " 17%|█▋        | 5/30 [00:10<00:52,  2.11s/it]\u001b[A\n",
            " 20%|██        | 6/30 [00:12<00:50,  2.10s/it]\u001b[A\n",
            " 23%|██▎       | 7/30 [00:14<00:48,  2.10s/it]\u001b[A\n",
            " 27%|██▋       | 8/30 [00:17<00:46,  2.12s/it]\u001b[A\n",
            " 30%|███       | 9/30 [00:19<00:45,  2.15s/it]\u001b[A\n",
            " 33%|███▎      | 10/30 [00:21<00:44,  2.22s/it]\u001b[A\n",
            " 37%|███▋      | 11/30 [00:23<00:41,  2.19s/it]\u001b[A\n",
            " 40%|████      | 12/30 [00:26<00:39,  2.20s/it]\u001b[A\n",
            " 43%|████▎     | 13/30 [00:28<00:38,  2.26s/it]\u001b[A\n",
            " 47%|████▋     | 14/30 [00:30<00:36,  2.25s/it]\u001b[A\n",
            " 50%|█████     | 15/30 [00:32<00:32,  2.17s/it]\u001b[A\n",
            " 53%|█████▎    | 16/30 [00:34<00:29,  2.11s/it]\u001b[A\n",
            " 57%|█████▋    | 17/30 [00:36<00:28,  2.17s/it]\u001b[A\n",
            " 60%|██████    | 18/30 [00:39<00:25,  2.14s/it]\u001b[A\n",
            " 63%|██████▎   | 19/30 [00:41<00:23,  2.15s/it]\u001b[A\n",
            " 67%|██████▋   | 20/30 [00:43<00:21,  2.12s/it]\u001b[A\n",
            " 70%|███████   | 21/30 [00:45<00:19,  2.22s/it]\u001b[A\n",
            " 73%|███████▎  | 22/30 [00:47<00:17,  2.17s/it]\u001b[A\n",
            " 77%|███████▋  | 23/30 [00:49<00:15,  2.15s/it]\u001b[A\n",
            " 80%|████████  | 24/30 [00:52<00:13,  2.20s/it]\u001b[A\n",
            " 83%|████████▎ | 25/30 [00:53<00:10,  2.08s/it]\u001b[A\n",
            " 87%|████████▋ | 26/30 [00:56<00:08,  2.09s/it]\u001b[A\n",
            " 90%|█████████ | 27/30 [00:58<00:06,  2.09s/it]\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "NOT MATCHED\n",
            "video-grounded dialogues with pretrained generation language models\n",
            "unified language model pre-training for natural language understanding and generation\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            " 93%|█████████▎| 28/30 [01:00<00:04,  2.12s/it]\u001b[A\n",
            " 97%|█████████▋| 29/30 [01:02<00:02,  2.12s/it]\u001b[A\n",
            "100%|██████████| 30/30 [01:04<00:00,  2.15s/it]\n",
            "\n",
            "  0%|          | 0/26 [00:00<?, ?it/s]\u001b[A\n",
            "  4%|▍         | 1/26 [00:02<01:04,  2.58s/it]\u001b[A\n",
            "  8%|▊         | 2/26 [00:04<00:58,  2.42s/it]\u001b[A\n",
            " 12%|█▏        | 3/26 [00:06<00:52,  2.28s/it]\u001b[A\n",
            " 15%|█▌        | 4/26 [00:08<00:47,  2.18s/it]\u001b[A\n",
            " 19%|█▉        | 5/26 [00:10<00:44,  2.14s/it]\u001b[A\n",
            " 23%|██▎       | 6/26 [00:12<00:41,  2.08s/it]\u001b[A\n",
            " 27%|██▋       | 7/26 [00:14<00:39,  2.10s/it]\u001b[A\n",
            " 31%|███       | 8/26 [00:16<00:37,  2.08s/it]\u001b[A\n",
            " 35%|███▍      | 9/26 [00:19<00:39,  2.31s/it]\u001b[A\n",
            " 38%|███▊      | 10/26 [00:21<00:36,  2.28s/it]\u001b[A\n",
            " 42%|████▏     | 11/26 [00:23<00:33,  2.21s/it]\u001b[A\n",
            " 46%|████▌     | 12/26 [00:26<00:32,  2.29s/it]\u001b[A\n",
            " 50%|█████     | 13/26 [00:28<00:28,  2.23s/it]\u001b[A\n",
            " 54%|█████▍    | 14/26 [00:30<00:27,  2.29s/it]\u001b[A\n",
            " 58%|█████▊    | 15/26 [00:33<00:25,  2.35s/it]\u001b[A\n",
            " 62%|██████▏   | 16/26 [00:35<00:23,  2.38s/it]\u001b[A\n",
            " 65%|██████▌   | 17/26 [00:38<00:21,  2.37s/it]\u001b[A\n",
            " 69%|██████▉   | 18/26 [00:39<00:17,  2.22s/it]\u001b[A\n",
            " 73%|███████▎  | 19/26 [00:42<00:15,  2.21s/it]\u001b[A\n",
            " 77%|███████▋  | 20/26 [00:44<00:13,  2.30s/it]\u001b[A\n",
            " 81%|████████  | 21/26 [00:46<00:10,  2.17s/it]\u001b[A\n",
            " 85%|████████▍ | 22/26 [00:48<00:08,  2.15s/it]\u001b[A\n",
            " 88%|████████▊ | 23/26 [00:51<00:06,  2.28s/it]\u001b[A\n",
            " 92%|█████████▏| 24/26 [00:53<00:04,  2.24s/it]\u001b[A\n",
            " 96%|█████████▌| 25/26 [00:55<00:02,  2.13s/it]\u001b[A\n",
            "100%|██████████| 26/26 [00:57<00:00,  2.20s/it]\n",
            "\n",
            "  0%|          | 0/43 [00:00<?, ?it/s]\u001b[A\n",
            "  2%|▏         | 1/43 [00:02<01:29,  2.14s/it]\u001b[A\n",
            "  5%|▍         | 2/43 [00:04<01:25,  2.09s/it]\u001b[A\n",
            "  7%|▋         | 3/43 [00:06<01:27,  2.19s/it]\u001b[A\n",
            "  9%|▉         | 4/43 [00:08<01:23,  2.13s/it]\u001b[A\n",
            " 12%|█▏        | 5/43 [00:10<01:19,  2.10s/it]\u001b[A\n",
            " 14%|█▍        | 6/43 [00:12<01:20,  2.17s/it]\u001b[A\n",
            " 16%|█▋        | 7/43 [00:15<01:19,  2.20s/it]\u001b[A\n",
            " 19%|█▊        | 8/43 [00:17<01:15,  2.15s/it]\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "NOT MATCHED\n",
            "content word aware neural machine translation\n",
            "selective attention for context-aware neural machine translation\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            " 21%|██        | 9/43 [00:19<01:13,  2.16s/it]\u001b[A\n",
            " 23%|██▎       | 10/43 [00:21<01:12,  2.20s/it]\u001b[A\n",
            " 26%|██▌       | 11/43 [00:23<01:08,  2.14s/it]\u001b[A\n",
            " 28%|██▊       | 12/43 [00:26<01:08,  2.20s/it]\u001b[A\n",
            " 30%|███       | 13/43 [00:28<01:05,  2.17s/it]\u001b[A\n",
            " 33%|███▎      | 14/43 [00:29<01:00,  2.07s/it]\u001b[A\n",
            " 35%|███▍      | 15/43 [00:32<00:58,  2.10s/it]\u001b[A\n",
            " 37%|███▋      | 16/43 [00:34<00:55,  2.07s/it]\u001b[A\n",
            " 40%|███▉      | 17/43 [00:36<00:54,  2.10s/it]\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "NOT MATCHED\n",
            "language-aware interlingua for multilingual neural machine translation\n",
            "a neural interlingua for multilingual machine translation\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            " 42%|████▏     | 18/43 [00:38<00:53,  2.14s/it]\u001b[A\n",
            " 44%|████▍     | 19/43 [00:40<00:51,  2.15s/it]\u001b[A\n",
            " 47%|████▋     | 20/43 [00:42<00:48,  2.11s/it]\u001b[A\n",
            " 49%|████▉     | 21/43 [00:44<00:46,  2.09s/it]\u001b[A\n",
            " 51%|█████     | 22/43 [00:46<00:43,  2.06s/it]\u001b[A\n",
            " 53%|█████▎    | 23/43 [00:48<00:40,  2.01s/it]\u001b[A\n",
            " 56%|█████▌    | 24/43 [00:50<00:39,  2.07s/it]\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "NOT MATCHED\n",
            "neural graph matching networks for chinese short text matching\n",
            "graph matching networks for learning the similarity of graph structured objects\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            " 58%|█████▊    | 25/43 [00:53<00:38,  2.14s/it]\u001b[A\n",
            " 60%|██████    | 26/43 [00:55<00:36,  2.13s/it]\u001b[A\n",
            " 63%|██████▎   | 27/43 [00:57<00:33,  2.07s/it]\u001b[A\n",
            " 65%|██████▌   | 28/43 [00:59<00:31,  2.09s/it]\u001b[A\n",
            " 67%|██████▋   | 29/43 [01:01<00:31,  2.24s/it]\u001b[A\n",
            " 70%|██████▉   | 30/43 [01:04<00:28,  2.21s/it]\u001b[A\n",
            " 72%|███████▏  | 31/43 [01:06<00:27,  2.28s/it]\u001b[A\n",
            " 74%|███████▍  | 32/43 [01:08<00:25,  2.28s/it]\u001b[A\n",
            " 77%|███████▋  | 33/43 [01:10<00:22,  2.24s/it]\u001b[A\n",
            " 79%|███████▉  | 34/43 [01:13<00:20,  2.27s/it]\u001b[A\n",
            " 81%|████████▏ | 35/43 [01:15<00:17,  2.23s/it]\u001b[A\n",
            " 84%|████████▎ | 36/43 [01:18<00:16,  2.34s/it]\u001b[A\n",
            " 86%|████████▌ | 37/43 [01:20<00:13,  2.27s/it]\u001b[A\n",
            " 88%|████████▊ | 38/43 [01:22<00:11,  2.26s/it]\u001b[A\n",
            " 91%|█████████ | 39/43 [01:24<00:08,  2.16s/it]\u001b[A\n",
            " 93%|█████████▎| 40/43 [01:26<00:06,  2.12s/it]\u001b[A\n",
            " 95%|█████████▌| 41/43 [01:28<00:04,  2.15s/it]\u001b[A\n",
            " 98%|█████████▊| 42/43 [01:31<00:02,  2.28s/it]\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "NOT MATCHED\n",
            "``you sound just like your father’’ commercial machine translation systems include stylistic biases\n",
            "reducing gender bias in neural machine translation as a domain adaptation problem\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "100%|██████████| 43/43 [01:33<00:00,  2.16s/it]\n",
            "\n",
            "  0%|          | 0/21 [00:00<?, ?it/s]\u001b[A\n",
            "  5%|▍         | 1/21 [00:02<00:47,  2.37s/it]\u001b[A\n",
            " 10%|▉         | 2/21 [00:05<00:47,  2.50s/it]\u001b[A\n",
            " 14%|█▍        | 3/21 [00:08<00:46,  2.60s/it]\u001b[A\n",
            " 19%|█▉        | 4/21 [00:09<00:40,  2.39s/it]\u001b[A\n",
            " 24%|██▍       | 5/21 [00:11<00:36,  2.29s/it]\u001b[A\n",
            " 29%|██▊       | 6/21 [00:13<00:32,  2.18s/it]\u001b[A\n",
            " 33%|███▎      | 7/21 [00:16<00:31,  2.26s/it]\u001b[A\n",
            " 38%|███▊      | 8/21 [00:18<00:30,  2.35s/it]\u001b[A\n",
            " 43%|████▎     | 9/21 [00:21<00:27,  2.28s/it]\u001b[A\n",
            " 48%|████▊     | 10/21 [00:23<00:25,  2.36s/it]\u001b[A\n",
            " 52%|█████▏    | 11/21 [00:25<00:22,  2.30s/it]\u001b[A\n",
            " 57%|█████▋    | 12/21 [00:27<00:19,  2.18s/it]\u001b[A\n",
            " 62%|██████▏   | 13/21 [00:29<00:17,  2.19s/it]\u001b[A\n",
            " 67%|██████▋   | 14/21 [00:32<00:15,  2.20s/it]\u001b[A\n",
            " 71%|███████▏  | 15/21 [00:34<00:13,  2.22s/it]\u001b[A\n",
            " 76%|███████▌  | 16/21 [00:36<00:11,  2.27s/it]\u001b[A\n",
            " 81%|████████  | 17/21 [00:39<00:09,  2.32s/it]\u001b[A\n",
            " 86%|████████▌ | 18/21 [00:41<00:06,  2.27s/it]\u001b[A\n",
            " 90%|█████████ | 19/21 [00:43<00:04,  2.27s/it]\u001b[A\n",
            " 95%|█████████▌| 20/21 [00:45<00:02,  2.24s/it]\u001b[A\n",
            "100%|██████████| 21/21 [00:48<00:00,  2.30s/it]\n",
            "\n",
            "  0%|          | 0/19 [00:00<?, ?it/s]\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "NOT MATCHED\n",
            "tree-structured neural topic model\n",
            "structured neural topic models for reviews\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "  5%|▌         | 1/19 [00:01<00:34,  1.89s/it]\u001b[A\n",
            " 11%|█         | 2/19 [00:04<00:33,  1.96s/it]\u001b[A\n",
            " 16%|█▌        | 3/19 [00:06<00:32,  2.06s/it]\u001b[A\n",
            " 21%|██        | 4/19 [00:08<00:31,  2.09s/it]\u001b[A\n",
            " 26%|██▋       | 5/19 [00:11<00:31,  2.25s/it]\u001b[A\n",
            " 32%|███▏      | 6/19 [00:13<00:28,  2.19s/it]\u001b[A\n",
            " 37%|███▋      | 7/19 [00:15<00:27,  2.31s/it]\u001b[A\n",
            " 42%|████▏     | 8/19 [00:17<00:24,  2.18s/it]\u001b[A\n",
            " 47%|████▋     | 9/19 [00:19<00:21,  2.11s/it]\u001b[A\n",
            " 53%|█████▎    | 10/19 [00:21<00:19,  2.15s/it]\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "NOT MATCHED\n",
            "multimodal and multiresolution speech recognition with transformers\n",
            "multiresolution and multimodal speech recognition with transformers\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            " 58%|█████▊    | 11/19 [00:24<00:18,  2.26s/it]\u001b[A\n",
            " 63%|██████▎   | 12/19 [00:26<00:15,  2.22s/it]\u001b[A\n",
            " 68%|██████▊   | 13/19 [00:28<00:12,  2.14s/it]\u001b[A\n",
            " 74%|███████▎  | 14/19 [00:30<00:10,  2.13s/it]\u001b[A\n",
            " 79%|███████▉  | 15/19 [00:33<00:09,  2.27s/it]\u001b[A\n",
            " 84%|████████▍ | 16/19 [00:35<00:06,  2.28s/it]\u001b[A\n",
            " 89%|████████▉ | 17/19 [00:37<00:04,  2.25s/it]\u001b[A\n",
            " 95%|█████████▍| 18/19 [00:39<00:02,  2.24s/it]\u001b[A\n",
            "100%|██████████| 19/19 [00:42<00:00,  2.21s/it]\n",
            "\n",
            "  0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n",
            " 14%|█▍        | 1/7 [00:02<00:14,  2.49s/it]\u001b[A\n",
            " 29%|██▊       | 2/7 [00:04<00:11,  2.37s/it]\u001b[A\n",
            " 43%|████▎     | 3/7 [00:06<00:09,  2.35s/it]\u001b[A\n",
            " 57%|█████▋    | 4/7 [00:08<00:06,  2.21s/it]\u001b[A\n",
            " 71%|███████▏  | 5/7 [00:11<00:04,  2.24s/it]\u001b[A\n",
            " 86%|████████▌ | 6/7 [00:13<00:02,  2.22s/it]\u001b[A\n",
            "100%|██████████| 7/7 [00:15<00:00,  2.20s/it]\n",
            "\n",
            "  0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n",
            " 33%|███▎      | 1/3 [00:02<00:04,  2.06s/it]\u001b[A\n",
            " 67%|██████▋   | 2/3 [00:03<00:02,  2.02s/it]\u001b[A\n",
            "100%|██████████| 3/3 [00:06<00:00,  2.10s/it]\n",
            "\n",
            "  0%|          | 0/6 [00:00<?, ?it/s]\u001b[A\n",
            " 17%|█▋        | 1/6 [00:02<00:12,  2.42s/it]\u001b[A\n",
            " 33%|███▎      | 2/6 [00:04<00:09,  2.43s/it]\u001b[A\n",
            " 50%|█████     | 3/6 [00:07<00:07,  2.42s/it]\u001b[A\n",
            " 67%|██████▋   | 4/6 [00:09<00:04,  2.45s/it]\u001b[A\n",
            " 83%|████████▎ | 5/6 [00:12<00:02,  2.57s/it]\u001b[A\n",
            "100%|██████████| 6/6 [00:14<00:00,  2.49s/it]\n",
            "\n",
            "  0%|          | 0/5 [00:00<?, ?it/s]\u001b[A\n",
            " 20%|██        | 1/5 [00:02<00:10,  2.55s/it]\u001b[A\n",
            " 40%|████      | 2/5 [00:04<00:07,  2.45s/it]\u001b[A\n",
            " 60%|██████    | 3/5 [00:07<00:05,  2.65s/it]\u001b[A\n",
            " 80%|████████  | 4/5 [00:10<00:02,  2.65s/it]\u001b[A\n",
            "100%|██████████| 5/5 [00:12<00:00,  2.58s/it]\n",
            "\n",
            "  0%|          | 0/5 [00:00<?, ?it/s]\u001b[A\n",
            " 20%|██        | 1/5 [00:02<00:08,  2.16s/it]\u001b[A\n",
            " 40%|████      | 2/5 [00:04<00:06,  2.14s/it]\u001b[A\n",
            " 60%|██████    | 3/5 [00:06<00:04,  2.10s/it]\u001b[A\n",
            " 80%|████████  | 4/5 [00:08<00:02,  2.17s/it]\u001b[A\n",
            "100%|██████████| 5/5 [00:11<00:00,  2.20s/it]\n",
            "\n",
            "  0%|          | 0/5 [00:00<?, ?it/s]\u001b[A\n",
            " 20%|██        | 1/5 [00:02<00:08,  2.15s/it]\u001b[A\n",
            " 40%|████      | 2/5 [00:04<00:06,  2.26s/it]\u001b[A\n",
            " 60%|██████    | 3/5 [00:06<00:04,  2.18s/it]\u001b[A\n",
            " 80%|████████  | 4/5 [00:08<00:02,  2.14s/it]\u001b[A\n",
            "100%|██████████| 5/5 [00:10<00:00,  2.19s/it]\n",
            "\n",
            "  0%|          | 0/6 [00:00<?, ?it/s]\u001b[A\n",
            " 17%|█▋        | 1/6 [00:02<00:12,  2.42s/it]\u001b[A\n",
            " 33%|███▎      | 2/6 [00:04<00:09,  2.35s/it]\u001b[A\n",
            " 50%|█████     | 3/6 [00:07<00:07,  2.41s/it]\u001b[A\n",
            " 67%|██████▋   | 4/6 [00:09<00:04,  2.36s/it]\u001b[A\n",
            " 83%|████████▎ | 5/6 [00:11<00:02,  2.34s/it]\u001b[A\n",
            "100%|██████████| 6/6 [00:14<00:00,  2.34s/it]\n",
            "\n",
            "  0%|          | 0/6 [00:00<?, ?it/s]\u001b[A\n",
            " 17%|█▋        | 1/6 [00:02<00:11,  2.24s/it]\u001b[A\n",
            " 33%|███▎      | 2/6 [00:04<00:09,  2.29s/it]\u001b[A\n",
            " 50%|█████     | 3/6 [00:07<00:07,  2.43s/it]\u001b[A\n",
            " 67%|██████▋   | 4/6 [00:09<00:04,  2.28s/it]\u001b[A\n",
            " 83%|████████▎ | 5/6 [00:11<00:02,  2.33s/it]\u001b[A\n",
            "100%|██████████| 6/6 [00:13<00:00,  2.31s/it]\n",
            "\n",
            "  0%|          | 0/8 [00:00<?, ?it/s]\u001b[A\n",
            " 12%|█▎        | 1/8 [00:01<00:13,  1.95s/it]\u001b[A\n",
            " 25%|██▌       | 2/8 [00:04<00:12,  2.03s/it]\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "NOT MATCHED\n",
            "a geometry-inspired attack for generating natural language adversarial examples\n",
            "a geometry-inspired decision-based attack\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            " 38%|███▊      | 3/8 [00:06<00:10,  2.09s/it]\u001b[A\n",
            " 50%|█████     | 4/8 [00:08<00:08,  2.18s/it]\u001b[A\n",
            " 62%|██████▎   | 5/8 [00:11<00:06,  2.23s/it]\u001b[A\n",
            " 75%|███████▌  | 6/8 [00:13<00:04,  2.15s/it]\u001b[A\n",
            " 88%|████████▊ | 7/8 [00:15<00:02,  2.20s/it]\u001b[A\n",
            "100%|██████████| 8/8 [00:17<00:00,  2.20s/it]\n",
            "\n",
            "  0%|          | 0/5 [00:00<?, ?it/s]\u001b[A\n",
            " 20%|██        | 1/5 [00:01<00:07,  1.94s/it]\u001b[A\n",
            " 40%|████      | 2/5 [00:04<00:06,  2.03s/it]\u001b[A\n",
            " 60%|██████    | 3/5 [00:06<00:04,  2.08s/it]\u001b[A\n",
            " 80%|████████  | 4/5 [00:08<00:02,  2.20s/it]\u001b[A\n",
            "100%|██████████| 5/5 [00:10<00:00,  2.16s/it]\n",
            "\n",
            "  0%|          | 0/6 [00:00<?, ?it/s]\u001b[A\n",
            " 17%|█▋        | 1/6 [00:02<00:10,  2.16s/it]\u001b[A\n",
            " 33%|███▎      | 2/6 [00:04<00:08,  2.12s/it]\u001b[A\n",
            " 50%|█████     | 3/6 [00:06<00:06,  2.16s/it]\u001b[A\n",
            " 67%|██████▋   | 4/6 [00:08<00:04,  2.21s/it]\u001b[A\n",
            " 83%|████████▎ | 5/6 [00:10<00:02,  2.12s/it]\u001b[A\n",
            "100%|██████████| 6/6 [00:12<00:00,  2.15s/it]\n",
            "\n",
            "  0%|          | 0/5 [00:00<?, ?it/s]\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "NOT MATCHED\n",
            "unsupervised multilingual sentence embeddings for parallel corpus mining\n",
            "margin-based parallel corpus mining with multilingual sentence embeddings\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            " 20%|██        | 1/5 [00:02<00:08,  2.06s/it]\u001b[A\n",
            " 40%|████      | 2/5 [00:04<00:06,  2.12s/it]\u001b[A\n",
            " 60%|██████    | 3/5 [00:07<00:04,  2.29s/it]\u001b[A\n",
            " 80%|████████  | 4/5 [00:09<00:02,  2.32s/it]\u001b[A\n",
            "100%|██████████| 5/5 [00:11<00:00,  2.29s/it]\n",
            "\n",
            "  0%|          | 0/8 [00:00<?, ?it/s]\u001b[A\n",
            " 12%|█▎        | 1/8 [00:02<00:14,  2.09s/it]\u001b[A\n",
            " 25%|██▌       | 2/8 [00:04<00:13,  2.18s/it]\u001b[A\n",
            " 38%|███▊      | 3/8 [00:06<00:10,  2.18s/it]\u001b[A\n",
            " 50%|█████     | 4/8 [00:09<00:09,  2.27s/it]\u001b[A\n",
            " 62%|██████▎   | 5/8 [00:11<00:06,  2.23s/it]\u001b[A\n",
            " 75%|███████▌  | 6/8 [00:14<00:05,  2.65s/it]\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "NOT MATCHED\n",
            "υbleu: uncertainty-aware automatic evaluation method for open-domain dialogue systems\n",
            "better automatic evaluation of open-domain dialogue systems with contextualized embeddings\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            " 88%|████████▊ | 7/8 [00:17<00:02,  2.51s/it]\u001b[A\n",
            "100%|██████████| 8/8 [00:19<00:00,  2.41s/it]\n",
            "\n",
            "  0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n",
            " 33%|███▎      | 1/3 [00:02<00:04,  2.21s/it]\u001b[A\n",
            " 67%|██████▋   | 2/3 [00:04<00:02,  2.12s/it]\u001b[A\n",
            "100%|██████████| 3/3 [00:06<00:00,  2.11s/it]\n",
            "\n",
            "  0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n",
            " 14%|█▍        | 1/7 [00:02<00:15,  2.53s/it]\u001b[A\n",
            " 29%|██▊       | 2/7 [00:04<00:11,  2.37s/it]\u001b[A\n",
            " 43%|████▎     | 3/7 [00:06<00:09,  2.29s/it]\u001b[A\n",
            " 57%|█████▋    | 4/7 [00:08<00:06,  2.27s/it]\u001b[A\n",
            " 71%|███████▏  | 5/7 [00:10<00:04,  2.20s/it]\u001b[A\n",
            " 86%|████████▌ | 6/7 [00:13<00:02,  2.30s/it]\u001b[A\n",
            "100%|██████████| 7/7 [00:15<00:00,  2.23s/it]\n",
            "\n",
            "  0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n",
            " 14%|█▍        | 1/7 [00:02<00:13,  2.24s/it]\u001b[A\n",
            " 29%|██▊       | 2/7 [00:04<00:11,  2.29s/it]\u001b[A\n",
            " 43%|████▎     | 3/7 [00:06<00:08,  2.23s/it]\u001b[A\n",
            " 57%|█████▋    | 4/7 [00:09<00:07,  2.36s/it]\u001b[A\n",
            " 71%|███████▏  | 5/7 [00:11<00:04,  2.38s/it]\u001b[A\n",
            " 86%|████████▌ | 6/7 [00:14<00:02,  2.40s/it]\u001b[A\n",
            "100%|██████████| 7/7 [00:16<00:00,  2.34s/it]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": false,
        "id": "Gk2bFBdqCNRI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with open(\"papers_with_arxiv_link.md\", \"w\") as f:\n",
        "    f.write(\"## Long Papers\\n\\n\")\n",
        "    generate_paper_list_with_arxiv_link(f, longp)\n",
        "    f.write(\"## Short Papers\\n\\n\")\n",
        "    generate_paper_list_with_arxiv_link(f, short)\n",
        "    f.write(\"## System Demonstrations\\n\\n\")\n",
        "    generate_paper_list_with_arxiv_link(f, demop)\n",
        "    f.write(\"## Student Research Workshop\\n\\n\")\n",
        "    generate_paper_list_with_arxiv_link(f, student)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GKaDBI55CNRK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}