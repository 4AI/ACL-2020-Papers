{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.2"
    },
    "colab": {
      "name": "generate_paper_list_with_arxiv_link.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "1m2RpTeiCNQq",
        "TUjlRSPtCNRD"
      ],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hunkim/ACL-2020-Papers/blob/master/generate_paper_list_with_arxiv_link.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1m2RpTeiCNQq",
        "colab_type": "text"
      },
      "source": [
        "# Load Paper List"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6G-XWU8JCNQr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def read_papers(path):\n",
        "    papers = [[]]\n",
        "    with open(path, \"r\", encoding=\"utf-8\") as f:\n",
        "        for line in f:\n",
        "            line = line.strip()\n",
        "            if line:\n",
        "                papers[-1].append(line)\n",
        "            else:\n",
        "                papers.append([])\n",
        "    for p in papers:\n",
        "        assert len(p) == 2\n",
        "    return papers"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m_5mqAPzCNQu",
        "colab_type": "code",
        "outputId": "c0f334d7-f482-4fdd-85d9-c00a3d7620ab",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        }
      },
      "source": [
        "longp = read_papers(\"./data/long.txt\")\n",
        "longp[:3]"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['2kenize: Tying Subword Sequences for Chinese Script Conversion',\n",
              "  'Pranav A and Isabelle Augenstein'],\n",
              " ['A Batch Normalized Inference Network Keeps the KL Vanishing Away',\n",
              "  'Qile Zhu, Wei Bi, Xiaojiang Liu, Xiyao Ma, Xiaolin Li and Dapeng Wu'],\n",
              " ['A Call for More Rigor in Unsupervised Cross-lingual Learning',\n",
              "  'Mikel Artetxe, Sebastian Ruder, Dani Yogatama, Gorka Labaka and Eneko Agirre']]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AxPZti17CNQx",
        "colab_type": "code",
        "outputId": "25cf494d-474b-467a-852b-16552b768dac",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "len(longp)"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "571"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SqL_0bNPCNQ0",
        "colab_type": "code",
        "outputId": "5ec4c616-6f2f-4d7f-d1ac-214e2848687f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        }
      },
      "source": [
        "short = read_papers(\"./data/short.txt\")\n",
        "short[:3]"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['A Complete Shift-Reduce Chinese Discourse Parser with Robust Dynamic Oracle',\n",
              "  'Shyh-Shiun Hung, Hen-Hsen Huang and Hsin-Hsi Chen'],\n",
              " ['A Diverse Corpus for Evaluating and Developing English Math Word Problem Solvers',\n",
              "  'Shen-yun Miao, Chao-Chun Liang and Keh-Yih Su'],\n",
              " ['A Frame-based Sentence Representation for Machine Reading Comprehension',\n",
              "  'Shaoru Guo, Ru Li, Hongye Tan, Xiaoli Li, Yong Guan, Hongyan Zhao and Yueping Zhang']]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rLNXH4MJCNQ2",
        "colab_type": "code",
        "outputId": "e63030a0-7c2c-47b4-b5bc-11ca29380a25",
        "colab": {}
      },
      "source": [
        "len(short)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "208"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TrBRORv3CNQ5",
        "colab_type": "code",
        "outputId": "715cc350-82da-4eb2-fd70-986ad051fb0c",
        "colab": {}
      },
      "source": [
        "demo = read_papers(\"./data/demo.txt\")\n",
        "demo[:3]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['ADVISER: A Toolkit for Developing Multi-modal, Multi-domain and Socially-engaged Conversational Agents',\n",
              "  'Chia-Yu Li, Daniel Ortega, Dirk Väth, Florian Lux, Lindsey Vanderlyn, Maximilian Schmidt, Michael Neumann, Moritz Völkel, Pavel Denisov, Sabrina Jenne, Zorica Kacarevic and Ngoc Thang Vu'],\n",
              " ['BENTO: A Visual Platform for Building Clinical NLP Pipelines Based on CodaLab',\n",
              "  'Yonghao Jin, Fei Li and Hong Yu'],\n",
              " ['Clinical-Coder: Assigning Interpretable ICD-10 Codes to Chinese Clinical Notes',\n",
              "  'Pengfei Cao, Chenwei Yan, xiangling fu, Yubo Chen, Kang Liu, Jun Zhao, Shengping Liu and Weifeng Chong']]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GySLkygHCNQ7",
        "colab_type": "code",
        "outputId": "bc0031db-864e-4a43-98d6-4f3c7fa23d47",
        "colab": {}
      },
      "source": [
        "len(demo)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "43"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0cNcBqCsCNQ-",
        "colab_type": "code",
        "outputId": "4d233334-f54a-47aa-e788-dcfec4eabeaf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        }
      },
      "source": [
        "student = read_papers(\"./data/student.txt\")\n",
        "student[:3]"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['#NotAWhore! A Computational Linguistic Perspective of Rape Culture and Victimization on Social Media',\n",
              "  'Ashima Suvarna and Grusha Bhalla'],\n",
              " ['A Geometry-Inspired Attack for Generating Natural Language Adversarial Examples',\n",
              "  'Zhao Meng and Roger Wattenhofer'],\n",
              " ['A Simple and Effective Dependency parser for Telugu',\n",
              "  'Sneha Nallani, Manish Shrivastava and Dipti Sharma']]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o9Zc2x0qCNRA",
        "colab_type": "code",
        "outputId": "49525fec-44d2-4130-8fce-077758220a61",
        "colab": {}
      },
      "source": [
        "len(student)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "49"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aw4p7l8eCYX2",
        "colab_type": "text"
      },
      "source": [
        "# Sorting by Topic\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c36Fa3LPCovq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "fd83c698-ed03-4b8a-f544-86bd403549eb"
      },
      "source": [
        "import gensim\n",
        "from gensim.utils import simple_preprocess\n",
        "from gensim.parsing.preprocessing import STOPWORDS\n",
        "from nltk.stem import WordNetLemmatizer, SnowballStemmer\n",
        "from nltk.stem.porter import *\n",
        "import numpy as np\n",
        "import nltk\n",
        "\n",
        "nltk.download('wordnet')\n",
        "stemmer = SnowballStemmer(\"english\")\n",
        "\n",
        "def lemmatize_stemming(text):\n",
        "  return stemmer.stem(WordNetLemmatizer().lemmatize(text, pos='v'))\n",
        "\n",
        "# Tokenize and lemmatize\n",
        "def preprocess(text):\n",
        "  result=[]\n",
        "  for token in gensim.utils.simple_preprocess(text) :\n",
        "    if token not in gensim.parsing.preprocessing.STOPWORDS and len(token) > 3:\n",
        "      result.append(lemmatize_stemming(token))\n",
        "                \n",
        "  return result\n",
        "\n",
        "\n"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zqDjrwyoHEPu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#FIXME: Better way to get human readable topic names from LDA topics?\n",
        "def list2topiclist(list, num_topics = 8):\n",
        "  processed_docs = []\n",
        "  for line in list:\n",
        "    processed_line = preprocess(line[0])\n",
        "    processed_docs.append(processed_line)\n",
        "\n",
        "    dictionary = gensim.corpora.Dictionary(processed_docs)\n",
        "    bow_corpus = [dictionary.doc2bow(doc) for doc in processed_docs]\n",
        "\n",
        "  \n",
        "  lda = gensim.models.LdaModel(bow_corpus, num_topics, \n",
        "                               id2word = dictionary, passes = 10)\n",
        "\n",
        "  # Assign list to topic\n",
        "  list_topics = []\n",
        "  for line in list:\n",
        "    processed_line = preprocess(line[0])\n",
        "    bow_vector = dictionary.doc2bow(processed_line)\n",
        "    line_topic = sorted(lda.get_document_topics(bow_vector), key=lambda tup: tup[1], reverse=True)\n",
        "    list_topics.append((line_topic[0][0], line)) \n",
        "\n",
        "  list_topics.sort(key=lambda tup: tup[0])\n",
        "  print(list_topics[:3])\n",
        "\n",
        "  # Sort out topics\n",
        "  prev_topic = -1\n",
        "  topic_dict = {}\n",
        "  \n",
        "  def show_topic_title(idx, topn=3):\n",
        "    return [dictionary[x[0]] for x in lda.get_topic_terms(idx, topn)]\n",
        "\n",
        "  for list in list_topics:\n",
        "    if list[0] != prev_topic:\n",
        "      prev_topic = list[0]\n",
        "      topic_title = show_topic_title(prev_topic)\n",
        "      topic_title = \" \".join(topic_title)\n",
        "      topic_dict[topic_title] = []\n",
        "    \n",
        "    topic_dict[topic_title].append(list[1])\n",
        "  \n",
        "  return topic_dict\n",
        "      \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zw8jDBlNNGYH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 218
        },
        "outputId": "53f91297-28b6-4de3-ee81-c41b3f228d57"
      },
      "source": [
        "topic_long = list2topiclist(longp)\n",
        "print(topic_long[-1])"
      ],
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[(0, ['A Generative Model for Joint Natural Language Understanding and Generation', 'Bo-Hsiang Tseng, Jianpeng Cheng, Yimai Fang and David Vandyke']), (0, ['A Graph-based Coarse-to-fine Method for Unsupervised Bilingual Lexicon Induction', 'Shuo Ren, Shujie Liu, Ming Zhou and Shuai Ma']), (0, ['A Span-based Linearization for Constituent Trees', 'Yang Wei, Yuanbin Wu and Man Lan'])]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-65-03031f3d456c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mtopic_long\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist2topiclist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlongp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtopic_long\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m: -1"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TUjlRSPtCNRD",
        "colab_type": "text"
      },
      "source": [
        "# Search arXiv Link"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ws04-fbRCNRD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from googlesearch import search\n",
        "import urllib\n",
        "from bs4 import BeautifulSoup\n",
        "from difflib import SequenceMatcher\n",
        "from tqdm import tqdm\n",
        "\n",
        "\n",
        "def similarity(a, b):\n",
        "    return SequenceMatcher(None, a, b).ratio()\n",
        "\n",
        "\n",
        "def search_arxiv_link(title):\n",
        "    link = None\n",
        "    for j in search(title, tld=\"co.in\", num=10, stop=1, pause=0.5):\n",
        "        if 'arxiv.org/abs' in j:\n",
        "            thepage = urllib.request.urlopen(j)\n",
        "            soup = BeautifulSoup(thepage, \"html.parser\")\n",
        "            searched_title = ' '.join(soup.title.text.lower().split()[1:])\n",
        "            if similarity(title, searched_title) > 0.8:\n",
        "                link = j\n",
        "                break\n",
        "            else:\n",
        "                print(\"NOT MATCHED\")\n",
        "                print(title)\n",
        "                print(searched_title)\n",
        "    return link"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SAJu9189CNRF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def generate_paper_list_with_arxiv_link(f, papers):\n",
        "    for p in tqdm(papers):\n",
        "        title, authors = p\n",
        "        link = search_arxiv_link(title.lower())\n",
        "        if link:\n",
        "            f.write(f\"- {title} [[arXiv]]({link})\\n\")\n",
        "        else:\n",
        "            f.write(f\"- {title}\\n\")\n",
        "    f.write(\"\\n\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "796iR6xmLnMd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def generate_paper_list_with_arxiv_link_topic(f, papers):\n",
        "  topic_papers = list2topiclist(papers)\n",
        "  print(topic_papers)\n",
        "  for topic in topic_papers:\n",
        "    f.write(\"###\" + topic + \"\\n\")\n",
        "    generate_paper_list_with_arxiv_link(f, topic_papers[topic])\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "11VvQQBRMZjY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 497
        },
        "outputId": "3534479a-201b-42f4-d9c8-060332076970"
      },
      "source": [
        "with open(\"papers_with_arxiv_link_topic.md\", \"w\") as f:\n",
        "  f.write(\"## Long Papers\\n\\n\")\n",
        "  generate_paper_list_with_arxiv_link_topic(f, longp)\n",
        "  f.write(\"## Short Papers\\n\\n\")\n",
        "  generate_paper_list_with_arxiv_link_topic(f, short)\n",
        "  f.write(\"## System Demonstrations\\n\\n\")\n",
        "  generate_paper_list_with_arxiv_link_topic(f, demo)\n",
        "  f.write(\"## Student Research Workshop\\n\\n\")\n",
        "  generate_paper_list_with_arxiv_link_topic(f, student)\n"
      ],
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "  0%|          | 0/71 [00:00<?, ?it/s]\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[(0, ['A Corpus for Large-Scale Phonetic Typology', 'Elizabeth Salesky, Eleanor Chodroff, Tiago Pimentel, Matthew Wiesner, Ryan Cotterell, Alan W Black and Jason Eisner']), (0, ['A Joint Model for Document Segmentation and Segment Labeling', 'Joe Barrow, Rajiv Jain, Vlad Morariu, Varun Manjunatha, Douglas Oard and Philip Resnik']), (0, ['A Recipe for Creating Multimodal Aligned Datasets for Sequential Tasks', 'Angela Lin, Sudha Rao, Asli Celikyilmaz, Elnaz Nouri, Chris Brockett, Debadeepta Dey and Bill Dolan'])]\n",
            "{'learn question graph': [['A Corpus for Large-Scale Phonetic Typology', 'Elizabeth Salesky, Eleanor Chodroff, Tiago Pimentel, Matthew Wiesner, Ryan Cotterell, Alan W Black and Jason Eisner'], ['A Joint Model for Document Segmentation and Segment Labeling', 'Joe Barrow, Rajiv Jain, Vlad Morariu, Varun Manjunatha, Douglas Oard and Philip Resnik'], ['A Recipe for Creating Multimodal Aligned Datasets for Sequential Tasks', 'Angela Lin, Sudha Rao, Asli Celikyilmaz, Elnaz Nouri, Chris Brockett, Debadeepta Dey and Bill Dolan'], ['A Span-based Linearization for Constituent Trees', 'Yang Wei, Yuanbin Wu and Man Lan'], ['A Top-down Neural Architecture towards Text-level Parsing of Discourse Rhetorical Structure', 'Longyin Zhang, Yuqing Xing, Fang Kong, Peifeng Li and Guodong Zhou'], ['Aligned Dual Channel Graph Convolutional Network for Visual Question Answering', 'Qingbao Huang, Jielong Wei, Yi Cai, Changmeng Zheng, Junying Chen, Ho-fung Leung and Qing Li'], ['An Effective Transition-based Model for Discontinuous NER', 'Xiang Dai, Sarvnaz Karimi, Ben Hachey and Cecile Paris'], ['Asking and Answering Questions to Evaluate the Factual Consistency of Summaries', 'Alex Wang, Kyunghyun Cho and Mike Lewis'], ['BPE-Dropout: Simple and Effective Subword Regularization', 'Ivan Provilkov, Dmitrii Emelianenko and Elena Voita'], ['CompGuessWhat?!: A Multi-task Evaluation Framework for Grounded Language Learning', 'Alessandro Suglia, Ioannis Konstas, Andrea Vanzo, Emanuele Bastianelli, Desmond Elliott, Stella Frank and Oliver Lemon'], ['Connecting Embeddings for Knowledge Graph Entity Typing', 'Yu Zhao, anxiang zhang, Ruobing Xie, Kang Liu and Xiaojie WANG'], ['Coupling Distant Annotation and Adversarial Training for Cross-Domain Chinese Word Segmentation', 'Ning Ding, Dingkun Long, Guangwei Xu, Muhua Zhu, Pengjun Xie, Xiaobin Wang and Haitao Zheng'], ['Dice Loss for Data-imbalanced NLP Tasks', 'Xiaoya Li, Xiaofei Sun, Yuxian Meng, Junjun Liang, Fei Wu and Jiwei Li'], ['Differentiable Window for Dynamic Local Attention', 'Thanh-Tung Nguyen, Xuan-Phi Nguyen, Shafiq Joty and Xiaoli Li'], ['Discourse as a Function of Event: Profiling Discourse Structure in News Articles around the Main Event', 'Prafulla Kumar Choubey, Aaron Lee, Ruihong Huang and Lu Wang'], ['Discrete Optimization for Unsupervised Sentence Summarization with Word-Level Extraction', 'Raphael Schumann, Lili Mou, Yao Lu, Olga Vechtomova and Katja Markert'], ['Distilling Annotations via Active Imitation Learning', 'Kianté Brantley, Hal Daumé III and Amr Sharaf'], ['Document-Level Event Role Filler Extraction using Multi-Granularity Contextualized Encoding', 'Xinya Du and Claire Cardie'], ['DTCA: Decision Tree-based Co-Attention Networks for Explainable Claim Verification', 'Lianwei Wu, Yuan Rao, Yongqiang Zhao, Hao Liang and Ambreen Nazir'], ['Exploiting Syntactic Structure for Better Language Modeling: A Syntactic Distance Approach', 'Wenyu DU, Zhouhan Lin, Yikang Shen, Timothy J. O’Donnell, Yoshua Bengio and Yue Zhang'], ['Exploring Contextual Word-level Style Relevance for Unsupervised Style Transfer', 'Chulun Zhou, Liangyu Chen, Jiachen Liu, Xinyan Xiao, Jinsong Su, Sheng Guo and Hua Wu'], ['FEQA: A Question Answering Evaluation Framework for Faithfulness Assessment in Abstractive Summarization', 'Esin Durmus, He He and Mona Diab'], ['Graph-to-Tree Learning for Solving Math Word Problems', 'Jipeng Zhang, Lei Wang, Roy Ka-Wei Lee, Yi Bin, Yan Wang, Jie Shao and Ee-Peng Lim'], ['Harvesting and Refining Question-Answer Pairs for Unsupervised QA', 'Zhongli Li, Wenhui Wang, Li Dong, Furu Wei and Ke Xu'], ['Heterogeneous Graph Neural Networks for Extractive Document Summarization', 'Danqing Wang, Pengfei Liu, Yining Zheng, Xipeng Qiu and Xuanjing Huang'], ['Hierarchical Entity Typing via Multi-level Learning to Rank', 'Tongfei Chen, Yunmo Chen and Benjamin Van Durme'], ['Hooks in the Headline: Learning to Generate Headlines with Controlled Styles', 'Di Jin, Zhijing Jin, Joey Tianyi Zhou, Lisa Orii and Peter Szolovits'], ['Improving Multi-hop Question Answering over Knowledge Graphs using Knowledge Base Embeddings', 'Apoorv Saxena, Aditay Tripathi and Partha Talukdar'], ['In Layman’s Terms: Semi-Open Relation Extraction from Scientific Texts', 'Ruben Kruiper, Julian Vincent, Jessica Chen-Burger, Marc Desmulliez and Ioannis Konstas'], ['INFOTABS: Inference on Tables as Semi-structured Data', 'Vivek Gupta, Maitrey Mehta, Pegah Nokhiz and Vivek Srikumar'], ['Iterative Edit-Based Unsupervised Sentence Simplification', 'Dhruv Kumar, Lili Mou, Lukasz Golab and Olga Vechtomova'], ['Knowledge Graph-Augmented Abstractive Summarization with Semantic-Driven Cloze Reward', 'Luyang Huang, Lingfei Wu and Lu Wang'], ['Large Scale Multi-Actor Generative Dialog Modeling', 'Alex Boyd, Raul Puri, Mohammad Shoeybi, Mostofa Patwary and Bryan Catanzaro'], ['Learning to Ask More: Semi-Autoregressive Sequential Question Generation under Dual-Graph Interaction', 'Zi Chai and Xiaojun Wan'], ['Learning to Contextually Aggregate Multi-Source Supervision for Sequence Labeling', 'Ouyu Lan, Xiao Huang, Bill Yuchen Lin, He Jiang, Liyuan Liu and Xiang Ren'], ['Learning to execute instructions in a Minecraft dialogue', 'Prashant Jayannavar, Anjali Narayan-Chen and Julia Hockenmaier'], ['Learning to Identify Follow-Up Questions in Conversational Question Answering', 'Souvik Kundu, Qian Lin and Hwee Tou Ng'], ['Learning to Segment Actions from Observation and Narration', 'Daniel Fried, Jean-Baptiste Alayrac, Phil Blunsom, Chris Dyer, Stephen Clark and Aida Nematzadeh'], ['Leveraging Graph to Improve Abstractive Multi-Document Summarization', 'Wei Li, Xinyan Xiao, Jiachen Liu, Hua Wu, Haifeng Wang and Junping Du'], ['MATINF: A Jointly Labeled Large-Scale Dataset for Classification, Question Answering and Summarization', 'Canwen Xu, Jiaxin Pei, Hongtao Wu, Yiyu Liu and Chenliang Li'], ['MIND: A Large-scale Dataset for News Recommendation', 'Fangzhao Wu, Ying Qiao, Jiun-Hung Chen, Chuhan Wu, Tao Qi, Jianxun Lian, Danyang Liu, Xing Xie, Jianfeng Gao, Winnie Wu and Ming Zhou'], ['Modeling Morphological Typology for Unsupervised Learning of Language Morphology', 'Hongzhi Xu, Jordan Kodner, Mitchell Marcus and Charles Yang'], ['Multidirectional Associative Optimization of Function-Specific Word Representations', 'Daniela Gerz, Ivan Vulić, Marek Rei, Roi Reichart and Anna Korhonen'], ['Multi-Granularity Interaction Network for Extractive and Abstractive Multi-Document Summarization', 'Hanqi Jin, Tianming Wang and Xiaojun Wan'], ['Multimodal Neural Graph Memory Networks for Visual Question Answering', 'Mahmoud Khademi'], ['On Faithfulness and Factuality in Abstractive Summarization', 'Joshua Maynez, Shashi Narayan, Bernd Bohnet and Ryan McDonald'], ['Optimizing the Factual Correctness of a Summary: A Study of Summarizing Radiology Reports', 'Yuhao Zhang, Derek Merck, Emily Tsai, Christopher D. Manning and Curtis Langlotz'], ['PeTra: A Sparsely Supervised Memory Model for People Tracking', 'Shubham Toshniwal, Allyson Ettinger, Kevin Gimpel and Karen Livescu'], ['Probabilistic Assumptions Matter: Improved Models for Distantly-Supervised Document-Level Question Answering', 'Hao Cheng, Ming-Wei Chang, Kenton Lee and Kristina Toutanova'], ['QuASE: Question-Answer Driven Sentence Encoding', 'Hangfeng He, Qiang Ning and Dan Roth'], ['Reasoning with Latent Structure Refinement for Document-Level Relation Extraction', 'Guoshun Nan, Zhijiang Guo, Ivan Sekulic and Wei Lu'], ['ReInceptionE: Relation-Aware Inception Network with Joint Local-Global Structural Information for Knowledge Graph Embedding', 'Zhiwen Xie, Guangyou Zhou, Jin Liu and Jimmy Xiangji Huang'], ['Relational Graph Attention Network for Aspect-based Sentiment Analysis', 'Kai Wang, Weizhou Shen, Yunyi Yang, Xiaojun Quan and Rui Wang'], ['SAS: Dialogue State Tracking via Slot Attention and Slot Information Sharing', 'Jiaying Hu, Yan Yang, Chencai Chen, Liang He and Zhou Yu'], ['Semi-Supervised Semantic Dependency Parsing Using CRF Autoencoders', 'Zixia Jia, Youmi Ma, Jiong Cai and Kewei Tu'], ['SenseBERT: Driving Some Sense into BERT', 'Yoav Levine, Barak Lenz, Or Dagan, Ori Ram, Dan Padnos, Or Sharir, Shai Shalev-Shwartz, Amnon Shashua and Yoav Shoham'], ['Sentiment and Emotion help Sarcasm? A Multi-task Learning Framework for Multi-Modal Sarcasm, Sentiment and Emotion Analysis', 'Dushyant Singh Chauhan, Dhanush S R, Asif Ekbal and Pushpak Bhattacharyya'], ['Span Selection Pre-training for Question Answering', 'Michael Glass, Alfio Gliozzo, Rishav Chakravarti, Anthony Ferritto, Lin Pan, G P Shrivatsa Bhargav, Dinesh Garg and Avi Sil'], ['Span-based Localizing Network for Natural Language Video Localization', 'Hao Zhang, Aixin Sun, Wei Jing and Joey Tianyi Zhou'], ['SpanMlt: A Span-based Multi-Task Learning Framework for Pair-wise Aspect and Opinion Terms Extraction', 'He Zhao, Longtao Huang, Rong Zhang, Quan Lu and Hui Xue'], ['STARC: Structured Annotations for Reading Comprehension', 'Yevgeni Berzak, Jonathan Malmaud and Roger Levy'], ['Stock Embeddings Acquired from News Articles and Price History, and an Application to Portfolio Optimization', 'Xin Du and Kumiko Tanaka-Ishii'], ['Structural Information Preserving for Graph-to-Text Generation', 'Linfeng Song, Ante Wang, Jinsong Su, Yue Zhang, Kun Xu, Yubin Ge and Dong Yu'], ['TaPas: Weakly Supervised Table Parsing via Pre-training', 'Jonathan Herzig, Pawel Krzysztof Nowak, Thomas Müller, Francesco Piccinno and Julian Eisenschlos'], ['Taxonomy Construction of Unseen Domains via Graph-based Cross-Domain Knowledge Transfer', 'Chao Shang, Sarthak Dash, Md Faisal Mahbub Chowdhury, Nandana Mihindukulasooriya and Alfio Gliozzo'], ['The Summary Loop: Learning to Write Abstractive Summaries Without Examples', 'Philippe Laban, Andrew Hsi, John Canny and Marti A. Hearst'], ['TransS-Driven Joint Learning Architecture for Implicit Discourse Relation Recognition', 'Ruifang He, Jian Wang, Fengyu Guo and Yugui Han'], ['Unsupervised Alignment-based Iterative Evidence Retrieval for Multi-hop Question Answering', 'Vikas Yadav, Steven Bethard and Mihai Surdeanu'], ['Unsupervised Opinion Summarization as Copycat-Review Generation', 'Arthur Bražinskas, Mirella Lapata and Ivan Titov'], ['Unsupervised Opinion Summarization with Noising and Denoising', 'Reinald Kim Amplayo and Mirella Lapata'], ['What Question Answering can Learn from Trivia Nerds', 'Jordan Boyd-Graber and Benjamin Börschinger']], 'languag model sentiment': [['A Self-Training Method for Machine Reading Comprehension with Soft Evidence Extraction', 'Yilin Niu, Fangkai Jiao, Mantong Zhou, Ting Yao, Jingfang Xu and Minlie Huang'], ['Agreement Prediction of Arguments in Cyber Argumentation for Detecting Stance Polarity and Intensity', 'Joseph Sirrianni, Xiaoqing Liu and Douglas Adams'], ['AMR Parsing with Latent Structural Information', 'Qiji Zhou, Yue Zhang, Donghong Ji and Hao Tang'], ['Aspect Sentiment Classification with Document-level Sentiment Preference Modeling', 'Xiao Chen, Changlong Sun, Jingjing Wang, Shoushan Li, Luo Si, Min Zhang and Guodong Zhou'], ['ASSET: A Dataset for Tuning and Evaluation of Sentence Simplification Models with Multiple Rewriting Transformations', 'Fernando Alva-Manchego, Louis Martin, Antoine Bordes, Carolina Scarton, Benoît Sagot and Lucia Specia'], ['Calibrating Structured Output Predictors for Natural Language Processing', 'Abhyuday Jagannatha and Hong Yu'], ['Cross-Lingual Unsupervised Sentiment Classification with Multi-View Transfer Learning', 'Hongliang Fei and Ping Li'], ['Dependency Graph Enhanced Dual-transformer Structure for Aspect-based Sentiment Classification', 'Hao Tang, Donghong Ji, Chenliang Li and Qiji Zhou'], ['Don’t Say That! Making Inconsistent Dialogue Unlikely with Unlikelihood Training', 'Margaret Li, Stephen Roller, Ilia Kulikov, Sean Welleck, Y-Lan Boureau, Kyunghyun Cho and Jason Weston'], ['Enhancing Cross-target Stance Detection with Transferable Semantic-Emotion Knowledge', 'Bowen Zhang, Min Yang, Xutao Li, Yunming Ye, Xiaofei Xu and Kuai Dai'], ['Fast and Accurate Deep Bidirectional Language Representations for Unsupervised Learning', 'Joongbo Shin, Yoonhyung Lee, Seunghyun Yoon and Kyomin Jung'], ['Few-shot Slot Tagging with Collapsed Dependency Transfer and Label-enhanced Task-adaptive Projection Network', 'Yutai Hou, Wanxiang Che, Yongkui Lai, Zhihan Zhou, Yijia Liu, Han Liu and Ting Liu'], ['From SPMRL to NMRL: What Did We Learn (and Unlearn) in a Decade of Parsing Morphologically-Rich Languages (MRLs)?', 'Reut Tsarfaty, Dan Bareket, Stav Klein and Amit Seker'], ['Gated Convolutional Bidirectional Attention-based Model for Off-topic Spoken Response Detection', 'Yefei Zha, Ruobing Li and Hui Lin'], ['He said “who’s gonna take care of your children when you are at ACL?”: Reported Sexist Acts are Not Sexist', 'Patricia Chiril, Véronique Moriceau, Farah Benamara, Alda Mari, Gloria Origgi and Marlène Coulomb-Gully'], ['Highway Transformer: Self-Gating Enhanced Self-Attentive Networks', 'Yekun Chai, Shuo Jin and Xinwen Hou'], ['How Accents Confound: Probing for Accent Information in End-to-End Speech Recognition Systems', 'Archiki Prasad and Preethi Jyothi'], ['How Does NLP Benefit Legal System: A Summary of Legal Artificial Intelligence', 'Haoxi Zhong, Chaojun Xiao, Cunchao Tu, Tianyang Zhang, Zhiyuan Liu and Maosong Sun'], ['Improved Natural Language Generation via Loss Truncation', 'Daniel Kang and Tatsunori Hashimoto'], ['Improving Disfluency Detection by Self-Training a Self-Attentive Model', 'Paria Jamshid Lou and Mark Johnson'], ['Integrating Multimodal Information in Large Pretrained Transformers', 'Wasifur Rahman, Md Kamrul Hasan, Sangwu Lee, AmirAli Bagher Zadeh, Chengfeng Mao, Louis-Philippe Morency and Ehsan Hoque'], ['KinGDOM: Knowledge-Guided DOMain adaptation for sentiment analysis', 'Deepanway Ghosal, Devamanyu Hazarika, Abhinaba Roy, Navonil Majumder, Rada Mihalcea and Soujanya Poria'], ['Low-Resource Generation of Multi-hop Reasoning Questions', 'Jianxing Yu, Wei Liu, Shuang Qiu, Qinliang Su, Kai Wang, Xiaojun Quan and Jian Yin'], ['Multi-Sentence Argument Linking', 'Seth Ebner, Patrick Xia, Ryan Culkin, Kyle Rawlins and Benjamin Van Durme'], ['Multi-source Meta Transfer for Low Resource Multiple-Choice Question Answering', 'Ming Yan, Hao Zhang, Di Jin and Joey Tianyi Zhou'], ['ParaCrawl: Web-Scale Acquisition of Parallel Corpora', 'Marta Bañón, Pinzhen Chen, Barry Haddow, Kenneth Heafield, Hieu Hoang, Miquel Esplà-Gomis, Mikel L. Forcada, Amir Kamran, Faheem Kirefu, Philipp Koehn, Sergio Ortiz Rojas, Leopoldo Pla Sempere, Gema Ramírez-Sánchez, Elsa Sarrías, Marek Strelec, Brian Thompson, William Waites, Dion Wiggins and Jaume Zaragoza'], ['Predicting Depression in Screening Interviews from Latent Categorization of Interview Prompts', 'Alex Rinaldi, Jean Fox Tree and Snigdha Chaturvedi'], ['Predicting Performance for Natural Language Processing Tasks', 'Mengzhou Xia, Antonios Anastasopoulos, Ruochen Xu, Yiming Yang and Graham Neubig'], ['Predicting the Topical Stance and Political Leaning of Media using Tweets', 'Peter Stefanov, Kareem Darwish, Atanas Atanasov and Preslav Nakov'], ['Pretraining with Contrastive Sentence Objectives Improves Discourse Performance of Language Models', 'Dan Iter, Kelvin Guu, Larry Lansing and Dan Jurafsky'], ['Probing for referential information in language models', 'Ionut-Teodor Sorodoc, Kristina Gulordava and Gemma Boleda'], ['Rationalizing Medical Relation Prediction from Corpus-level Statistics', 'Zhen Wang, Jennifer Lee, Simon Lin and Huan Sun'], ['Response-Anticipated Memory for On-Demand Knowledge Integration in Response Generation', 'Zhiliang Tian, Wei Bi, Dongkyu Lee, Lanqing Xue, Yiping Song, Xiaojiang Liu and Nevin L. Zhang'], ['Rethinking Dialogue State Tracking with Reasoning', 'Lizi Liao, Yunshan Ma, Wenqiang Lei and Tat-Seng Chua'], ['RikiNet: Reading Wikipedia Pages for Natural Question Answering', 'Dayiheng Liu, Yeyun Gong, Jie Fu, Yu Yan, Jiusheng Chen, Daxin Jiang, Jiancheng Lv and Nan Duan'], ['SentiBERT: A Transferable Transformer-Based Architecture for Compositional Sentiment Semantics', 'Da Yin, Tao Meng and Kai-Wei Chang'], ['SKEP: Sentiment Knowledge Enhanced Pre-training for Sentiment Analysis', 'Hao Tian, Can Gao, Xinyan Xiao, Hao Liu, Bolei He, Hua Wu, Haifeng Wang and Feng Wu'], ['SpellGCN: Incorporating Phonological and Visual Similarities into Language Models for Chinese Spelling Check', 'Xingyi Cheng, Weidi Xu, Kunlong Chen, Shaohua Jiang, Feng Wang, Taifeng Wang, Wei Chu and Yuan Qi'], ['Synchronous Double-channel Recurrent Network for Aspect-Opinion Pair Extraction', 'Shaowei Chen, Jie Liu, Yu Wang, Wenzheng Zhang and Ziming Chi'], ['Syn-QG: Syntactic and Shallow Semantic Rules for Question Generation', 'Kaustubh Dhole and Christopher D. Manning'], ['That is a Known Lie: Detecting Previously Fact-Checked Claims', 'Shaden Shaar, Nikolay Babulkov, Giovanni Da San Martino and Preslav Nakov'], ['The TechQA Dataset', 'Vittorio Castelli, Rishav Chakravarti, Saswati Dana, Anthony Ferritto, Radu Florian, Martin Franz, Dinesh Garg, Dinesh Khandelwal, Scott McCarley, Michael McCawley, Mohamed Nasr, Lin Pan, Cezar Pendus, John Pitrelli, Saurabh Pujar, Salim Roukos, Andrzej Sakrajda, Avi Sil, Rosario Uceda-Sosa, Todd Ward and Rong Zhang'], ['Towards Emotion-aided Multi-modal Dialogue Act Classification', 'Tulika Saha, Aditya Patra, Sriparna Saha and Pushpak Bhattacharyya'], ['TVQA+: Spatio-Temporal Grounding for Video Question Answering', 'Jie Lei, Licheng Yu, Tamara Berg and Mohit Bansal'], ['“Who said it, and Why?” Provenance for Natural Language Claims', 'Yi Zhang, Zachary Ives and Dan Roth'], ['XtremeDistil: Multi-stage Distillation for Massive Multilingual Models', 'Subhabrata Mukherjee and Ahmed Hassan Awadallah'], ['ZeroShotCeres: Zero-Shot Relation Extraction from Semi-Structured Webpages', 'Colin Lockard, Prashant Shiralkar, Xin Luna Dong and Hannaneh Hajishirzi']], 'generat cross learn': [['A Girl Has A Name: Detecting Authorship Obfuscation', 'Asad Mahmood, Zubair Shafiq and Padmini Srinivasan'], ['A Methodology for Creating Question Answering Corpora Using Inverse Data Annotation', 'Jan Deriu, Katsiaryna Mlynchyk, Philippe Schläpfer, Alvaro Rodrigo, Dirk von Grünigen, Nicolas Kaiser, Kurt Stockinger, Eneko Agirre and Mark Cieliebak'], ['Addressing Posterior Collapse with Mutual Information for Improved Variational Neural Machine Translation', 'Arya D. McCarthy, Xian Li, Jiatao Gu and Ning Dong'], ['Analyzing Political Parody in Social Media', 'Antonios Maronikolakis, Danae Sánchez Villegas, Daniel Preotiuc-Pietro and Nikolaos Aletras'], ['Attend, Translate and Summarize: An Efficient Method for Neural Cross-Lingual Summarization', 'Junnan Zhu, Yu Zhou, Jiajun Zhang and Chengqing Zong'], ['Automatic Detection of Generated Text is Easiest when Humans are Fooled', 'Daphne Ippolito, Daniel Duckworth, Chris Callison-Burch and Douglas Eck'], ['Automatic Generation of Citation Texts in Scholarly Papers: A Pilot Study', 'Xinyu Xing, Xiaosheng Fan and Xiaojun Wan'], ['BERTRAM: Improved Word Embeddings Have Big Impact on Contextualized Model Performance', 'Timo Schick and Hinrich Schütze'], ['BiRRE: Learning Bidirectional Residual Relation Embeddings for Supervised Hypernymy Detection', 'Chengyu Wang and Xiaofeng He'], ['CH-SIMS: A Chinese Multimodal Sentiment Analysis Dataset with Fine-grained Annotation of Modality', 'Wenmeng Yu, Hua Xu, Fanyang Meng, Yilin Zhu, Yixiao Ma, Jiele Wu, Jiyun Zou and Kaicheng Yang'], ['Conditional Augmentation for Aspect Term Extraction via Masked Sequence-to-Sequence Generation', 'Kun Li, Chengbo Chen, Xiaojun Quan, Qing Ling and Yan Song'], ['CorefQA: Coreference Resolution as Query-based Span Prediction', 'Wei Wu, Fei Wang, Arianna Yuan, Fei Wu and Jiwei Li'], ['Cross-media Structured Common Space for Multimedia Event Extraction', 'Manling Li, Alireza Zareian, Qi Zeng, Spencer Whitehead, Di Lu, Heng Ji and Shih-Fu Chang'], ['Data Manipulation: Towards Effective Instance Learning for Neural Dialogue Generation via Learning to Augment and Reweight', 'Hengyi Cai, Hongshen Chen, Yonghao Song, Cheng Zhang, Xiaofang Zhao and Dawei Yin'], ['Dialogue-Based Relation Extraction', 'Dian Yu, Kai Sun, Claire Cardie and Dong Yu'], ['Diverse and Informative Dialogue Generation with Context-Specific Commonsense Knowledge Awareness', 'Sixing Wu, Ying Li, Dawei Zhang, Yang Zhou and Zhonghai Wu'], ['Document Translation vs. Query Translation for Cross-Lingual Information Retrieval in the Medical Domain', 'Shadi Saleh and Pavel Pecina'], ['DoQA - Accessing Domain-Specific FAQs via Conversational QA', 'Jon Ander Campos, Arantxa Otegi, Aitor Soroa, Jan Deriu, Mark Cieliebak and Eneko Agirre'], ['Double-Hard Debias: Tailoring Word Embeddings for Gender Bias Mitigation', 'Tianlu Wang, Xi Victoria Lin, Nazneen Fatema Rajani, Bryan McCann, Vicente Ordonez and Caiming Xiong'], ['ECPE-2D: Emotion-Cause Pair Extraction based on Joint Two-Dimensional Representation, Interaction and Prediction', 'Zixiang Ding, Rui Xia and Jianfei Yu'], ['Empowering Active Learning to Jointly Optimize System and User Demands', 'Ji-Ung Lee, Christian M. Meyer and Iryna Gurevych'], ['Estimating predictive uncertainty for rumour verification models', 'Elena Kochkina and Maria Liakata'], ['Fact-based Text Editing', 'Hayate Iso, Chao Qiao and Hang Li'], ['Fine-Grained Analysis of Cross-Linguistic Syntactic Divergences', 'Dmitry Nikolaev, Ofir Arviv, Taelin Karidi, Neta Kenneth, Veronika Mitnik, Lilja Maria Saeboe and Omri Abend'], ['Fine-grained Interest Matching for Neural News Recommendation', 'Heyuan Wang, Fangzhao Wu, Zheng Liu and Xing Xie'], ['Fluent Response Generation for Conversational Question Answering', 'Ashutosh Baheti, Alan Ritter and Kevin Small'], ['GCAN: Graph-aware Co-Attention Networks for Explainable Fake News Detection on Social Media', 'Yi-Ju Lu and Cheng-Te Li'], ['Gender Bias in Multilingual Embeddings and Cross-Lingual Transfer', 'Jieyu Zhao, Subhabrata Mukherjee, Saghar Hosseini, Kai-Wei Chang and Ahmed Hassan Awadallah'], ['Generating Diverse and Consistent QA pairs from Contexts with Information-Maximizing Hierarchical Conditional VAEs', 'Dong Bok Lee, Seanie Lee, Woo Tae Jeong, Donghwan Kim and Sung Ju Hwang'], ['GoEmotions: A Dataset of Fine-Grained Emotions', 'Dorottya Demszky, Dana Movshovitz-Attias, Jeongwoo Ko, Alan Cowen, Gaurav Nemade and Sujith Ravi'], ['IMoJIE: Iterative Memory-Based Joint Open Information Extraction', 'Keshav Kolluru, Samarth Aggarwal, Vipul Rathore, Mausam - and Soumen Chakrabarti'], ['Improving Neural Machine Translation with Soft Template Prediction', 'Jian Yang, Shuming Ma, Dongdong Zhang, Zhoujun Li and Ming Zhou'], ['Interactive Classification by Asking Informative Questions', 'Lili Yu, Howard Chen, Sida I. Wang, Tao Lei and Yoav Artzi'], ['Interpreting Pretrained Contextualized Representations via Reductions to Static Embeddings', 'Rishi Bommasani, Kelly Davis and Claire Cardie'], ['MLQA: Evaluating Cross-lingual Extractive Question Answering', 'Patrick Lewis, Barlas Oguz, Ruty Rinott, Sebastian Riedel and Holger Schwenk'], ['Modelling Context and Syntactical Features for Aspect-based Sentiment Analysis', 'Minh Hieu Phan and Philip O. Ogunbona'], ['More Diverse Dialogue Datasets via Diversity-Informed Data Collection', 'Katherine Stasaski, Grace Hui Yang and Marti A. Hearst'], ['MultiQT: Multimodal learning for real-time question tracking in speech', 'Jakob D. Havtorn, Jan Latko, Joakim Edin, Lars Maaløe, Lasse Borgholt, Lorenzo Belgrano, Nicolai Jacobsen, Regitze Sdun and Željko Agić'], ['Neural Data-to-Text Generation via Jointly Learning the Segmentation and Correspondence', 'Xiaoyu Shen, Ernie Chang, Hui Su, Cheng Niu and Dietrich Klakow'], ['On the Cross-lingual Transferability of Monolingual Representations', 'Mikel Artetxe, Sebastian Ruder and Dani Yogatama'], ['One Size Does Not Fit All: Generating and Evaluating Variable Number of Keyphrases', 'Xingdi Yuan, Tong Wang, Rui Meng, Khushboo Thaker, Peter Brusilovsky, Daqing He and Adam Trischler'], ['Out of the Echo Chamber: Detecting Countering Debate Speeches', 'Matan Orbach, Yonatan Bilu, Assaf Toledo, Dan Lahav, Michal Jacovi, Ranit Aharonov and Noam Slonim'], ['Paraphrase Generation by Learning How to Edit from Samples', 'Amirhossein Kazemnejad, Mohammadreza Salehi and Mahdieh Soleymani Baghshah'], ['Politeness Transfer: A Tag and Generate Approach', 'Aman Madaan, Amrith Setlur, Tanmay Parekh, Barnabas Poczos, Graham Neubig, Yiming Yang, Ruslan Salakhutdinov, Alan W Black and Shrimai Prabhumoye'], ['Posterior Control of Blackbox Generation', 'Xiang Lisa Li and Alexander Rush'], ['Predictive Biases in Natural Language Processing Models: A Conceptual Framework and Overview', 'Deven Santosh Shah, H. Andrew Schwartz and Dirk Hovy'], ['Refer360° : A Referring Expression Recognition Dataset in 360° Images', 'Volkan Cirik, Taylor Berg-Kirkpatrick and Louis-Philippe Morency'], ['Relabel the Noise: Joint Extraction of Entities and Relations via Cooperative Multiagents', 'Daoyuan Chen, Yaliang Li, Kai Lei and Ying Shen'], ['Relation-Aware Collaborative Learning for Unified Aspect-Based Sentiment Analysis', 'Zhuang Chen and Tieyun Qian'], ['Representation Learning for Information Extraction from Form-like Documents', 'Bodhisattwa Prasad Majumder, Navneet Potti, Sandeep Tata, James Bradley Wendt, Qi Zhao and Marc Najork'], ['Review-based Question Generation with Adaptive Instance Transfer and Augmentation', 'Qian Yu, Lidong Bing, Qiong Zhang, Wai Lam and Luo Si'], ['Revisiting the Context Window for Cross-lingual Word Embeddings', 'Ryokan Ri and Yoshimasa Tsuruoka'], ['Rigid Formats Controlled Text Generation', 'Piji Li, Haisong Zhang, Xiaojiang Liu and Shuming Shi'], ['Should All Cross-Lingual Embeddings Speak English?', 'Antonios Anastasopoulos and Graham Neubig'], ['Spelling Error Correction with Soft-Masked BERT', 'Shaohua Zhang, Haoran Huang, Jicong Liu and Hang Li'], ['TaBERT: Pretraining for Joint Understanding of Textual and Tabular Data', 'Pengcheng Yin, Graham Neubig, Wen-tau Yih and Sebastian Riedel'], ['TAG : Type Auxiliary Guiding for Code Comment Generation', 'Ruichu Cai, Zhihao Liang, Boyan Xu, zijian li, Yuexing Hao and Yao Chen'], ['Text-Based Ideal Points', 'Keyon Vafa, Suresh Naidu and David Blei'], ['“The Boating Store Had Its Best Sail Ever”: Pronunciation-attentive Contextualized Pun Recognition', 'Yichao Zhou, Jyun-Yu Jiang, Jieyu Zhao, Kai-Wei Chang and Wei Wang'], ['To Boldly Query What No One Has Annotated Before? The Frontiers of Corpus Querying', 'Markus Gärtner and Kerstin Jung'], ['Towards Faithful Neural Table-to-Text Generation with Content-Matching Constraints', 'Zhenyi Wang, Xiaoyang Wang, Bang An, Dong Yu and Changyou Chen'], ['Towards Understanding Gender Bias in Relation Extraction', 'Andrew Gaut, Tony Sun, Shirlyn Tang, Yuxin Huang, Jing Qian, Mai ElSherief, Jieyu Zhao, Diba Mirza, Elizabeth Belding, Kai-Wei Chang and William Yang Wang'], ['Unsupervised Cross-lingual Representation Learning at Scale', 'Alexis Conneau, Kartikay Khandelwal, Naman Goyal, Vishrav Chaudhary, Guillaume Wenzek, Francisco Guzmán, Edouard Grave, Myle Ott, Luke Zettlemoyer and Veselin Stoyanov'], ['What determines the order of adjectives in English? Comparing efficiency-based theories using dependency treebanks', 'Richard Futrell, William Dyer and Greg Scontras'], ['What Was Written vs. Who Read It: News Media Profiling Using Text Analysis and Social Media Context', 'Ramy Baly, Georgi Karadzhov, Jisun An, Haewoon Kwak, Yoan Dinkov, Ahmed Ali, James Glass and Preslav Nakov'], ['Word-level Textual Adversarial Attacking as Combinatorial Optimization', 'Yuan Zang, Fanchao Qi, Chenghao Yang, Zhiyuan Liu, Meng Zhang, Qun Liu and Maosong Sun'], ['You Impress Me: Dialogue Generation via Mutual Persona Perception', 'Qian Liu, Yihong Chen, Bei Chen, Jian-Guang Lou, Zixuan Chen, Bin Zhou and Dongmei Zhang']], 'languag natur model': [['A Generative Model for Joint Natural Language Understanding and Generation', 'Bo-Hsiang Tseng, Jianpeng Cheng, Yimai Fang and David Vandyke'], ['A Monolingual Approach to Contextualized Word Embeddings for Mid-Resource Languages', 'Pedro Javier Ortiz Suárez, Laurent Romary and Benoît Sagot'], ['A Multitask Learning Approach for Diacritic Restoration', 'Sawsan Alqahtani, Ajay Mishra and Mona Diab'], ['Adaptive Compression of Word Embeddings', 'Yeachan Kim, Kang-Min Kim and SangKeun Lee'], ['Adversarial NLI: A New Benchmark for Natural Language Understanding', 'Yixin Nie, Adina Williams, Emily Dinan, Mohit Bansal, Jason Weston and Douwe Kiela'], ['Analysing Lexical Semantic Change with Contextualised Word Representations', 'Mario Giulianelli, Marco Del Tredici and Raquel Fernández'], ['Analyzing analytical methods: The case of phonology in neural models of spoken language', 'Grzegorz Chrupała, Bertrand Higy and Afra Alishahi'], ['Are Natural Language Inference Models IMPPRESsive? Learning IMPlicature and PRESupposition', 'Paloma Jeretic, Alex Warstadt, Suvrat Bhooshan and Adina Williams'], ['Benchmarking Multimodal Regex Synthesis with Complex Structures', 'Xi Ye, Qiaochu Chen, Isil Dillig and Greg Durrett'], ['Breaking Through the 80% Glass Ceiling: Raising the State of the Art in Word Sense Disambiguation by Incorporating Knowledge Graph Information', 'Michele Bevilacqua and Roberto Navigli'], ['CluBERT: A Cluster-Based Approach for Learning Sense Distributions in Multiple Languages', 'Tommaso Pasini, Federico Scozzafava and Bianca Scarlini'], ['Curriculum Learning for Natural Language Understanding', 'Benfeng Xu, Licheng Zhang, Zhendong Mao, Quan Wang, Hongtao Xie and Yongdong Zhang'], ['Discourse-Aware Neural Extractive Text Summarization', 'Jiacheng Xu, Zhe Gan, Yu Cheng and Jingjing Liu'], ['Do Neural Models Learn Systematicity of Monotonicity Inference in Natural Language?', 'Hitomi Yanaka, Koji Mineshima, Daisuke Bekki and Kentaro Inui'], ['Dynamic Programming Encoding for Subword Segmentation in Neural Machine Translation', 'Xuanli He, Gholamreza Haffari and Mohammad Norouzi'], ['Efficient Constituency Parsing by Pointing', 'Thanh-Tung Nguyen, Xuan-Phi Nguyen, Shafiq Joty and Xiaoli Li'], ['End-to-End Neural Word Alignment Outperforms GIZA++', 'Thomas Zenkel, Joern Wuebker and John DeNero'], ['ERASER: A Benchmark to Evaluate Rationalized NLP Models', 'Jay DeYoung, Sarthak Jain, Nazneen Fatema Rajani, Eric Lehman, Caiming Xiong, Richard Socher and Byron C. Wallace'], ['Examining Citations of Natural Language Processing Literature', 'Saif M. Mohammad'], ['Examining the State-of-the-Art in News Timeline Summarization', 'Demian Gholipour Ghalandari and Georgiana Ifrim'], ['Exploiting the Syntax-Model Consistency for Neural Relation Extraction', 'Amir Pouran Ben Veyseh, Franck Dernoncourt, Dejing Dou and Thien Huu Nguyen'], ['Extractive Summarization as Text Matching', 'Ming Zhong, Pengfei Liu, Yiran Chen, Danqing Wang, Xipeng Qiu and Xuanjing Huang'], ['Facet-Aware Evaluation for Extractive Summarization', 'Yuning Mao, Liyuan Liu, Qi Zhu, Xiang Ren and Jiawei Han'], ['From Arguments to Key Points: Towards Automatic Argument Summarization', 'Roy Bar-Haim, Lilach Eden, Roni Friedman, Yoav Kantor, Dan Lahav and Noam Slonim'], ['Gender Gap in Natural Language Processing Research: Disparities in Authorship and Citations', 'Saif M. Mohammad'], ['HAT: Hardware-Aware Transformers for Efficient Natural Language Processing', 'Hanrui Wang, Zhanghao Wu, Zhijian Liu, Han Cai, Ligeng Zhu, Chuang Gan and Song Han'], ['Investigating Word-Class Distributions in Word Vector Spaces', 'Ryohei Sasano and Anna Korhonen'], ['iSarcasm: A Dataset of Intended Sarcasm', 'Silviu Oprea and Walid Magdy'], ['Joint Chinese Word Segmentation and Part-of-speech Tagging via Two-way Attentions of Auto-analyzed Knowledge', 'Yuanhe Tian, Yan Song, Xiang Ao, Fei Xia, Xiaojun Quan, Tong Zhang and Yonggang Wang'], ['Jointly Learning to Align and Summarize for Neural Cross-Lingual Summarization', 'Yue Cao, Hui Liu and Xiaojun Wan'], ['Knowledge Graph Embedding Compression', 'Mrinmaya Sachan'], ['Language (Re)modelling: Towards Embodied Language Understanding', 'Ronen Tamari, Chen Shani, Tom Hope, Miriam R L Petruck, Omri Abend and Dafna Shahaf'], ['Language (technology) is power: The need to be explicit about NLP harms', 'Su Lin Blodgett, Solon Barocas, Hal Daumé III and Hanna Wallach'], ['Language to Network: Conditional Parameter Adaptation with Natural Language Descriptions', 'Tian Jin, Zhun Liu, Shengjia Yan, Alexandre Eichenberger and Louis-Philippe Morency'], ['Learning to Faithfully Rationalize by Construction', 'Sarthak Jain, Sarah Wiegreffe, Yuval Pinter and Byron C. Wallace'], ['Learning to Update Natural Language Comments Based on Code Changes', 'Sheena Panthaplackel, Pengyu Nie, Milos Gligoric, Junyi Jessy Li and Raymond Mooney'], ['Low-Dimensional Hyperbolic Knowledge Graph Embeddings', 'Ines Chami, Adva Wolf, Da-Cheng Juan, Frederic Sala, Sujith Ravi and Christopher Ré'], ['Machine Reading of Historical Events', 'Or Honovich, Lucas Torroba Hennigen, Omri Abend and Shay B. Cohen'], ['Mapping Natural Language Instructions to Mobile UI Action Sequences', 'Yang Li, Jiacong He, Xin Zhou, Yuan Zhang and Jason Baldridge'], ['Modeling Code-Switch Languages Using Bilingual Parallel Corpus', 'Grandee Lee and Haizhou Li'], ['Multi-agent Communication meets Natural Language: Synergies between Functional and Structural Language Learning', 'Angeliki Lazaridou, Anna Potapenko and Olivier Tieleman'], ['NeuInfer: Knowledge Inference on N-ary Facts', 'Saiping Guan, Xiaolong Jin, Jiafeng Guo, Yuanzhuo Wang and Xueqi Cheng'], ['NILE : Natural Language Inference with Faithful Natural Language Explanations', 'Sawan Kumar and Partha Talukdar'], ['Null It Out: Guarding Protected Attributes by Iterative Nullspace Projection', 'Shauli Ravfogel, Yanai Elazar, Hila Gonen, Michael Twiton and Yoav Goldberg'], ['On the Encoder-Decoder Incompatibility in Variational Text Modeling and Beyond', 'Chen Wu, Prince Zizhuang Wang and William Yang Wang'], ['Orthogonal Relation Transforms with Graph Context Modeling for Knowledge Graph Embedding', 'Yun Tang, Jing Huang, Guangtao Wang, Xiaodong He and Bowen Zhou'], ['Pre-train and Plug-in: Flexible Conditional Text Generation with Variational Auto-Encoders', 'Yu Duan, Canwen Xu, Jiaxin Pei, Jialong Han and Chenliang Li'], ['Probabilistically Masked Language Model Capable of Autoregressive Generation in Arbitrary Word Order', 'Yi Liao, Xin Jiang and Qun Liu'], ['Programming in Natural Language with fuSE: Synthesizing Methods from Spoken Utterances Using Deep Natural Language Understanding', 'Sebastian Weigelt, Vanessa Steurer, Tobias Hey and Walter F. Tichy'], ['Rationalizing Text Matching: Learning Sparse Alignments via Optimal Transport', 'Kyle Swanson, Lili Yu and Tao Lei'], ['Recurrent Chunking Mechanisms for Long-Text Machine Reading Comprehension', 'Hongyu Gong, Yelong Shen, Dian Yu, Jianshu Chen and Dong Yu'], ['Screenplay Summarization Using Latent Narrative Structure', 'Pinelopi Papalampidi, Frank Keller, Lea Frermann and Mirella Lapata'], ['ScriptWriter: Narrative-Guided Script Generation', 'Yutao Zhu, Ruihua Song, Zhicheng Dou, Jian-Yun Nie and Jin Zhou'], ['SEEK: Segmented Embedding of Knowledge Graphs', 'Wentao Xu, Shun Zheng, Liang He, Bin Shao, Jian Yin and Tie-Yan Liu'], ['SMART: Robust and Efficient Fine-Tuning for Pre-trained Natural Language Models through Principled Regularized Optimization', 'Haoming Jiang, Pengcheng He, Weizhu Chen, Xiaodong Liu, Jianfeng Gao and Tuo Zhao'], ['Speak to your Parser: Interactive Text-to-SQL with Natural Language Feedback', 'Ahmed Elgohary, Saghar Hosseini and Ahmed Hassan Awadallah'], ['Spying on your neighbors: Fine-grained probing of contextual embeddings for information about surrounding words', 'Josef Klafka and Allyson Ettinger'], ['Text and Causal Inference: A Review of Using Text to Remove Confounding from Causal Estimates', 'Katherine Keith, David Jensen and Brendan O’Connor'], ['Towards Unsupervised Language Understanding and Generation by Joint Dual Learning', 'Shang-Yu Su, Chao-Wei Huang and Yun-Nung Chen'], ['Transition-based Directed Graph Construction for Emotion-Cause Pair Extraction', 'Chuang Fan, Chaofa Yuan, Jiachen Du, Lin Gui, Min Yang and Ruifeng Xu'], ['Translationese as a Language in “Multilingual” NMT', 'Parker Riley, Isaac Caswell, Markus Freitag and David Grangier'], ['TXtract: Taxonomy-Aware Knowledge Extraction for Thousands of Product Categories', 'Giannis Karamanolakis, Jun Ma and Xin Luna Dong'], ['What are the Goals of Distributional Semantics?', 'Guy Emerson']], 'translat neural machin': [['A Call for More Rigor in Unsupervised Cross-lingual Learning', 'Mikel Artetxe, Sebastian Ruder, Dani Yogatama, Gorka Labaka and Eneko Agirre'], ['A Graph-based Coarse-to-fine Method for Unsupervised Bilingual Lexicon Induction', 'Shuo Ren, Shujie Liu, Ming Zhou and Shuai Ma'], ['A Novel Graph-based Multi-modal Fusion Encoder for Neural Machine Translation', 'Yongjing Yin, Fandong Meng, Jinsong Su, Chulun Zhou, Zhengyuan Yang, Jie Zhou and Jiebo Luo'], ['A Reinforced Generation of Adversarial Examples for Neural Machine Translation', 'Wei Zou, Shujian Huang, Jun Xie, Xinyu Dai and Jiajun Chen'], ['A Unified MRC Framework for Named Entity Recognition', 'Xiaoya Li, Jingrong Feng, Yuxian Meng, Qinghong Han, Fei Wu and Jiwei Li'], ['AdvAug: Robust Adversarial Augmentation for Neural Machine Translation', 'Yong Cheng, Lu Jiang, Wolfgang Macherey and Jacob Eisenstein'], ['BabyWalk: Going Farther in Vision-and-Language Navigation by Taking Baby Steps', 'Wang Zhu, Hexiang Hu, Jiacheng Chen, Zhiwei Deng, Vihan Jain, Eugene Ie and Fei Sha'], ['Balancing Training for Multilingual Neural Machine Translation', 'Xinyi Wang, Yulia Tsvetkov and Graham Neubig'], ['Bipartite Flat-Graph Network for Nested Named Entity Recognition', 'Ying Luo and Hai Zhao'], ['Boosting Neural Machine Translation with Similar Translations', 'Jitao XU, Josep Crego and Jean Senellart'], ['Bridging the Structural Gap Between Encoding and Decoding for Data-To-Text Generation', 'Chao Zhao, Marilyn Walker and Snigdha Chaturvedi'], ['Building a User-Generated Content North-African Arabizi Treebank: Tackling Hell', 'Djamé Seddah, Farah Essaidi, Amal Fethi, Matthieu Futeral, Benjamin Muller, Pedro Javier Ortiz Suárez, Benoît Sagot and Abhishek Srivastava'], ['CDL: Curriculum Dual Learning for Emotion-Controllable Response Generation', 'Lei Shen and Yang Feng'], ['Compositionality and Generalization In Emergent Languages', 'Rahma Chaabouni, Eugene Kharitonov, Diane Bouchacourt, Emmanuel Dupoux and Marco Baroni'], ['Continual Relation Learning via Episodic Memory Activation and Reconsolidation', 'Xu Han, Yi Dai, Tianyu Gao, Yankai Lin, Zhiyuan Liu, Peng Li, Maosong Sun and Jie Zhou'], ['Curriculum Pre-training for End-to-End Speech Translation', 'Chengyi Wang, Yu Wu, Shujie Liu, Ming Zhou and Zhenglu Yang'], ['Detecting Perceived Emotions in Hurricane Disasters', 'Shrey Desai, Cornelia Caragea and Junyi Jessy Li'], ['DRTS Parsing with Structure-Aware Encoding and Decoding', 'Qiankun Fu, Yue Zhang, Jiangming Liu and Meishan Zhang'], ['Dynamic Fusion Network for Multi-Domain End-to-end Task-Oriented Dialog', 'Libo Qin, Xiao Xu, Wanxiang Che, Yue Zhang and Ting Liu'], ['Emergence of Syntax Needs Minimal Supervision', 'Raphaël Bailly and Kata Gábor'], ['Emerging Cross-lingual Structure in Pretrained Language Models', 'Alexis Conneau, Shijie Wu, Haoran Li, Luke Zettlemoyer and Veselin Stoyanov'], ['End-to-End Neural Pipeline for Goal-Oriented Dialogue Systems using GPT-2', 'Donghoon Ham, Jeong-Gwan Lee, Youngsoo Jang and Kee-Eung Kim'], ['ESPRIT: Explaining Solutions to Physical Reasoning Tasks', 'Nazneen Fatema Rajani, Rui Zhang, Yi Chern Tan, Stephan Zheng, Jeremy Weiss, Aadit Vyas, Abhijit Gupta, Caiming Xiong, Richard Socher and Dragomir Radev'], ['Evaluating and Enhancing the Robustness of Neural Network-based Dependency Parsing Models with Adversarial Examples', 'Xiaoqing Zheng, Jiehang Zeng, Yi Zhou, Cho-Jui Hsieh, Minhao Cheng and Xuanjing Huang'], ['Evaluating Explainable AI: Which Algorithmic Explanations Help Users Predict Model Behavior?', 'Peter Hase and Mohit Bansal'], ['Evaluating Explanation Methods for Neural Machine Translation', 'Jierui Li, Lemao Liu, Huayang Li, Guanlin Li, Guoping Huang and Shuming Shi'], ['Expertise Style Transfer: A New Task Towards Better Communication between Experts and Laymen', 'Yixin Cao, Ruihao Shui, Liangming Pan, Min-Yen Kan, Zhiyuan Liu and Tat-Seng Chua'], ['Explicit Semantic Decomposition for Definition Generation', 'Jiahuan Li, Yu Bao, Shujian Huang, Xinyu Dai and Jiajun Chen'], ['Gender in Danger? Evaluating Speech Translation Technology on the MuST-SHE Corpus', 'Luisa Bentivogli, Beatrice Savoldi, Matteo Negri, Mattia A. Di Gangi, Roldano Cattoni and Marco Turchi'], ['Generate, Delete and Rewrite: A Three-Stage Framework for Improving Persona Consistency of Dialogue Generation', 'Haoyu Song, Yan Wang, Wei-Nan Zhang, Xiaojiang Liu and Ting Liu'], ['Generative Semantic Hashing Enhanced via Boltzmann Machines', 'Lin Zheng, Qinliang Su, Dinghan Shen and Changyou Chen'], ['Hard-Coded Gaussian Attention for Neural Machine Translation', 'Weiqiu You, Simeng Sun and Mohit Iyyer'], ['Hiring Now: A Skill-Aware Multi-Attention Model for Job Posting Generation', 'Liting Liu, Jie Liu, Wenzheng Zhang, Ziming Chi, Wenxuan Shi and Yalou Huang'], ['Improving Chinese Word Segmentation with Wordhood Memory Networks', 'Yuanhe Tian, Yan Song, Fei Xia, Tong Zhang and Yonggang Wang'], ['Improving Massively Multilingual Neural Machine Translation and Zero-Shot Translation', 'Biao Zhang, Philip Williams, Ivan Titov and Rico Sennrich'], ['Improving Multimodal Named Entity Recognition via Entity Span Detection with Unified Multimodal Transformer', 'Jianfei Yu, Jing Jiang, Li Yang and Rui Xia'], ['Improving Segmentation for Technical Support Problems', 'Kushal Chauhan and Abhirut Gupta'], ['Improving Truthfulness of Headline Generation', 'Kazuki Matsumaru, Sho Takase and Naoaki Okazaki'], ['In Neural Machine Translation, What Does Transfer Learning Transfer?', 'Alham Fikri Aji, Nikolay Bogoychev, Kenneth Heafield and Rico Sennrich'], ['Inflecting when there’s no majority: Limitations of encoder-decoder neural networks as cognitive models for German plurals', 'Kate McCurdy, Sharon Goldwater and Adam Lopez'], ['Intermediate-Task Transfer Learning with Pretrained Language Models: When and Why Does It Work?', 'Yada Pruksachatkun, Jason Phang, Haokun Liu, Phu Mon Htut, Xiaoyi Zhang, Richard Yuanzhe Pang, Clara Vania, Katharina Kann and Samuel R. Bowman'], ['It’s Morphin’ Time! Combating Linguistic Discrimination with Inflectional Perturbations', 'Samson Tan, Shafiq Joty, Min-Yen Kan and Richard Socher'], ['Joint Modelling of Emotion and Abusive Language Detection', 'Santhosh Rajamanickam, Pushkar Mishra, Helen Yannakoudakis and Ekaterina Shutova'], ['Language Models as an Alternative Evaluator of Word Order Hypotheses: A Case Study in Japanese', 'Tatsuki Kuribayashi, Takumi Ito, Jun Suzuki and Kentaro Inui'], ['Learning a Multi-Domain Curriculum for Neural Machine Translation', 'Wei Wang, Ye Tian, Jiquan Ngiam, Yinfei Yang, Isaac Caswell and Zarana Parekh'], ['Learning and Evaluating Emotion Lexicons for 91 Languages', 'Sven Buechel, Susanna Rücker and Udo Hahn'], ['Learning Dialog Policies from Weak Demonstrations', 'Gabriel Gordon-Hall, Philip John Gorinski and Shay B. Cohen'], ['Learning Efficient Dialogue Policy from Demonstrations through Shaping', 'Huimin Wang, Baolin Peng and Kam-Fai Wong'], ['Learning to Deceive with Attention-Based Explanations', 'Danish Pruthi, Mansi Gupta, Bhuwan Dhingra, Graham Neubig and Zachary C. Lipton'], ['Learning to Recover from Multi-Modality Errors for Non-Autoregressive Neural Machine Translation', 'Qiu Ran, Yankai Lin, Peng Li and Jie Zhou'], ['Line Graph Enhanced AMR-to-Text Generation with Mix-Order Graph Attention Networks', 'Yanbin Zhao, Lu Chen, Zhi Chen, Ruisheng Cao, Su Zhu and Kai Yu'], ['MIE: A Medical Information Extractor towards Medical Dialogues', 'Yuanzhe Zhang, Zhongtao Jiang, Tao Zhang, Shiwan Liu, Jiarun Cao, Kang Liu, Shengping Liu and Jun Zhao'], ['MMPE: A Multi-Modal Interface for Post-Editing Machine Translation', 'Nico Herbig, Tim Düwel, Santanu Pal, Kalliopi Maria Meladaki, Mahsa Monshizadeh, Antonio Krüger and Josef van Genabith'], ['Multi-Agent Task-Oriented Dialog Policy Learning with Role-Aware Reward Decomposition', 'Ryuichi Takanobu, Runze Liang and Minlie Huang'], ['Multi-Domain Dialogue Acts and Response Co-Generation', 'Kai Wang, Junfeng Tian, Rui Wang, Xiaojun Quan and Jianxing Yu'], ['Multi-Hypothesis Machine Translation Evaluation', 'Marina Fomicheva, Lucia Specia and Francisco Guzmán'], ['Named Entity Recognition without Labelled Data: A Weak Supervision Approach', 'Pierre Lison, Jeremy Barnes, Aliaksandr Hubin and Samia Touileb'], ['Negative Training for Neural Dialogue Response Generation', 'Tianxing He and James Glass'], ['Neighborhood Matching Network for Entity Alignment', 'Yuting Wu, Xiao Liu, Yansong Feng, Zheng Wang and Dongyan Zhao'], ['Neural Generation of Dialogue Response Timings', 'Matthew Roddy and Naomi Harte'], ['Neural Reranking for Dependency Parsing: An Evaluation', 'Bich-Ngoc Do and Ines Rehbein'], ['Neural Syntactic Preordering for Controlled Paraphrase Generation', 'Tanya Goyal and Greg Durrett'], ['Norm-Based Curriculum Learning for Neural Machine Translation', 'Xuebo Liu, Houtim Lai, Derek F. Wong and Lidia S. Chao'], ['On The Evaluation of Machine Translation SystemsTrained With Back-Translation', 'Sergey Edunov, Myle Ott, Marc’Aurelio Ranzato and Michael Auli'], ['On the Robustness of Language Encoders against Grammatical Errors', 'Fan Yin, Quanyu Long, Tao Meng and Kai-Wei Chang'], ['Paraphrase Augmented Task-Oriented Dialog Generation', 'Silin Gao, Yichi Zhang, Zhijian Ou and Zhou Yu'], ['Phone Features Improve Speech Translation', 'Elizabeth Salesky and Alan W Black'], ['Pyramid: A Layered Model for Nested Named Entity Recognition', 'Jue Wang, Lidan Shou, Ke Chen and Gang Chen'], ['Recurrent Neural Network Language Models Always Learn English-Like Relative Clause Attachment', 'Forrest Davis and Marten van Schijndel'], ['Robust Encodings: A Framework for Combating Adversarial Typos', 'Erik Jones, Robin Jia, Aditi Raghunathan and Percy Liang'], ['S2ORC: The Semantic Scholar Open Research Corpus', 'Kyle Lo, Lucy Wang, Mark Neumann, Rodney Kinney and Daniel Weld'], ['Semi-Supervised Dialogue Policy Learning via Stochastic Reward Estimation', 'Xinting Huang, Jianzhong Qi, Yu Sun and Rui Zhang'], ['SimulSpeech: End-to-End Simultaneous Speech to Text Translation', 'Yi Ren, Jinglin Liu, Xu Tan, Chen Zhang, Tao Qin, Zhou Zhao and Tie-Yan Liu'], ['Slot-consistent NLG for Task-oriented Dialogue Systems with Iterative Rectification Network', 'Yangming Li, Kaisheng Yao, Libo Qin, Wanxiang Che, Xiaolong Li and Ting Liu'], ['Sources of Transfer in Multilingual Named Entity Recognition', 'David Mueller, Nicholas Andrews and Mark Dredze'], ['Speaker Sensitive Response Evaluation Model', 'JinYeong Bak and Alice Oh'], ['Speech Translation and the End-to-End Promise: Taking Stock of Where We Are', 'Matthias Sperber and Matthias Paulik'], ['Structured Tuning for Semantic Role Labeling', 'Tao Li, Parth Anand Jawale, Martha Palmer and Vivek Srikumar'], ['TACRED Revisited: A Thorough Evaluation of the TACRED Relation Extraction Task', 'Christoph Alt, Aleksandra Gabryszak and Leonhard Hennig'], ['Tangled up in BLEU: Reevaluating the Evaluation of Automatic Machine Translation Evaluation Metrics', 'Nitika Mathur, Timothy Baldwin and Trevor Cohn'], ['The Paradigm Discovery Problem', 'Alexander Erdmann, Micha Elsner, Shijie Wu, Ryan Cotterell and Nizar Habash'], ['The SOFC-Exp Corpus and Neural Approaches to Information Extraction in the Materials Science Domain', 'Annemarie Friedrich, Heike Adel, Federico Tomazic, Johannes Hingerl, Renou Benteau, Anika Marusczyk and Lukas Lange'], ['Uncertainty-Aware Curriculum Learning for Neural Machine Translation', 'Yikai Zhou, Baosong Yang, Derek F. Wong, Yu Wan and Lidia S. Chao'], ['Unsupervised Dual Paraphrasing for Two-stage Semantic Parsing', 'Ruisheng Cao, Su Zhu, Chenyu Yang, Chen Liu, Rao Ma, Yanbin Zhao, Lu Chen and Kai Yu'], ['Unsupervised Multimodal Neural Machine Translation with Pseudo Visual Pivoting', 'Po-Yao Huang, Junjie Hu, Xiaojun Chang and Alexander Hauptmann'], ['When do Word Embeddings Accurately Reflect Surveys on our Beliefs About People?', 'Kenneth Joseph and Jonathan Morgan']], 'model text domain': [['A Comprehensive Analysis of Preprocessing for Word Representation Learning in Affective Tasks', 'Nastaran Babanejad, Ameeta Agrawal, Aijun An and Manos Papagelis'], ['A Contextual Hierarchical Attention Network with Adaptive Objective for Dialogue State Tracking', 'Yong Shan, Zekang Li, Jinchao Zhang, Fandong Meng, Yang Feng, Cheng Niu and Jie Zhou'], ['A Formal Hierarchy of RNN Architectures', 'William Merrill, Gail Weiss, Yoav Goldberg, Roy Schwartz, Noah A. Smith and Eran Yahav'], ['A Graph Auto-encoder Model of Derivational Morphology', 'Valentin Hofmann, Hinrich Schütze and Janet Pierrehumbert'], ['A Mixture of h − 1 Heads is Better than h Heads', 'Hao Peng, Roy Schwartz, Dianqi Li and Noah A. Smith'], ['A Prioritization Model for Suicidality Risk Assessment', 'Han-Chin Shing, Philip Resnik and Douglas Oard'], ['A Study of Non-autoregressive Model for Sequence Generation', 'Yi Ren, Jinglin Liu, Xu Tan, Zhou Zhao, Sheng Zhao and Tie-Yan Liu'], ['A Systematic Assessment of Syntactic Generalization in Neural Language Models', 'Jennifer Hu, Jon Gauthier, Peng Qian, Ethan Wilcox and Roger Levy'], ['A Tale of Two Perplexities: Sensitivity of Neural Language Models to Lexical Retrieval Deficits in Dementia of the Alzheimer’s Type', 'Trevor Cohen and Serguei Pakhomov'], ['Adversarial and Domain-Aware BERT for Cross-Domain Sentiment Analysis', 'Chunning Du, Haifeng Sun, Jingyu Wang, Qi Qi and Jianxin Liao'], ['AMR Parsing via Graph-Sequence Iterative Inference', 'Deng Cai and Wai Lam'], ['An analysis of the utility of explicit negative examples to improve the syntactic abilities of neural language models', 'Hiroshi Noji and Hiroya Takamura'], ['An Effectiveness Metric for Ordinal Classification: Formal Properties and Experimental Results', 'Enrique Amigo, Julio Gonzalo, Stefano Mizzaro and Jorge Carrillo-de-Albornoz'], ['An Online Semantic-enhanced Dirichlet Model for Short Text Stream Clustering', 'Jay Kumar, Junming Shao, Salah Uddin and Wazir Ali'], ['Attentive Pooling with Learnable Norms for Text Representation', 'Chuhan Wu, Fangzhao Wu, Tao Qi, Xiaohui Cui and Yongfeng Huang'], ['Autoencoding Pixies: Amortised Variational Inference with Graph Convolutions for Functional Distributional Semantics', 'Guy Emerson'], ['Beyond Accuracy: Behavioral Testing of NLP Models with CheckList', 'Marco Tulio Ribeiro, Tongshuang Wu, Carlos Guestrin and Sameer Singh'], ['Beyond Possession Existence: Duration and Co-Possession', 'Dhivya Chinnappa, Srikala Murugan and Eduardo Blanco'], ['Beyond User Self-Reported Likert Scale Ratings: A Comparison Model for Automatic Dialog Evaluation', 'Weixin Liang, James Zou and Zhou Yu'], ['BLEURT: Learning Robust Metrics for Text Generation', 'Thibault Sellam, Dipanjan Das and Ankur Parikh'], ['Clinical Reading Comprehension: A Thorough Analysis of the emrQA Dataset', 'Xiang Yue, Bernal Jimenez Gutierrez and Huan Sun'], ['Contextualized Weak Supervision for Text Classification', 'Dheeraj Mekala and Jingbo Shang'], ['Dense-Caption Matching and Frame-Selection Gating for Temporal Localization in VideoQA', 'Hyounghun Kim, Zineng Tang and Mohit Bansal'], ['Dialogue Coherence Assessment Without Explicit Dialogue Act Labels', 'Mohsen Mesgar, Sebastian Bücker and Iryna Gurevych'], ['Discrete Latent Variable Representations for Low-Resource Text Classification', 'Shuning Jin, Sam Wiseman, Karl Stratos and Karen Livescu'], ['Distilling Knowledge Learned in BERT for Text Generation', 'Yen-Chun Chen, Zhe Gan, Yu Cheng, Jingzhou Liu and Jingjing Liu'], ['Distinguish Confusing Law Articles for Legal Judgment Prediction', 'Nuo Xu, Pinghui Wang, Long Chen, Li Pan, Xiaoyan Wang and Junzhou Zhao'], ['Diversifying Dialogue Generation with Non-Conversational Text', 'Hui Su, Xiaoyu Shen, Sanqiang Zhao, Zhou Xiao, Pengwei Hu, Randy Zhong, Cheng Niu and Jie Zhou'], ['Do Neural Language Models Show Preferences for Syntactic Formalisms?', 'Artur Kulmizev, Vinit Ravishankar, Mostafa Abdou and Joakim Nivre'], ['Document Modeling with Graph Attention Networks for Multi-grained Machine Reading Comprehension', 'Bo Zheng, Haoyang Wen, Yaobo Liang, Nan Duan, Wanxiang Che, Daxin Jiang, Ming Zhou and Ting Liu'], ['Don’t Stop Pretraining: Adapt Language Models to Domains and Tasks', 'Suchin Gururangan, Ana Marasović, Swabha Swayamdipta, Kyle Lo, Iz Beltagy, Doug Downey and Noah A. Smith'], ['Efficient Dialogue State Tracking by Selectively Overwriting Memory', 'Sungdong Kim, Sohee Yang, Gyuwan Kim and Sang-Woo Lee'], ['Efficient Pairwise Annotation of Argument Quality', 'Lukas Gienapp, Benno Stein, Matthias Hagen and Martin Potthast'], ['Enhancing Answer Boundary Detection for Multilingual Machine Reading Comprehension', 'Fei Yuan, Linjun Shou, Xuanyu Bai, Ming Gong, Yaobo Liang, Nan Duan, Yan Fu and Daxin Jiang'], ['Estimating the influence of auxiliary tasks for multi-task learning of sequence tagging tasks', 'Fynn Schröder and Chris Biemann'], ['Exact yet Efficient Graph Parsing, Bi-directional Locality and the Constructivist Hypothesis', 'Yajie Ye and Weiwei Sun'], ['Extracting Headless MWEs from Dependency Parse Trees: Parsing, Tagging, and Joint Modeling Approaches', 'Tianze Shi and Lillian Lee'], ['Fast and Accurate Non-Projective Dependency Tree Linearization', 'Xiang Yu, Simon Tannert, Ngoc Thang Vu and Jonas Kuhn'], ['FastBERT: a Self-distilling BERT with Adaptive Inference Time', 'Weijie Liu, Peng Zhou, Zhiruo Wang, Zhe Zhao, Haotang Deng and QI JU'], ['Feature Projection for Improved Text Classification', 'Qi Qin, Wenpeng Hu and Bing Liu'], ['Finding Universal Grammatical Relations in Multilingual BERT', 'Ethan A. Chi, John Hewitt and Christopher D. Manning'], ['From Zero to Hero: Human-In-The-Loop Entity Linking in Low Resource Domains', 'Jan-Christoph Klie, Richard Eckart de Castilho and Iryna Gurevych'], ['Generalized Entropy Regularization or: There’s Nothing Special about Label Smoothing', 'Clara Meister, Elizabeth Salesky and Ryan Cotterell'], ['Generalizing Natural Language Analysis through Span-relation Representations', 'Zhengbao Jiang, Wei Xu, Jun Araki and Graham Neubig'], ['Generating Hierarchical Explanations on Text Classification via Feature Interaction Detection', 'Hanjie Chen, Guangtao Zheng and Yangfeng Ji'], ['Graph Neural News Recommendation with Unsupervised Preference Disentanglement', 'Linmei Hu, Siyong Xu, Chen Li, Cheng Yang, Chuan Shi, Nan Duan, Xing Xie and Ming Zhou'], ['Grounding Conversations with Improvised Dialogues', 'Hyundong Cho and Jonathan May'], ['Heterogeneous Graph Transformer for Graph-to-Sequence Learning', 'Shaowei Yao, Tianming Wang and Xiaojun Wan'], ['Hierarchy-Aware Global Model for Hierarchical Text Classification', 'Jie Zhou, Chunping Ma, Dingkun Long, Guangwei Xu, Ning Ding, Haoyu Zhang, Pengjun Xie and Gongshen Liu'], ['How does BERT’s attention change when you fine-tune? An analysis methodology and a case study in negation scope', 'Yiyun Zhao and Steven Bethard'], ['How Does Selective Mechanism Improve Self-Attention Networks?', 'Xinwei Geng, Longyue Wang, Xing Wang, Bing Qin, Ting Liu and Zhaopeng Tu'], ['Human Attention Maps for Text Classification: Do Humans and Neural Networks Focus on the Same Words?', 'Cansu Sen, Thomas Hartvigsen, Biao Yin, Xiangnan Kong and Elke Rundensteiner'], ['Hyperbolic Capsule Networks for Multi-Label Classification', 'Boli Chen, Xin Huang, Lin Xiao and Liping Jing'], ['Improving Adversarial Text Generation by Modeling the Distant Future', 'Ruiyi Zhang, Changyou Chen, Zhe Gan, Wenlin Wang, Dinghan Shen, Guoyin Wang, Zheng Wen and Lawrence Carin'], ['Improving Disentangled Text Representation Learning with Information-Theoretic Guidance', 'Pengyu Cheng, Martin Renqiang Min, Dinghan Shen, Christopher Malon, Yizhe Zhang, Yitong Li and Lawrence Carin'], ['Improving Image Captioning Evaluation by Considering Inter References Variance', 'Yanzhi Yi, Hangyu Deng and Jinglu Hu'], ['Improving Transformer Models by Reordering their Sublayers', 'Ofir Press, Noah A. Smith and Omer Levy'], ['Information-Theoretic Probing for Linguistic Structure', 'Tiago Pimentel, Josef Valvoda, Rowan Hall Maudslay, Ran Zmigrod, Adina Williams and Ryan Cotterell'], ['INSET: Sentence Infilling with INter-SEntential Transformer', 'Yichen Huang, Yizhe Zhang, Oussama Elachqar and Yu Cheng'], ['Interactive Machine Comprehension with Information Seeking Agents', 'Xingdi Yuan, Jie Fu, Marc-Alexandre Côté, Yi Tay, Chris Pal and Adam Trischler'], ['It Takes Two to Lie: One to Lie, and One to Listen', 'Denis Peskov, Benny Cheng, Ahmed Elgohary, Joe Barrow, Cristian Danescu-Niculescu-Mizil and Jordan Boyd-Graber'], ['Jointly Masked Sequence-to-Sequence Model for Non-Autoregressive Neural Machine Translation', 'Junliang Guo, Linli Xu and Enhong Chen'], ['KdConv: A Chinese Multi-domain Dialogue Dataset Towards Multi-turn Knowledge-driven Conversation', 'Hao Zhou, Chujie Zheng, Kaili Huang, Minlie Huang and Xiaoyan Zhu'], ['KLEJ: Comprehensive Benchmark for Polish Language Understanding', 'Piotr Rybak, Robert Mroczkowski, Janusz Tracz and Ireneusz Gawlik'], ['Knowledge Distillation for Multilingual Unsupervised Neural Machine Translation', 'Haipeng Sun, Rui Wang, Kehai Chen, Masao Utiyama, Eiichiro Sumita and Tiejun Zhao'], ['Learning Architectures from an Extended Search Space for Language Modeling', 'Yinqiao Li, Chi Hu, Yuhao Zhang, Nuo Xu, Yufan Jiang, Tong Xiao, Jingbo Zhu, Tongran Liu and Changliang Li'], ['Learning to Customize Model Structures for Few-shot Dialogue Generation Tasks', 'Yiping Song, Zequn Liu, Wei Bi, Rui Yan and Ming Zhang'], ['Masked Language Model Scoring', 'Julian Salazar, Davis Liang, Toan Q. Nguyen and Katrin Kirchhoff'], ['Max-Margin Incremental CCG Parsing', 'Miloš Stanojević and Mark Steedman'], ['Meta-Reinforced Multi-Domain State Generator for Dialogue Systems', 'Yi Huang, Junlan Feng, Min Hu, Xiaoting Wu, Xiaoyu Du and Shuo Ma'], ['Mind the Trade-off: Debiasing NLU Models without Degrading the In-distribution Performance', 'Prasetya Ajie Utama, Nafise Sadat Moosavi and Iryna Gurevych'], ['MixText: Linguistically-Informed Interpolation of Hidden Space for Semi-Supervised Text Classification', 'Jiaao Chen, Zichao Yang and Diyi Yang'], ['Multi-Cell Compositional LSTM for NER Domain Adaptation', 'Chen Jia and Yue Zhang'], ['Multi-Domain Named Entity Recognition with Genre-Aware and Agnostic Inference', 'Jing Wang, Mayank Kulkarni and Daniel Preotiuc-Pietro'], ['Multi-Domain Neural Machine Translation with Word-Level Adaptive Layer-wise Domain Mixing', 'Haoming Jiang, Chen Liang, Chong Wang and Tuo Zhao'], ['Multi-Label and Multilingual News Framing Analysis', 'Afra Feyza Akyürek, Lei Guo, Randa Elanwar, Prakash Ishwar, Margrit Betke and Derry Tanti Wijaya'], ['Multiscale Collaborative Deep Models for Neural Machine Translation', 'Xiangpeng Wei, Heng Yu, Yue Hu, Yue Zhang, Rongxiang Weng and Weihua Luo'], ['MuTual: A Dataset for Multi-Turn Dialogue Reasoning', 'Leyang Cui, Yu Wu, Shujie Liu, Yue Zhang and Ming Zhou'], ['NAT: Noise-Aware Training for Robust Neural Sequence Labeling', 'Marcin Namysl, Sven Behnke and Joachim Köhler'], ['Neural CRF Model for Sentence Alignment in Text Simplification', 'Chao Jiang, Mounica Maddela, Wuwei Lan, Yang Zhong and Wei Xu'], ['Neural Mixed Counting Models for Dispersed Topic Discovery', 'Jiemin Wu, Yanghui Rao, Zusheng Zhang, Haoran Xie, Qing Li, Fu Lee Wang and Ziye Chen'], ['Not All Claims are Created Equal: Choosing the Right Statistical Approach to Assess Hypotheses', 'Erfan Sadeqi Azer, Daniel Khashabi, Ashish Sabharwal and Dan Roth'], ['Perturbed Masking: Parameter-free Probing for Analyzing and Interpreting BERT', 'Zhiyong Wu, Yun Chen, Ben Kao and Qun Liu'], ['PLATO: Pre-trained Dialogue Generation Model with Discrete Latent Variable', 'Siqi Bao, Huang He, Fan Wang, Hua Wu and Haifeng Wang'], ['Predicting the Focus of Negation: Model and Error Analysis', 'Md Mosharaf Hossain, Kathleen Hamilton, Alexis Palmer and Eduardo Blanco'], ['Premise Selection in Natural Language Mathematical Texts', 'Deborah Ferreira and André Freitas'], ['Probing Linguistic Systematicity', 'Emily Goodwin, Koustuv Sinha and Timothy J. O’Donnell'], ['RAT-SQL: Relation-Aware Schema Encoding and Linking for Text-to-SQL Parsers', 'Bailin Wang, Richard Shin, Xiaodong Liu, Oleksandr Polozov and Matthew Richardson'], ['(Re)construing Meaning in NLP', 'Sean Trott, Tiago Timponi Torrent, Nancy Chang and Nathan Schneider'], ['Selective Question Answering under Domain Shift', 'Amita Kamath, Robin Jia and Percy Liang'], ['Semi-supervised Contextual Historical Text Normalization', 'Peter Makarov and Simon Clematide'], ['SeqVAT: Virtual Adversarial Training for Semi-Supervised Sequence Labeling', 'Luoxin Chen, Weitong Ruan, Xinyue Liu and Jianhua Lu'], ['Similarity Analysis of Contextual Word Representation Models', 'John Wu, Yonatan Belinkov, Hassan Sajjad, Nadir Durrani, Fahim Dalvi and James Glass'], ['Simplify the Usage of Lexicon in Chinese NER', 'Ruotian Ma, Minlong Peng, Qi Zhang, Zhongyu Wei and Xuanjing Huang'], ['Speakers enhance contextually confusable words', 'Eric Meinhardt, Eric Bakovic and Leon Bergen'], ['SPECTER: Document-level Representation Learning using Citation-informed Transformers', 'Arman Cohan, Sergey Feldman, Iz Beltagy, Doug Downey and Daniel Weld'], ['Storytelling with Dialogue: A Critical Role Dungeons and Dragons Dataset', 'Revanth Rameshkumar and Peter Bailey'], ['Structure-Level Knowledge Distillation For Multilingual Sequence Labeling', 'Xinyu Wang, Yong Jiang, Nguyen Bach, Tao Wang, Fei Huang and Kewei Tu'], ['Suspense in Short Stories is Predicted By Uncertainty Reduction over Neural Story Representation', 'David Wilmot and Frank Keller'], ['Syntax-Aware Opinion Role Labeling with Dependency Graph Convolutional Networks', 'Bo Zhang, Yue Zhang, Rui Wang, Zhenghua Li and Min Zhang'], ['Tchebycheff Procedure for Multi-task Text Classification', 'Yuren Mao, Shuang Yun, Weiwei Liu and Bo Du'], ['The Cascade Transformer: an Application for Efficient Answer Sentence Selection', 'Luca Soldaini and Alessandro Moschitti'], ['The Right Tool for the Job: Matching Model and Instance Complexities', 'Roy Schwartz, Gabriel Stanovsky, Swabha Swayamdipta, Jesse Dodge and Noah A. Smith'], ['To Test Machine Comprehension, Start by Defining Comprehension', 'Jesse Dunietz, Greg Burnham, Akash Bharadwaj, Owen Rambow, Jennifer Chu-Carroll and Dave Ferrucci'], ['Towards Conversational Recommendation over Multi-Type Dialogs', 'Zeming Liu, Haifeng Wang, Zheng-Yu Niu, Hua Wu, Wanxiang Che and Ting Liu'], ['Towards Debiasing Sentence Representations', 'Paul Pu Liang, Irene Mengze Li, Emily Zheng, Yao Chong Lim, Ruslan Salakhutdinov and Louis-Philippe Morency'], ['Understanding Attention for Text Classification', 'Xiaobing Sun and Wei Lu'], ['Understanding the Language of Political Agreement and Disagreement in Legislative Texts', 'Maryam Davoodi, Eric Waltenburg and Dan Goldwasser'], ['Unknown Intent Detection Using Gaussian Mixture Model with an Application to Zero-shot Intent Classification', 'Guangfeng Yan, Lu Fan, Qimai Li, Han Liu, Xiaotong Zhang, Xiao-Ming Wu and Albert Y.S. Lam'], ['Unsupervised Domain Clusters in Pretrained Language Models', 'Roee Aharoni and Yoav Goldberg'], ['Unsupervised Morphological Paradigm Completion', 'Huiming Jin, Liwei Cai, Yihui Peng, Chen Xia, Arya McCarthy and Katharina Kann'], ['Zero-shot Text Classification via Reinforced Self-training', 'Zhiquan Ye, Yuxia Geng, Jiaoyan Chen, Jingmin Chen, Xiaoxiao Xu, Suhang Zheng, Feng Wang, Jun Zhang and Huajun Chen'], ['Zero-Shot Transfer Learning with Synthesized Data for Multi-Domain Dialogue State Tracking', 'Giovanni Campagna, Agata Foryciarz, Mehrad Moradshahi and Monica Lam']], 'generat graph network': [['A Batch Normalized Inference Network Keeps the KL Vanishing Away', 'Qile Zhu, Wei Bi, Xiaojiang Liu, Xiyao Ma, Xiaolin Li and Dapeng Wu'], ['A Generate-and-Rank Framework with Semantic Type Regularization for Biomedical Concept Normalization', 'Dongfang Xu, Zeyu Zhang and Steven Bethard'], ['Automated Evaluation of Writing – 50 Years and Counting', 'Beata Beigman Klebanov and Nitin Madnani'], ['Automatic Poetry Generation from Prosaic Text', 'Tim Van de Cruys'], ['Balancing Objectives in Counseling Conversations: Advancing Forwards or Looking Backwards', 'Justine Zhang and Cristian Danescu-Niculescu-Mizil'], ['Bootstrapping Techniques for Polysynthetic Morphological Analysis', 'William Lane and Steven Bird'], ['Can We Predict New Facts with Open Knowledge Graph Embeddings? A Benchmark for Open Link Prediction', 'Samuel Broscheit, Kiril Gashteovski, Yanjie Wang and Rainer Gemulla'], ['Can You Put it All Together: Evaluating Conversational Agents’ Ability to Blend Skills', 'Eric Michael Smith, Mary Williamson, Kurt Shuster, Jason Weston and Y-Lan Boureau'], ['Code and Named Entity Recognition in StackOverflow', 'Jeniya Tabassum, Mounica Maddela, Wei Xu and Alan Ritter'], ['Conversational Graph Grounded Policy Learning for Open-Domain Conversation Generation', 'Jun Xu, Haifeng Wang, Zheng-Yu Niu, Hua Wu, Wanxiang Che and Ting Liu'], ['Cross-Linguistic Syntactic Evaluation of Word Prediction Models', 'Aaron Mueller, Garrett Nicolai, Panayiota Petrou-Zeniou, Natalia Talmina and Tal Linzen'], ['Cross-Modality Relevance for Reasoning on Language and Vision', 'Chen Zheng, Quan Guo and Parisa Kordjamshidi'], ['DeFormer: Decomposing Pre-trained Transformers for Faster Question Answering', 'Qingqing Cao, Harsh Trivedi, Aruna Balasubramanian and Niranjan Balasubramanian'], ['Demographics Should Not Be the Reason of Toxicity: Mitigating Discrimination in Text Classifications with Instance Weighting', 'Guanhua Zhang, Bing Bai, Junqi Zhang, Kun Bai, Conghui Zhu and Tiejun Zhao'], ['DeSePtion: Dual Sequence Prediction and Adversarial Examples for Improved Fact-Checking', 'Christopher Hidey, Tuhin Chakrabarty, Tariq Alhindi, Siddharth Varia, Kriste Krstovski, Mona Diab and Smaranda Muresan'], ['Evidence-Aware Inferential Text Generation with Vector Quantised Variational AutoEncoder', 'Daya Guo, Duyu Tang, Nan Duan, Jian Yin, Daxin Jiang and Ming Zhou'], ['Explicit Memory Tracker with Coarse-to-Fine Reasoning for Conversational Machine Reading', 'Yifan Gao, Chien-Sheng Wu, Shafiq Joty, Caiming Xiong, Richard Socher, Irwin King, Michael Lyu and Steven C.H. Hoi'], ['Fine-grained Fact Verification with Kernel Graph Attention Network', 'Zhenghao Liu, Chenyan Xiong, Maosong Sun and Zhiyuan Liu'], ['From English to Code-Switching: Transfer Learning with Strong Morphological Clues', 'Gustavo Aguilar and Thamar Solorio'], ['Generating Fact Checking Explanations', 'Pepa Atanasova, Jakob Grue Simonsen, Christina Lioma and Isabelle Augenstein'], ['GLUECoS: An Evaluation Benchmark for Code-Switched NLP', 'Simran Khanuja, Sandipan Dandapat, Anirudh Srinivasan, Sunayana Sitaram and Monojit Choudhury'], ['Good-Enough Compositional Data Augmentation', 'Jacob Andreas'], ['Grounded Conversation Generation as Guided Traverses in Commonsense Knowledge Graphs', 'Houyu Zhang, Zhenghao Liu, Chenyan Xiong and Zhiyuan Liu'], ['Harnessing the linguistic signal to predict scalar inferences', 'Sebastian Schuster, Yuxing Chen and Judith Degen'], ['History for Visual Dialog: Do we really need it?', 'Shubham Agarwal, Trung Bui, Joon-Young Lee, Ioannis Konstas and Verena Rieser'], ['How to Ask Good Questions? Try to Leverage Paraphrases', 'Xin Jia, Wenjie Zhou, Xu Sun and Yunfang Wu'], ['HyperCore: Hyperbolic and Co-graph Representation for Automatic ICD Coding', 'Pengfei Cao, Yubo Chen, Kang Liu, Jun Zhao, Shengping Liu and Weifeng Chong'], ['Image-Chat: Engaging Grounded Conversations', 'Kurt Shuster, Samuel Humeau, Antoine Bordes and Jason Weston'], ['Improving Event Detection via Open-domain Trigger Knowledge', 'Meihan Tong, Bin Xu, Shuai Wang, Yixin Cao, Lei Hou, Juanzi Li and Jun Xie'], ['Influence Paths for Characterizing Subject-Verb Number Agreement in LSTM Language Models', 'Kaiji Lu, Piotr Mardziel, Klas Leino, Matt Fredrikson and Anupam Datta'], ['Integrating Semantic and Structural Information with Graph Convolutional Network for Controversy Detection', 'Lei Zhong, Juan Cao, Qiang Sheng, Junbo Guo and Ziang Wang'], ['Joint Diacritization, Lemmatization, Normalization, and Fine-Grained Morphological Tagging', 'Nasser Zalmout and Nizar Habash'], ['Learning Constraints for Structured Prediction Using Rectifier Networks', 'Xingyuan Pan, Maitrey Mehta and Vivek Srikumar'], ['Learning Interpretable Relationships between Entities, Relations and Concepts via Bayesian Structure Learning on Open Domain Facts', 'Jingyuan Zhang, Mingming Sun, Yue Feng and Ping Li'], ['Learning Web-based Procedures by Reasoning over Explanations and Demonstrations in Context', 'Shashank Srivastava, Oleksandr Polozov, Nebojsa Jojic and Christopher Meek'], ['Logical Natural Language Generation from Open-Domain Tables', 'Wenhu Chen, Jianshu Chen, Yu Su, Zhiyu Chen and William Yang Wang'], ['LogicalFactChecker: Leveraging Logical Operations for Fact Checking with Graph Module Network', 'Wanjun Zhong, Duyu Tang, Zhangyin Feng, Nan Duan, Ming Zhou, Ming Gong, Linjun Shou, Daxin Jiang, Jiahai Wang and Jian Yin'], ['Moving Down the Long Tail of Word Sense Disambiguation with Gloss Informed Bi-encoders', 'Terra Blevins and Luke Zettlemoyer'], ['Obtaining Faithful Interpretations from Compositional Neural Networks', 'Sanjay Subramanian, Ben Bogin, Nitish Gupta, Tomer Wolfson, Sameer Singh, Jonathan Berant and Matt Gardner'], ['On the Limitations of Cross-lingual Encoders as Exposed by Reference-Free Machine Translation Evaluation', 'Wei Zhao, Goran Glavaš, Maxime Peyrard, Yang Gao, Robert West and Steffen Eger'], ['Parsing into Variable-in-situ Logico-Semantic Graphs', 'Yufei Chen and Weiwei Sun'], ['Predicting Declension Class from Form and Meaning', 'Adina Williams, Tiago Pimentel, Arya D. McCarthy, Hagen Blix, Eleanor Chodroff and Ryan Cotterell'], ['Predicting the Growth of Morphological Families from Social and Linguistic Factors', 'Valentin Hofmann, Janet Pierrehumbert and Hinrich Schütze'], ['Pre-training Is (Almost) All You Need: An Application to Commonsense Reasoning', 'Alexandre Tamborrino, Nicola Pellicanò, Baptiste Pannier, Pascal Voitot and Louise Naudin'], ['R^3: Reverse, Retrieve, and Rank for Sarcasm Generation with Commonsense Knowledge', 'Tuhin Chakrabarty, Debanjan Ghosh, Smaranda Muresan and Nanyun Peng'], ['Reasoning Over Semantic-Level Graph for Fact Checking', 'Wanjun Zhong, Jingjing Xu, Duyu Tang, Zenan Xu, Nan Duan, Ming Zhou, Jiahai Wang and Jian Yin'], ['Reasoning with Multimodal Sarcastic Tweets via Modeling Cross-Modality Contrast and Semantic Association', 'Nan Xu, Zhixiong Zeng and Wenji Mao'], ['Semantic Graphs for Generating Deep Questions', 'Liangming Pan, Yuxi Xie, Yansong Feng, Tat-Seng Chua and Min-Yen Kan'], ['Semantic Scaffolds for Pseudocode-to-Code Generation', 'Ruiqi Zhong, Mitchell Stern and Dan Klein'], ['Simple, Interpretable and Stable Method for Detecting Words with Usage Change across Corpora', 'Hila Gonen, Ganesh Jawahar, Djamé Seddah and Yoav Goldberg'], ['Single-/Multi-Source Cross-Lingual NER via Teacher-Student Learning on Unlabeled Data in Target Language', 'Qianhui Wu, Zijia Lin, Börje Karlsson, Jian-Guang Lou and Biqing Huang'], ['Target Inference in Argument Conclusion Generation', 'Milad Alshomary, Shahbaz Syed, Martin Potthast and Henning Wachsmuth'], ['Temporal Common Sense Acquisition with Minimal Supervision', 'Ben Zhou, Qiang Ning, Daniel Khashabi and Dan Roth'], ['Temporally-Informed Analysis of Named Entity Recognition', 'Shruti Rijhwani and Daniel Preotiuc-Pietro'], ['The Dialogue Dodecathlon: Open-Domain Knowledge and Image Grounded Conversational Agents', 'Kurt Shuster, Da JU, Stephen Roller, Emily Dinan, Y-Lan Boureau and Jason Weston'], ['Towards Holistic and Automatic Evaluation of Open-Domain Dialogue Generation', 'Bo Pang, Erik Nijkamp, Wenjuan Han, Linqi Zhou, Yixian Liu and Kewei Tu'], ['Towards Interpretable Clinical Diagnosis with Bayesian Network Ensembles Stacked on Entity-Aware CNNs', 'Jun Chen, Xiaoya Dai, Quan Yuan, Chao Lu and Haifeng Huang'], ['Transition-based Semantic Dependency Parsing with Pointer Networks', 'Daniel Fernández-González and Carlos Gómez-Rodríguez'], ['Universal Decompositional Semantic Parsing', 'Elias Stengel-Eskin, Aaron Steven White, Sheng Zhang and Benjamin Van Durme'], ['USR: An Unsupervised and Reference Free Evaluation Metric for Dialog Generation', 'Shikib Mehri and Maxine Eskenazi'], ['Weight Poisoning Attacks on Pretrained Models', 'Keita Kurita, Paul Michel and Graham Neubig']], 'model languag neural': [['2kenize: Tying Subword Sequences for Chinese Script Conversion', 'Pranav A and Isabelle Augenstein'], ['A Joint Neural Model for Information Extraction with Global Features', 'Ying Lin, Heng Ji, Fei Huang and Lingfei Wu'], ['A Novel Cascade Binary Tagging Framework for Relational Triple Extraction', 'Zhepei Wei, Jianlin Su, Yue Wang, Yuan Tian and Yi Chang'], ['Amalgamation of protein sequence, structure and textual information for improving protein-protein interaction identification', 'Pratik Dutta and Sriparna Saha'], ['BART: Denoising Sequence-to-Sequence Pre-training for Natural Language Generation, Translation, and Comprehension', 'Mike Lewis, Yinhan Liu, Naman Goyal, Marjan Ghazvininejad, Abdelrahman Mohamed, Omer Levy, Veselin Stoyanov and Luke Zettlemoyer'], ['Bilingual Dictionary Based Neural Machine Translation without Using Parallel Sentences', 'Xiangyu Duan, Baijun Ji, Hao Jia, Min Tan, Min Zhang, Boxing Chen, Weihua Luo and Yue Zhang'], ['Biomedical Entity Representations with Synonym Marginalization', 'Mujeen Sung, Hwisang Jeon, Jinhyuk Lee and Jaewoo Kang'], ['Bridging Anaphora Resolution as Question Answering', 'Yufang Hou'], ['CamemBERT: a Tasty French Language Model', 'Louis Martin, Benjamin Muller, Pedro Javier Ortiz Suárez, Yoann Dupont, Laurent Romary, Éric de la Clergerie, Djamé Seddah and Benoît Sagot'], ['ChartDialogs: Plotting from Natural Language Instructions', 'Yutong Shao and Ndapa Nakashole'], ['Climbing towards NLU: On Meaning, Form, and Understanding in the Age of Data', 'Emily M. Bender and Alexander Koller'], ['CluHTM - Semantic Hierarchical Topic Modeling based on CluWords', 'Felipe Viegas, Washington Cunha, Christian Gomes, Antônio Pereira, Leonardo Rocha and Marcos Goncalves'], ['CraftAssist Instruction Parsing: Semantic Parsing for a Voxel-World Assistant', 'Kavya Srinet, Yacine Jernite, Jonathan Gray and Arthur Szlam'], ['Cross-Lingual Semantic Role Labeling with High-Quality Translated Training Corpus', 'Hao Fei, Meishan Zhang and Donghong Ji'], ['Cross-modal Coherence Modeling for Caption Generation', 'Malihe Alikhani, Piyush Sharma, Shengjie Li, Radu Soricut and Matthew Stone'], ['Cross-modal Language Generation using Pivot Stabilization for Web-scale Language Coverage', 'Ashish V. Thapliyal and Radu Soricut'], ['Dynamic Online Conversation Recommendation', 'Xingshan Zeng, Jing Li, Lu Wang, Zhiming Mao and Kam-Fai Wong'], ['Effective Estimation of Deep Generative Language Models', 'Tom Pelsmaeker and Wilker Aziz'], ['Effective Inter-Clause Modeling for End-to-End Emotion-Cause Pair Extraction', 'Penghui Wei, Jiahao Zhao and Wenji Mao'], ['Efficient Second-Order TreeCRF for Neural Dependency Parsing', 'Yu Zhang, Zhenghua Li and Min Zhang'], ['Empower Entity Set Expansion via Language Model Probing', 'Yunyi Zhang, Jiaming Shen, Jingbo Shang and Jiawei Han'], ['End-to-End Bias Mitigation by Modelling Biases in Corpora', 'Rabeeh Karimi Mahabadi, Yonatan Belinkov and James Henderson'], ['Exclusive Hierarchical Decoding for Deep Keyphrase Generation', 'Wang Chen, Hou Pong Chan, Piji Li and Irwin King'], ['Explaining Black Box Predictions and Unveiling Data Artifacts through Influence Functions', 'Xiaochuang Han, Byron C. Wallace and Yulia Tsvetkov'], ['Exploring Unexplored Generalization Challenges for Cross-Database Semantic Parsing', 'Alane Suhr, Ming-Wei Chang, Peter Shaw and Kenton Lee'], ['Frugal Paradigm Completion', 'Alexander Erdmann, Tom Kenter, Markus Becker and Christian Schallhart'], ['Generating Counter Narratives against Online Hate Speech: Data and Strategies', 'Serra Sinem Tekiroğlu, Yi-Ling Chung and Marco Guerini'], ['Generating Informative Conversational Response using Recurrent Knowledge-Interaction and Knowledge-Copy', 'Xiexiong Lin, Weiyu Jian, Jianshan He, Taifeng Wang and Wei Chu'], ['Guiding Variational Response Generator to Exploit Persona', 'Bowen Wu, Mengyuan Li, Zongsheng Wang, Yifu Chen, Derek F. Wong, Qihang Feng, Junhong Huang and Baoxun Wang'], ['Handling Rare Entities for Neural Sequence Labeling', 'Yangming Li, Han Li, Kaisheng Yao and Xiaolong Li'], ['Hierarchical Modeling for User Personality Prediction: The Role of Message-Level Attention', 'Veronica Lynn, Niranjan Balasubramanian and H. Andrew Schwartz'], ['Improving Image Captioning with Better Use of Caption', 'Zhan Shi, Xu Zhou, Xipeng Qiu and Xiaodan Zhu'], ['Injecting Numerical Reasoning Skills into Language Models', 'Mor Geva, Ankit Gupta and Jonathan Berant'], ['Interactive Construction of User-Centric Dictionary for Text Analytics', 'Ryosuke Kohita, Issei Yoshida, Hiroshi Kanayama and Tetsuya Nasukawa'], ['Investigating the effect of auxiliary objectives for the automated grading of learner English speech transcriptions', 'Hannah Craighead, Andrew Caines, Paula Buttery and Helen Yannakoudakis'], ['Learning Source Phrase Representations for Neural Machine Translation', 'Hongfei Xu, Josef van Genabith, Deyi Xiong, Qiuhui Liu and Jingyi Zhang'], ['Location Attention for Extrapolation to Longer Sequences', 'Yann Dubois, Gautier Dagan, Dieuwke Hupkes and Elia Bruni'], ['MART: Memory-Augmented Recurrent Transformer for Coherent Video Paragraph Captioning', 'Jie Lei, Liwei Wang, Yelong Shen, Dong Yu, Tamara Berg and Mohit Bansal'], ['Measuring Forecasting Skill from Text', 'Shi Zong, Alan Ritter and Eduard Hovy'], ['MobileBERT: a Compact Task-Agnostic BERT for Resource-Limited Devices', 'Zhiqing Sun, Hongkun Yu, Xiaodan Song, Renjie Liu, Yiming Yang and Denny Zhou'], ['Neural Topic Modeling with Bidirectional Adversarial Training', 'Rui Wang, Xuemeng Hu, Deyu Zhou, Yulan He, Yuxuan Xiong, Chenchen Ye and Haiyang Xu'], ['On the Inference Calibration of Neural Machine Translation', 'Shuo Wang, Zhaopeng Tu, Shuming Shi and Yang Liu'], ['Parallel Corpus Filtering via Pre-trained Language Models', 'Boliang Zhang, Ajay Nagesh and Kevin Knight'], ['Phonetic and Visual Priors for Decipherment of Informal Romanization', 'Maria Ryskina, Matthew R. Gormley and Taylor Berg-Kirkpatrick'], ['Probing Linguistic Features of Sentence-Level Representations in Relation Extraction', 'Christoph Alt, Aleksandra Gabryszak and Leonhard Hennig'], ['PuzzLing Machines: A Challenge on Learning From Small Data', 'Gözde Gül Şahin, Yova Kementchedjhieva, Phillip Rust and Iryna Gurevych'], ['Reducing Gender Bias in Neural Machine Translation as a Domain Adaptation Problem', 'Danielle Saunders and Bill Byrne'], ['Roles and Utilization of Attention Heads in Transformer-based Neural Language Models', 'Jae-young Jo and Sung-Hyon Myaeng'], ['SCDE: Sentence Cloze Dataset with High Quality Distractors From Examinations', 'Xiang Kong, Varun Gangal and Eduard Hovy'], ['schuBERT: Optimizing Elements of BERT', 'Ashish Khetan and Zohar Karnin'], ['SciREX: A Challenge Dataset for Document-Level Information Extraction', 'Sarthak Jain, Madeleine van Zuylen, Hannaneh Hajishirzi and Iz Beltagy'], ['Selecting Backtranslated Data from Multiple Sources for Improved Neural Machine Translation', 'Xabier Soto, Dimitar Shterionov, Alberto Poncelas and Andy Way'], ['Semantic Parsing for English as a Second Language', 'Yuanyuan Zhao, Weiwei Sun, Junjie Cao and Xiaojun Wan'], ['Social Bias Frames: Reasoning about Social and Power Implications of Language', 'Maarten Sap, Saadia Gabriel, Lianhui Qin, Dan Jurafsky, Noah A. Smith and Yejin Choi'], ['The Sensitivity of Language Models and Humans to Winograd Schema Perturbations', 'Mostafa Abdou, Vinit Ravishankar, Maria Barrett, Yonatan Belinkov, Desmond Elliott and Anders Søgaard'], ['The State and Fate of Linguistic Diversity and Inclusion in the NLP World', 'Pratik Joshi, Sebastin Santy, Amar Budhiraja, Kalika Bali and Monojit Choudhury'], ['The Unstoppable Rise of Computational Linguistics in Deep Learning', 'James Henderson'], ['Toward Gender-Inclusive Coreference Resolution', 'Yang Trista Cao and Hal Daumé III'], ['Towards Robustifying NLI Models Against Lexical Dataset Biases', 'Xiang Zhou and Mohit Bansal'], ['Towards Transparent and Explainable Attention Models', 'Akash Kumar Mohankumar, Preksha Nema, Sharan Narasimhan, Mitesh M. Khapra, Balaji Vasan Srinivasan and Balaraman Ravindran'], ['Toxicity Detection: Does Context Really Matter?', 'John Pavlopoulos, Jeffrey Sorensen, Lucas Dixon, Nithum Thain and Ion Androutsopoulos'], ['Unsupervised Paraphrasing by Simulated Annealing', 'Xianggen Liu, Lili Mou, Fandong Meng, Hao Zhou, Jie Zhou and Sen Song'], ['WinoWhy: A Deep Diagnosis of Essential Commonsense Knowledge for Answering Winograd Schema Challenge', 'Hongming Zhang, Xinran Zhao and Yangqiu Song']]}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r  0%|          | 0/71 [00:02<?, ?it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "error",
          "ename": "HTTPError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mHTTPError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-63-cf4baeb4b8f9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"papers_with_arxiv_link_topic.md\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"w\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m   \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"## Long Papers\\n\\n\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m   \u001b[0mgenerate_paper_list_with_arxiv_link_topic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlongp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m   \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"## Short Papers\\n\\n\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m   \u001b[0mgenerate_paper_list_with_arxiv_link_topic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshort\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-61-1ce87bb79dfe>\u001b[0m in \u001b[0;36mgenerate_paper_list_with_arxiv_link_topic\u001b[0;34m(f, papers)\u001b[0m\n\u001b[1;32m      4\u001b[0m   \u001b[0;32mfor\u001b[0m \u001b[0mtopic\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtopic_papers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"###\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mtopic\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"\\n\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mgenerate_paper_list_with_arxiv_link\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtopic_papers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtopic\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-42-be07db6ef015>\u001b[0m in \u001b[0;36mgenerate_paper_list_with_arxiv_link\u001b[0;34m(f, papers)\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpapers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m         \u001b[0mtitle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mauthors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m         \u001b[0mlink\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msearch_arxiv_link\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlink\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m             \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"- {title} [[arXiv]]({link})\\n\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-41-c82cf37f4ce8>\u001b[0m in \u001b[0;36msearch_arxiv_link\u001b[0;34m(title)\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0msearch_arxiv_link\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0mlink\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msearch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtld\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"co.in\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpause\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m'arxiv.org/abs'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m             \u001b[0mthepage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0murllib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0murlopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/googlesearch/__init__.py\u001b[0m in \u001b[0;36msearch\u001b[0;34m(query, tld, lang, tbs, safe, num, start, stop, domains, pause, tpe, country, extra_params, user_agent)\u001b[0m\n\u001b[1;32m    310\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    311\u001b[0m         \u001b[0;31m# Request the Google Search results page.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 312\u001b[0;31m         \u001b[0mhtml\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_page\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muser_agent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    313\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    314\u001b[0m         \u001b[0;31m# Parse the response and get every anchored URL.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/googlesearch/__init__.py\u001b[0m in \u001b[0;36mget_page\u001b[0;34m(url, user_agent)\u001b[0m\n\u001b[1;32m    174\u001b[0m     \u001b[0mrequest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_header\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'User-Agent'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muser_agent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m     \u001b[0mcookie_jar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_cookie_header\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 176\u001b[0;31m     \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0murlopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    177\u001b[0m     \u001b[0mcookie_jar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextract_cookies\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    178\u001b[0m     \u001b[0mhtml\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/urllib/request.py\u001b[0m in \u001b[0;36murlopen\u001b[0;34m(url, data, timeout, cafile, capath, cadefault, context)\u001b[0m\n\u001b[1;32m    221\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    222\u001b[0m         \u001b[0mopener\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_opener\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 223\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mopener\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    224\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    225\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0minstall_opener\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopener\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/urllib/request.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(self, fullurl, data, timeout)\u001b[0m\n\u001b[1;32m    530\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mprocessor\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprocess_response\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprotocol\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m             \u001b[0mmeth\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocessor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmeth_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmeth\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/urllib/request.py\u001b[0m in \u001b[0;36mhttp_response\u001b[0;34m(self, request, response)\u001b[0m\n\u001b[1;32m    640\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m200\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0mcode\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m300\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    641\u001b[0m             response = self.parent.error(\n\u001b[0;32m--> 642\u001b[0;31m                 'http', request, response, code, msg, hdrs)\n\u001b[0m\u001b[1;32m    643\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    644\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/urllib/request.py\u001b[0m in \u001b[0;36merror\u001b[0;34m(self, proto, *args)\u001b[0m\n\u001b[1;32m    562\u001b[0m             \u001b[0mhttp_err\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    563\u001b[0m         \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mproto\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmeth_name\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 564\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_chain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    565\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    566\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/urllib/request.py\u001b[0m in \u001b[0;36m_call_chain\u001b[0;34m(self, chain, kind, meth_name, *args)\u001b[0m\n\u001b[1;32m    502\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhandler\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mhandlers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    503\u001b[0m             \u001b[0mfunc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmeth_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 504\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    505\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mresult\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    506\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/urllib/request.py\u001b[0m in \u001b[0;36mhttp_error_302\u001b[0;34m(self, req, fp, code, msg, headers)\u001b[0m\n\u001b[1;32m    754\u001b[0m         \u001b[0mfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    755\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 756\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    757\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    758\u001b[0m     \u001b[0mhttp_error_301\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhttp_error_303\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhttp_error_307\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhttp_error_302\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/urllib/request.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(self, fullurl, data, timeout)\u001b[0m\n\u001b[1;32m    530\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mprocessor\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprocess_response\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprotocol\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m             \u001b[0mmeth\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocessor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmeth_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmeth\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/urllib/request.py\u001b[0m in \u001b[0;36mhttp_response\u001b[0;34m(self, request, response)\u001b[0m\n\u001b[1;32m    640\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m200\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0mcode\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m300\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    641\u001b[0m             response = self.parent.error(\n\u001b[0;32m--> 642\u001b[0;31m                 'http', request, response, code, msg, hdrs)\n\u001b[0m\u001b[1;32m    643\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    644\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/urllib/request.py\u001b[0m in \u001b[0;36merror\u001b[0;34m(self, proto, *args)\u001b[0m\n\u001b[1;32m    568\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhttp_err\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    569\u001b[0m             \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'default'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'http_error_default'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0morig_args\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 570\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_chain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    571\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    572\u001b[0m \u001b[0;31m# XXX probably also want an abstract factory that knows when it makes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/urllib/request.py\u001b[0m in \u001b[0;36m_call_chain\u001b[0;34m(self, chain, kind, meth_name, *args)\u001b[0m\n\u001b[1;32m    502\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhandler\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mhandlers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    503\u001b[0m             \u001b[0mfunc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmeth_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 504\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    505\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mresult\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    506\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/urllib/request.py\u001b[0m in \u001b[0;36mhttp_error_default\u001b[0;34m(self, req, fp, code, msg, hdrs)\u001b[0m\n\u001b[1;32m    648\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mHTTPDefaultErrorHandler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBaseHandler\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    649\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mhttp_error_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmsg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhdrs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 650\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mHTTPError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfull_url\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmsg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhdrs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    651\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    652\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mHTTPRedirectHandler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBaseHandler\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mHTTPError\u001b[0m: HTTP Error 429: Too Many Requests"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": false,
        "id": "Gk2bFBdqCNRI",
        "colab_type": "code",
        "outputId": "bdbd8eec-b5de-4ad3-f6bc-ae612f11255b",
        "colab": {}
      },
      "source": [
        "with open(\"papers_with_arxiv_link.md\", \"w\") as f:\n",
        "    f.write(\"## Long Papers\\n\\n\")\n",
        "    generate_paper_list_with_arxiv_link(f, longp)\n",
        "    f.write(\"## Short Papers\\n\\n\")\n",
        "    generate_paper_list_with_arxiv_link(f, short)\n",
        "    f.write(\"## System Demonstrations\\n\\n\")\n",
        "    generate_paper_list_with_arxiv_link(f, demo)\n",
        "    f.write(\"## Student Research Workshop\\n\\n\")\n",
        "    generate_paper_list_with_arxiv_link(f, student)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  5%|▌         | 31/571 [01:07<21:59,  2.44s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "NOT MATCHED\n",
            "adaptive compression of word embeddings\n",
            "online embedding compression for text classification using low rank matrix factorization\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r  6%|▌         | 32/571 [01:10<22:15,  2.48s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "NOT MATCHED\n",
            "addressing posterior collapse with mutual information for improved variational neural machine translation\n",
            "improved variational neural machine translation by promoting mutual information\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "  9%|▉         | 53/571 [01:54<18:55,  2.19s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "NOT MATCHED\n",
            "attentive pooling with learnable norms for text representation\n",
            "attentive pooling networks\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 12%|█▏        | 68/571 [02:31<21:03,  2.51s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "NOT MATCHED\n",
            "bilingual dictionary based neural machine translation without using parallel sentences\n",
            "bridging neural machine translation and bilingual dictionaries\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 13%|█▎        | 73/571 [02:43<19:23,  2.34s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "NOT MATCHED\n",
            "boosting neural machine translation with similar translations\n",
            "neural machine translation from simplified translations\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 17%|█▋        | 96/571 [03:36<18:33,  2.34s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "NOT MATCHED\n",
            "contextualized weak supervision for text classification\n",
            "weakly-supervised neural text classification\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 18%|█▊        | 103/571 [03:50<17:57,  2.30s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "NOT MATCHED\n",
            "cross-lingual unsupervised sentiment classification with multi-view transfer learning\n",
            "multi-source cross-lingual model transfer: learning what to share\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 19%|█▉        | 109/571 [04:07<19:52,  2.58s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "NOT MATCHED\n",
            "curriculum learning for natural language understanding\n",
            "visualizing and understanding curriculum learning for long short-term memory networks\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 22%|██▏       | 126/571 [04:50<17:29,  2.36s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "NOT MATCHED\n",
            "distilling annotations via active imitation learning\n",
            "random expert distillation: imitation learning via expert policy support estimation\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 26%|██▌       | 147/571 [05:45<17:43,  2.51s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "NOT MATCHED\n",
            "effective inter-clause modeling for end-to-end emotion-cause pair extraction\n",
            "end-to-end emotion-cause pair extraction via learning to link\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 31%|███       | 176/571 [06:53<17:02,  2.59s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "NOT MATCHED\n",
            "explicit semantic decomposition for definition generation\n",
            "semantic composition and decomposition: from recognition to generation\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 38%|███▊      | 218/571 [08:31<14:40,  2.49s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "NOT MATCHED\n",
            "graph neural news recommendation with unsupervised preference disentanglement\n",
            "graph neural news recommendation with long-term and short-term interest modeling\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 44%|████▍     | 251/571 [09:43<11:39,  2.18s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "NOT MATCHED\n",
            "improving disentangled text representation learning with information-theoretic guidance\n",
            "improving disentangled representation learning with the beta bernoulli process\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 45%|████▍     | 255/571 [09:52<11:58,  2.27s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "NOT MATCHED\n",
            "improving image captioning with better use of caption\n",
            "hidden state guidance: improving image captioning using an image conditioned autoencoder\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 46%|████▌     | 264/571 [10:15<12:37,  2.47s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "NOT MATCHED\n",
            "in neural machine translation, what does transfer learning transfer?\n",
            "exploring benefits of transfer learning in neural machine translation\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 53%|█████▎    | 303/571 [11:47<10:44,  2.40s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "NOT MATCHED\n",
            "learning constraints for structured prediction using rectifier networks\n",
            "adversarial constraint learning for structured prediction\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 54%|█████▍    | 308/571 [11:58<10:49,  2.47s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "NOT MATCHED\n",
            "learning to ask more: semi-autoregressive sequential question generation under dual-graph interaction\n",
            "semi-autoregressive neural machine translation\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 57%|█████▋    | 325/571 [12:39<10:59,  2.68s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "NOT MATCHED\n",
            "low-resource generation of multi-hop reasoning questions\n",
            "reinforced multi-task approach for multi-hop question generation\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 58%|█████▊    | 333/571 [12:57<09:05,  2.29s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "NOT MATCHED\n",
            "meta-reinforced multi-domain state generator for dialogue systems\n",
            "transferable multi-domain state generator for task-oriented dialogue systems\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 62%|██████▏   | 354/571 [13:43<08:24,  2.32s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "NOT MATCHED\n",
            "multi-hypothesis machine translation evaluation\n",
            "pairwise neural machine translation evaluation\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 71%|███████▏  | 407/571 [15:50<05:31,  2.02s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "NOT MATCHED\n",
            "predicting the topical stance and political leaning of media using tweets\n",
            "predicting the topical stance of media and popular twitter users\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 72%|███████▏  | 409/571 [15:55<06:08,  2.27s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "NOT MATCHED\n",
            "premise selection in natural language mathematical texts\n",
            "natural language premise selection: finding supporting statements for mathematical text\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 76%|███████▌  | 434/571 [16:59<05:52,  2.57s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "NOT MATCHED\n",
            "reinceptione: relation-aware inception network with joint local-global structural information for knowledge graph embedding\n",
            "relation-aware entity alignment for heterogeneous knowledge graphs\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 86%|████████▌ | 492/571 [19:24<03:03,  2.32s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "NOT MATCHED\n",
            "structural information preserving for graph-to-text generation\n",
            "structural neural encoders for amr-to-text generation\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 96%|█████████▌| 547/571 [21:33<00:55,  2.30s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "NOT MATCHED\n",
            "unknown intent detection using gaussian mixture model with an application to zero-shot intent classification\n",
            "zero-shot user intent detection via capsule neural networks\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|█████████▉| 569/571 [22:29<00:04,  2.46s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "NOT MATCHED\n",
            "zero-shot text classification via reinforced self-training\n",
            "transductive zero-shot learning with a self-training dictionary approach\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 571/571 [22:33<00:00,  2.35s/it]\n",
            " 13%|█▎        | 28/208 [01:03<06:52,  2.29s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "NOT MATCHED\n",
            "camouflaged chinese spam content detection with semi-supervised generative active learning\n",
            "gans for semi-supervised opinion spam detection\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 18%|█▊        | 37/208 [01:26<07:13,  2.54s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "NOT MATCHED\n",
            "content word aware neural machine translation\n",
            "selective attention for context-aware neural machine translation\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 32%|███▏      | 66/208 [02:53<10:01,  4.23s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "NOT MATCHED\n",
            "entity-aware dependency-based deep graph attention network for comparative preference classification\n",
            "exploiting typed syntactic dependencies for targeted sentiment classification using graph attention neural network\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 45%|████▍     | 93/208 [04:07<05:58,  3.11s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "NOT MATCHED\n",
            "interpretable operational risk classification with semi-supervised variational autoencoder\n",
            "disentangled variational auto-encoder for semi-supervised learning\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 49%|████▉     | 102/208 [04:29<04:46,  2.70s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "NOT MATCHED\n",
            "learning low-resource end-to-end goal-oriented dialog for fast and reliable system deployment\n",
            "learning end-to-end goal-oriented dialog\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 58%|█████▊    | 121/208 [05:21<05:06,  3.52s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "NOT MATCHED\n",
            "multimodal and multiresolution speech recognition with transformers\n",
            "multiresolution and multimodal speech recognition with transformers\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 61%|██████    | 126/208 [05:33<03:56,  2.88s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "NOT MATCHED\n",
            "neural graph matching networks for chinese short text matching\n",
            "graph matching networks for learning the similarity of graph structured objects\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 91%|█████████ | 189/208 [08:17<00:52,  2.75s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "NOT MATCHED\n",
            "tree-structured neural topic model\n",
            "structured neural topic models for reviews\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|█████████▉| 207/208 [09:01<00:02,  2.87s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "NOT MATCHED\n",
            "``you sound just like your father’’ commercial machine translation systems include stylistic biases\n",
            "reducing gender bias in neural machine translation as a domain adaptation problem\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 208/208 [09:03<00:00,  2.49s/it]\n",
            "100%|██████████| 43/43 [01:42<00:00,  2.15s/it]\n",
            "  4%|▍         | 2/49 [00:04<01:36,  2.06s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "NOT MATCHED\n",
            "a geometry-inspired attack for generating natural language adversarial examples\n",
            "a geometry-inspired decision-based attack\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 49%|████▉     | 24/49 [00:50<00:53,  2.12s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "NOT MATCHED\n",
            "υbleu: uncertainty-aware automatic evaluation method for open-domain dialogue systems\n",
            "better automatic evaluation of open-domain dialogue systems with contextualized embeddings\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 49/49 [01:43<00:00,  1.84s/it]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GKaDBI55CNRK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}