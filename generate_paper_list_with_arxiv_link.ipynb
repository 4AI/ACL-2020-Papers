{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Paper List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_papers(path):\n",
    "    papers = [[]]\n",
    "    with open(path, \"r\", encoding=\"utf-8\") as f:\n",
    "        for line in f:\n",
    "            line = line.strip()\n",
    "            if line:\n",
    "                papers[-1].append(line)\n",
    "            else:\n",
    "                papers.append([])\n",
    "    for p in papers:\n",
    "        assert len(p) == 2\n",
    "    return papers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['2kenize: Tying Subword Sequences for Chinese Script Conversion',\n",
       "  'Pranav A and Isabelle Augenstein'],\n",
       " ['A Batch Normalized Inference Network Keeps the KL Vanishing Away',\n",
       "  'Qile Zhu, Wei Bi, Xiaojiang Liu, Xiyao Ma, Xiaolin Li and Dapeng Wu'],\n",
       " ['A Call for More Rigor in Unsupervised Cross-lingual Learning',\n",
       "  'Mikel Artetxe, Sebastian Ruder, Dani Yogatama, Gorka Labaka and Eneko Agirre']]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "long = read_papers(\"./data/long.txt\")\n",
    "long[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "571"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['A Complete Shift-Reduce Chinese Discourse Parser with Robust Dynamic Oracle',\n",
       "  'Shyh-Shiun Hung, Hen-Hsen Huang and Hsin-Hsi Chen'],\n",
       " ['A Diverse Corpus for Evaluating and Developing English Math Word Problem Solvers',\n",
       "  'Shen-yun Miao, Chao-Chun Liang and Keh-Yih Su'],\n",
       " ['A Frame-based Sentence Representation for Machine Reading Comprehension',\n",
       "  'Shaoru Guo, Ru Li, Hongye Tan, Xiaoli Li, Yong Guan, Hongyan Zhao and Yueping Zhang']]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "short = read_papers(\"./data/short.txt\")\n",
    "short[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "208"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(short)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['ADVISER: A Toolkit for Developing Multi-modal, Multi-domain and Socially-engaged Conversational Agents',\n",
       "  'Chia-Yu Li, Daniel Ortega, Dirk Väth, Florian Lux, Lindsey Vanderlyn, Maximilian Schmidt, Michael Neumann, Moritz Völkel, Pavel Denisov, Sabrina Jenne, Zorica Kacarevic and Ngoc Thang Vu'],\n",
       " ['BENTO: A Visual Platform for Building Clinical NLP Pipelines Based on CodaLab',\n",
       "  'Yonghao Jin, Fei Li and Hong Yu'],\n",
       " ['Clinical-Coder: Assigning Interpretable ICD-10 Codes to Chinese Clinical Notes',\n",
       "  'Pengfei Cao, Chenwei Yan, xiangling fu, Yubo Chen, Kang Liu, Jun Zhao, Shengping Liu and Weifeng Chong']]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "demo = read_papers(\"./data/demo.txt\")\n",
    "demo[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "43"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(demo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['#NotAWhore! A Computational Linguistic Perspective of Rape Culture and Victimization on Social Media',\n",
       "  'Ashima Suvarna and Grusha Bhalla'],\n",
       " ['A Geometry-Inspired Attack for Generating Natural Language Adversarial Examples',\n",
       "  'Zhao Meng and Roger Wattenhofer'],\n",
       " ['A Simple and Effective Dependency parser for Telugu',\n",
       "  'Sneha Nallani, Manish Shrivastava and Dipti Sharma']]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "student = read_papers(\"./data/student.txt\")\n",
    "student[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "49"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(student)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Search arXiv Link"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from googlesearch import search\n",
    "import urllib\n",
    "from bs4 import BeautifulSoup\n",
    "from difflib import SequenceMatcher\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "def similarity(a, b):\n",
    "    return SequenceMatcher(None, a, b).ratio()\n",
    "\n",
    "\n",
    "def search_arxiv_link(title):\n",
    "    link = None\n",
    "    for j in search(title, tld=\"co.in\", num=10, stop=1, pause=0.5):\n",
    "        if 'arxiv.org/abs' in j:\n",
    "            thepage = urllib.request.urlopen(j)\n",
    "            soup = BeautifulSoup(thepage, \"html.parser\")\n",
    "            searched_title = ' '.join(soup.title.text.lower().split()[1:])\n",
    "            if similarity(title, searched_title) > 0.8:\n",
    "                link = j\n",
    "                break\n",
    "            else:\n",
    "                print(\"NOT MATCHED\")\n",
    "                print(title)\n",
    "                print(searched_title)\n",
    "    return link"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generate_paper_list_with_arxiv_link(f, papers):\n",
    "    for p in tqdm(papers):\n",
    "        title, authors = p\n",
    "        link = search_arxiv_link(title.lower())\n",
    "        if link:\n",
    "            f.write(f\"- {title} [[arXiv]]({link})\\n\")\n",
    "        else:\n",
    "            f.write(f\"- {title}\\n\")\n",
    "    f.write(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 31/571 [01:07<21:59,  2.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOT MATCHED\n",
      "adaptive compression of word embeddings\n",
      "online embedding compression for text classification using low rank matrix factorization\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  6%|▌         | 32/571 [01:10<22:15,  2.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOT MATCHED\n",
      "addressing posterior collapse with mutual information for improved variational neural machine translation\n",
      "improved variational neural machine translation by promoting mutual information\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|▉         | 53/571 [01:54<18:55,  2.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOT MATCHED\n",
      "attentive pooling with learnable norms for text representation\n",
      "attentive pooling networks\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 68/571 [02:31<21:03,  2.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOT MATCHED\n",
      "bilingual dictionary based neural machine translation without using parallel sentences\n",
      "bridging neural machine translation and bilingual dictionaries\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█▎        | 73/571 [02:43<19:23,  2.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOT MATCHED\n",
      "boosting neural machine translation with similar translations\n",
      "neural machine translation from simplified translations\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 96/571 [03:36<18:33,  2.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOT MATCHED\n",
      "contextualized weak supervision for text classification\n",
      "weakly-supervised neural text classification\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█▊        | 103/571 [03:50<17:57,  2.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOT MATCHED\n",
      "cross-lingual unsupervised sentiment classification with multi-view transfer learning\n",
      "multi-source cross-lingual model transfer: learning what to share\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|█▉        | 109/571 [04:07<19:52,  2.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOT MATCHED\n",
      "curriculum learning for natural language understanding\n",
      "visualizing and understanding curriculum learning for long short-term memory networks\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 126/571 [04:50<17:29,  2.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOT MATCHED\n",
      "distilling annotations via active imitation learning\n",
      "random expert distillation: imitation learning via expert policy support estimation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|██▌       | 147/571 [05:45<17:43,  2.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOT MATCHED\n",
      "effective inter-clause modeling for end-to-end emotion-cause pair extraction\n",
      "end-to-end emotion-cause pair extraction via learning to link\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 31%|███       | 176/571 [06:53<17:02,  2.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOT MATCHED\n",
      "explicit semantic decomposition for definition generation\n",
      "semantic composition and decomposition: from recognition to generation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|███▊      | 218/571 [08:31<14:40,  2.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOT MATCHED\n",
      "graph neural news recommendation with unsupervised preference disentanglement\n",
      "graph neural news recommendation with long-term and short-term interest modeling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|████▍     | 251/571 [09:43<11:39,  2.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOT MATCHED\n",
      "improving disentangled text representation learning with information-theoretic guidance\n",
      "improving disentangled representation learning with the beta bernoulli process\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|████▍     | 255/571 [09:52<11:58,  2.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOT MATCHED\n",
      "improving image captioning with better use of caption\n",
      "hidden state guidance: improving image captioning using an image conditioned autoencoder\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 46%|████▌     | 264/571 [10:15<12:37,  2.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOT MATCHED\n",
      "in neural machine translation, what does transfer learning transfer?\n",
      "exploring benefits of transfer learning in neural machine translation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 53%|█████▎    | 303/571 [11:47<10:44,  2.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOT MATCHED\n",
      "learning constraints for structured prediction using rectifier networks\n",
      "adversarial constraint learning for structured prediction\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 54%|█████▍    | 308/571 [11:58<10:49,  2.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOT MATCHED\n",
      "learning to ask more: semi-autoregressive sequential question generation under dual-graph interaction\n",
      "semi-autoregressive neural machine translation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 57%|█████▋    | 325/571 [12:39<10:59,  2.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOT MATCHED\n",
      "low-resource generation of multi-hop reasoning questions\n",
      "reinforced multi-task approach for multi-hop question generation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 58%|█████▊    | 333/571 [12:57<09:05,  2.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOT MATCHED\n",
      "meta-reinforced multi-domain state generator for dialogue systems\n",
      "transferable multi-domain state generator for task-oriented dialogue systems\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|██████▏   | 354/571 [13:43<08:24,  2.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOT MATCHED\n",
      "multi-hypothesis machine translation evaluation\n",
      "pairwise neural machine translation evaluation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 71%|███████▏  | 407/571 [15:50<05:31,  2.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOT MATCHED\n",
      "predicting the topical stance and political leaning of media using tweets\n",
      "predicting the topical stance of media and popular twitter users\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 72%|███████▏  | 409/571 [15:55<06:08,  2.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOT MATCHED\n",
      "premise selection in natural language mathematical texts\n",
      "natural language premise selection: finding supporting statements for mathematical text\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 76%|███████▌  | 434/571 [16:59<05:52,  2.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOT MATCHED\n",
      "reinceptione: relation-aware inception network with joint local-global structural information for knowledge graph embedding\n",
      "relation-aware entity alignment for heterogeneous knowledge graphs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 86%|████████▌ | 492/571 [19:24<03:03,  2.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOT MATCHED\n",
      "structural information preserving for graph-to-text generation\n",
      "structural neural encoders for amr-to-text generation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 96%|█████████▌| 547/571 [21:33<00:55,  2.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOT MATCHED\n",
      "unknown intent detection using gaussian mixture model with an application to zero-shot intent classification\n",
      "zero-shot user intent detection via capsule neural networks\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████▉| 569/571 [22:29<00:04,  2.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOT MATCHED\n",
      "zero-shot text classification via reinforced self-training\n",
      "transductive zero-shot learning with a self-training dictionary approach\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 571/571 [22:33<00:00,  2.35s/it]\n",
      " 13%|█▎        | 28/208 [01:03<06:52,  2.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOT MATCHED\n",
      "camouflaged chinese spam content detection with semi-supervised generative active learning\n",
      "gans for semi-supervised opinion spam detection\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█▊        | 37/208 [01:26<07:13,  2.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOT MATCHED\n",
      "content word aware neural machine translation\n",
      "selective attention for context-aware neural machine translation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|███▏      | 66/208 [02:53<10:01,  4.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOT MATCHED\n",
      "entity-aware dependency-based deep graph attention network for comparative preference classification\n",
      "exploiting typed syntactic dependencies for targeted sentiment classification using graph attention neural network\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|████▍     | 93/208 [04:07<05:58,  3.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOT MATCHED\n",
      "interpretable operational risk classification with semi-supervised variational autoencoder\n",
      "disentangled variational auto-encoder for semi-supervised learning\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 49%|████▉     | 102/208 [04:29<04:46,  2.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOT MATCHED\n",
      "learning low-resource end-to-end goal-oriented dialog for fast and reliable system deployment\n",
      "learning end-to-end goal-oriented dialog\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 58%|█████▊    | 121/208 [05:21<05:06,  3.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOT MATCHED\n",
      "multimodal and multiresolution speech recognition with transformers\n",
      "multiresolution and multimodal speech recognition with transformers\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 61%|██████    | 126/208 [05:33<03:56,  2.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOT MATCHED\n",
      "neural graph matching networks for chinese short text matching\n",
      "graph matching networks for learning the similarity of graph structured objects\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 91%|█████████ | 189/208 [08:17<00:52,  2.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOT MATCHED\n",
      "tree-structured neural topic model\n",
      "structured neural topic models for reviews\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████▉| 207/208 [09:01<00:02,  2.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOT MATCHED\n",
      "``you sound just like your father’’ commercial machine translation systems include stylistic biases\n",
      "reducing gender bias in neural machine translation as a domain adaptation problem\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 208/208 [09:03<00:00,  2.49s/it]\n",
      "100%|██████████| 43/43 [01:42<00:00,  2.15s/it]\n",
      "  4%|▍         | 2/49 [00:04<01:36,  2.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOT MATCHED\n",
      "a geometry-inspired attack for generating natural language adversarial examples\n",
      "a geometry-inspired decision-based attack\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 49%|████▉     | 24/49 [00:50<00:53,  2.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOT MATCHED\n",
      "υbleu: uncertainty-aware automatic evaluation method for open-domain dialogue systems\n",
      "better automatic evaluation of open-domain dialogue systems with contextualized embeddings\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 49/49 [01:43<00:00,  1.84s/it]\n"
     ]
    }
   ],
   "source": [
    "with open(\"papers_with_arxiv_link.md\", \"w\") as f:\n",
    "    f.write(\"## Long Papers\\n\\n\")\n",
    "    generate_paper_list_with_arxiv_link(f, long)\n",
    "    f.write(\"## Short Papers\\n\\n\")\n",
    "    generate_paper_list_with_arxiv_link(f, short)\n",
    "    f.write(\"## System Demonstrations\\n\\n\")\n",
    "    generate_paper_list_with_arxiv_link(f, demo)\n",
    "    f.write(\"## Student Research Workshop\\n\\n\")\n",
    "    generate_paper_list_with_arxiv_link(f, student)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
